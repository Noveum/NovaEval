{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The agent as shown on Noveum.ai platform\n",
        "\n",
        "![Alt text](image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Final Agent Evaluation Demo with NovaEval\n",
        "\n",
        "This notebook demonstrates a streamlined approach to agent evaluation using modular utility functions:\n",
        "\n",
        "1. **Load agent trace data** from JSON datasets\n",
        "2. **Map trace spans** to AgentData format using utility functions\n",
        "3. **Create and analyze** AgentDataset\n",
        "4. **Evaluate agent performance** using AgentEvaluator with Gemini model\n",
        "5. **Analyze results** and export data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scorers Used\n",
        "\n",
        "**context_relevancy_scorer** - Evaluates whether the agent response is appropriate and relevant given the agent's task and role.\n",
        "\n",
        "**role_adherence_scorer** - Scores whether the agent's tool calls and response adhere to its assigned role and task.\n",
        "\n",
        "**task_progression_scorer** - Measures whether the agent has made meaningful progress on the assigned task.\n",
        "\n",
        "**tool_relevancy_scorer** - Assesses how relevant and appropriate the tool call is given the available tools and the agent's context.\n",
        "\n",
        "**tool_correctness_scorer** - Compares actual tool calls against expected tool calls to evaluate correctness of tool usage and parameters.\n",
        "\n",
        "**parameter_correctness_scorer** - Validates whether correct parameters were passed to tool calls by analyzing the tool results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Dependencies and Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import our custom utility functions\n",
        "from demo_utils import (\n",
        "    list_dataset_files,\n",
        "    load_and_analyze_dataset,\n",
        "    convert_spans_to_agent_dataset,\n",
        "    analyze_dataset_statistics,\n",
        "    setup_gemini_model,\n",
        "    setup_agent_evaluator,\n",
        "    run_evaluation,\n",
        "    analyze_agent_behavior_patterns,\n",
        "    export_processed_dataset,\n",
        "    setup_logging,\n",
        "    validate_environment,\n",
        "    print_demo_summary\n",
        ")\n",
        "\n",
        "print(\"âœ… All utility functions imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `python print('hi')'\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading dataset.json...\n",
            "Original dataset: 4198 records\n",
            "Filtering spans...\n",
            "After filtering: 3381 records\n",
            "Converting tool output format...\n",
            "Writing dataset_filtered.json...\n",
            "Filtering complete! Output: dataset_filtered.json\n",
            "\n",
            "Success! Created dataset_filtered.json\n",
            "Reading dataset_filtered.json...\n",
            "Input dataset: 3381 records\n",
            "Mapping spans...\n",
            "Writing dataset_filtered_mapped.json...\n",
            "Mapping complete! Output: dataset_filtered_mapped.json\n",
            "\n",
            "Success! Created dataset_filtered_mapped.json\n",
            "Input file: dataset_filtered_mapped.json\n",
            "Output directory: split_datasets\n",
            "\n",
            "Loading dataset from dataset_filtered_mapped.json...\n",
            "Loaded 3381 objects\n",
            "Found 5 unique span names\n",
            "Using hardcoded mapping: agent.query_generation -> agent_query_gen_dataset.json\n",
            "  Wrote 533 objects to split_datasets/agent_query_gen_dataset.json\n",
            "Using hardcoded mapping: tool:tavily_search_results_json:tavily_search_results_json -> tavily_search_results_dataset.json\n",
            "  Wrote 2301 objects to split_datasets/tavily_search_results_dataset.json\n",
            "Using hardcoded mapping: post_validation -> post_validation_dataset.json\n",
            "  Wrote 521 objects to split_datasets/post_validation_dataset.json\n",
            "Using hardcoded mapping: agent.comment_generation -> agent_comment_gen_dataset.json\n",
            "  Wrote 13 objects to split_datasets/agent_comment_gen_dataset.json\n",
            "Using hardcoded mapping: email_generation_and_sending -> email_gen_send_dataset.json\n",
            "  Wrote 13 objects to split_datasets/email_gen_send_dataset.json\n",
            "\n",
            "Split complete! Created 5 files in split_datasets\n"
          ]
        }
      ],
      "source": [
        "!python preprocess_filter.py dataset.json\n",
        "!python preprocess_map.py dataset_filtered.json\n",
        "!python preprocess_split_data.py dataset_filtered_mapped.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:48 - noveum_trace.transport.batch_processor - INFO - ðŸ”„ Batch processor background thread started (batch_size=100, timeout=5.0s)\n",
            "2025-09-26 04:14:48 - noveum_trace.transport.batch_processor - INFO - Batch processor started with batch_size=100\n",
            "2025-09-26 04:14:48 - noveum_trace.transport.http_transport - INFO - HTTP transport initialized for endpoint: https://api.noveum.ai/api\n",
            "2025-09-26 04:14:48 - noveum_trace.core.client - INFO - Noveum Trace client initialized\n",
            "2025-09-26 04:14:48,825 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All imports successful!\n",
            "âœ… list_dataset_files function defined!\n",
            "âœ… load_and_analyze_dataset function defined!\n",
            "âœ… parse_tools_from_prompt function defined!\n",
            "âœ… parse_params function defined!\n",
            "âœ… identify_span_type function defined!\n",
            "âœ… map_span_to_agent_data function defined!\n",
            "âœ… convert_spans_to_agent_dataset function defined!\n",
            "âœ… analyze_dataset_statistics function defined!\n",
            "âœ… setup_gemini_model function defined!\n",
            "âœ… setup_agent_evaluator function defined!\n",
            "âœ… run_evaluation function defined!\n",
            "âœ… analyze_agent_behavior_patterns function defined!\n",
            "âœ… export_processed_dataset function defined!\n",
            "âœ… setup_logging function defined!\n",
            "âœ… validate_environment function defined!\n",
            "âœ… print_demo_summary function defined!\n",
            "âœ… run_complete_agent_evaluation function defined!\n",
            "ðŸš€ Starting Complete Agent Evaluation Pipeline\n",
            "ðŸ“ Processing file: split_datasets/tavily_search_results_dataset.json\n",
            "============================================================\n",
            "\n",
            "ðŸ“‹ Step 1: Environment Setup\n",
            "âœ… Logging configured at INFO level\n",
            "ðŸ” Environment validation:\n",
            "  âœ… gemini_api_key: True\n",
            "  âœ… pandas_available: True\n",
            "  âœ… novaeval_available: True\n",
            "âœ… Environment ready for evaluation!\n",
            "\n",
            "ðŸ“‹ Step 2: Loading Dataset\n",
            "ðŸ“Š Loaded 2301 spans from split_datasets/tavily_search_results_dataset.json\n",
            "\n",
            "ðŸ” Available span types:\n",
            "  - tool:tavily_search_results_json:tavily_search_results_json: 2301\n",
            "âœ… Dataset loaded: 2301 spans\n",
            "\n",
            "ðŸ“‹ Step 3: Converting to AgentDataset Format\n",
            "ðŸ”„ Converting spans to AgentData objects...\n",
            "\n",
            "âœ… Successfully converted 2301 spans to AgentData\n",
            "ðŸ“Š AgentDataset created with 2301 records\n",
            "âœ… AgentDataset created: 2301 records\n",
            "\n",
            "ðŸ“‹ Step 4: Dataset Analysis\n",
            "ðŸ“ˆ Dataset Statistics:\n",
            "\n",
            "Agent Types: {'tool': 2301}\n",
            "Records with responses: 2301\n",
            "Records with tool calls: 0\n",
            "Records with retrieval: 0\n",
            "Tool usage: {}\n",
            "ðŸ” Dataset Analysis:\n",
            "\n",
            "=== Agent Behavior Patterns ===\n",
            "\n",
            "ðŸ“ˆ Tool Usage:\n",
            "\n",
            "ðŸ“‹ Task Types:\n",
            "  - other: 2301\n",
            "\n",
            "ðŸ“ Response Statistics:\n",
            "  - Average response length: 679.2 characters\n",
            "  - Min response length: 70\n",
            "  - Max response length: 7309\n",
            "\n",
            "ðŸ“‹ Step 5: Setting up Evaluation\n",
            "âœ… GEMINI_API_KEY found in environment\n",
            "âœ… Gemini model initialized\n",
            "âœ… Initialized 5 scoring functions:\n",
            "  - task_progression_scorer\n",
            "  - context_relevancy_scorer\n",
            "  - role_adherence_scorer\n",
            "  - tool_relevancy_scorer\n",
            "  - parameter_correctness_scorer\n",
            "\n",
            "âœ… AgentEvaluator created with Gemini model and scoring functions\n",
            "âœ… Evaluation components ready!\n",
            "\n",
            "ðŸ“‹ Step 6: Running Evaluation\n",
            "ðŸŽ¯ Evaluating 25 samples...\n",
            "ðŸš€ Running evaluation on sample data...\n",
            "\n",
            "ðŸ“Š Evaluating 25 sample records...\n",
            "2025-09-26 04:14:48 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating samples: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:48 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:50 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:50 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 64390c07-1bb2-4e17-adab-0a37bb7d3881) - 1 spans\n",
            "2025-09-26 04:14:50 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 64390c07-1bb2-4e17-adab-0a37bb7d3881) - 1 spans\n",
            "2025-09-26 04:14:50 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 64390c07-1bb2-4e17-adab-0a37bb7d3881\n",
            "2025-09-26 04:14:50 - noveum_trace.transport.http_transport - INFO - âœ… Trace 64390c07-1bb2-4e17-adab-0a37bb7d3881 successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:50 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:51 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:51 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 0e52d952-1e90-4867-a442-d1ff54ce0f2e) - 1 spans\n",
            "2025-09-26 04:14:51 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 0e52d952-1e90-4867-a442-d1ff54ce0f2e) - 1 spans\n",
            "2025-09-26 04:14:51 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 0e52d952-1e90-4867-a442-d1ff54ce0f2e\n",
            "2025-09-26 04:14:51 - noveum_trace.transport.http_transport - INFO - âœ… Trace 0e52d952-1e90-4867-a442-d1ff54ce0f2e successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:51 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:52 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:52 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 2aa5c2c1-dc3e-4c5a-8776-ad0ca2e612e1) - 1 spans\n",
            "2025-09-26 04:14:52 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 2aa5c2c1-dc3e-4c5a-8776-ad0ca2e612e1) - 1 spans\n",
            "2025-09-26 04:14:52 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 2aa5c2c1-dc3e-4c5a-8776-ad0ca2e612e1\n",
            "2025-09-26 04:14:52 - noveum_trace.transport.http_transport - INFO - âœ… Trace 2aa5c2c1-dc3e-4c5a-8776-ad0ca2e612e1 successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:52 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 1 samples\n",
            "2025-09-26 04:14:52 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to evaluation_results/agent_evaluation/agent_evaluation_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating samples: 1it [00:03,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:52 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:54 - noveum_trace.transport.batch_processor - INFO - â° TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
            "2025-09-26 04:14:54 - noveum_trace.transport.batch_processor - INFO - ðŸ“¤ SENDING BATCH: 3 traces via send_callback\n",
            "2025-09-26 04:14:54 - noveum_trace.transport.http_transport - INFO - ðŸš€ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:54 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:54 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 0d472422-19e3-441f-9689-3dd46f60038c) - 1 spans\n",
            "2025-09-26 04:14:54 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 0d472422-19e3-441f-9689-3dd46f60038c) - 1 spans\n",
            "2025-09-26 04:14:54 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 0d472422-19e3-441f-9689-3dd46f60038c\n",
            "2025-09-26 04:14:54 - noveum_trace.transport.http_transport - INFO - âœ… Trace 0d472422-19e3-441f-9689-3dd46f60038c successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:54 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:55 - noveum_trace.transport.http_transport - INFO - ðŸ“¡ HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
            "2025-09-26 04:14:55 - noveum_trace.transport.http_transport - INFO - âœ… Successfully sent batch of 3 traces\n",
            "2025-09-26 04:14:55 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully sent batch of 3 traces via callback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:55 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:55 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: a4336f24-af5b-4da5-ad01-ec72cd6acaac) - 1 spans\n",
            "2025-09-26 04:14:55 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: a4336f24-af5b-4da5-ad01-ec72cd6acaac) - 1 spans\n",
            "2025-09-26 04:14:55 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace a4336f24-af5b-4da5-ad01-ec72cd6acaac\n",
            "2025-09-26 04:14:55 - noveum_trace.transport.http_transport - INFO - âœ… Trace a4336f24-af5b-4da5-ad01-ec72cd6acaac successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:55 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:56 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:56 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 167bb438-75e0-48f7-92a4-b16297320171) - 1 spans\n",
            "2025-09-26 04:14:56 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 167bb438-75e0-48f7-92a4-b16297320171) - 1 spans\n",
            "2025-09-26 04:14:56 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 167bb438-75e0-48f7-92a4-b16297320171\n",
            "2025-09-26 04:14:56 - noveum_trace.transport.http_transport - INFO - âœ… Trace 167bb438-75e0-48f7-92a4-b16297320171 successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:56 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 2 samples\n",
            "2025-09-26 04:14:56 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to evaluation_results/agent_evaluation/agent_evaluation_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating samples: 2it [00:07,  3.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:56 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:58 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:58 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 9e3bc805-f035-4257-85b0-e0061b17cb71) - 1 spans\n",
            "2025-09-26 04:14:58 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9e3bc805-f035-4257-85b0-e0061b17cb71) - 1 spans\n",
            "2025-09-26 04:14:58 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 9e3bc805-f035-4257-85b0-e0061b17cb71\n",
            "2025-09-26 04:14:58 - noveum_trace.transport.http_transport - INFO - âœ… Trace 9e3bc805-f035-4257-85b0-e0061b17cb71 successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:58 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n",
            "2025-09-26 04:14:59 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:59 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: d6d18818-7c78-402e-8e67-a608b2950c4f) - 1 spans\n",
            "2025-09-26 04:14:59 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: d6d18818-7c78-402e-8e67-a608b2950c4f) - 1 spans\n",
            "2025-09-26 04:14:59 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace d6d18818-7c78-402e-8e67-a608b2950c4f\n",
            "2025-09-26 04:14:59 - noveum_trace.transport.http_transport - INFO - âœ… Trace d6d18818-7c78-402e-8e67-a608b2950c4f successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:59 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:14:59 - noveum_trace.transport.batch_processor - INFO - â° TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
            "2025-09-26 04:14:59 - noveum_trace.transport.batch_processor - INFO - ðŸ“¤ SENDING BATCH: 5 traces via send_callback\n",
            "2025-09-26 04:14:59 - noveum_trace.transport.http_transport - INFO - ðŸš€ SENDING BATCH: 5 traces to https://api.noveum.ai/api/v1/traces\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.http_transport - INFO - ðŸ“¡ HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.http_transport - INFO - âœ… Successfully sent batch of 5 traces\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully sent batch of 5 traces via callback\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:00 - INFO - google_genai.models - AFC remote call 1 is done.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:00 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 62ea9358-1667-4114-beed-30e94c560a89) - 1 spans\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 62ea9358-1667-4114-beed-30e94c560a89) - 1 spans\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 62ea9358-1667-4114-beed-30e94c560a89\n",
            "2025-09-26 04:15:00 - noveum_trace.transport.http_transport - INFO - âœ… Trace 62ea9358-1667-4114-beed-30e94c560a89 successfully queued for export\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:00 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 3 samples\n",
            "2025-09-26 04:15:00 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to evaluation_results/agent_evaluation/agent_evaluation_results.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating samples: 3it [00:11,  3.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:00 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:01 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_generate (ID: 88278c33-963b-4104-83a5-4334a6465c6b) - 1 spans\n",
            "2025-09-26 04:15:01 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_generate (ID: 88278c33-963b-4104-83a5-4334a6465c6b) - 1 spans\n",
            "2025-09-26 04:15:01 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 88278c33-963b-4104-83a5-4334a6465c6b\n",
            "2025-09-26 04:15:01 - noveum_trace.transport.http_transport - INFO - âœ… Trace 88278c33-963b-4104-83a5-4334a6465c6b successfully queued for export\n",
            "Evaluating samples: 3it [00:12,  4.19s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdemo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_complete_agent_evaluation\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# One line execution\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mrun_complete_agent_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplit_datasets/tavily_search_results_dataset.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/reddit_agent_demo/demo_utils.py:896\u001b[0m, in \u001b[0;36mrun_complete_agent_evaluation\u001b[0;34m(selected_file, sample_size, evaluation_name, model_name, temperature, max_tokens, output_dir)\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“‹ Step 6: Running Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸŽ¯ Evaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 896\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_name\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation_completed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/reddit_agent_demo/demo_utils.py:536\u001b[0m, in \u001b[0;36mrun_evaluation\u001b[0;34m(dataset, evaluator, sample_size, file_name)\u001b[0m\n\u001b[1;32m    526\u001b[0m sample_evaluator \u001b[38;5;241m=\u001b[39m AgentEvaluator(\n\u001b[1;32m    527\u001b[0m     agent_dataset\u001b[38;5;241m=\u001b[39msample_dataset,\n\u001b[1;32m    528\u001b[0m     models\u001b[38;5;241m=\u001b[39mevaluator\u001b[38;5;241m.\u001b[39mmodels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    532\u001b[0m     include_reasoning\u001b[38;5;241m=\u001b[39mevaluator\u001b[38;5;241m.\u001b[39minclude_reasoning\n\u001b[1;32m    533\u001b[0m )\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[0;32m--> 536\u001b[0m \u001b[43msample_evaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Evaluation completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# Read and display results\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/src/novaeval/evaluators/agent_evaluator.py:175\u001b[0m, in \u001b[0;36mAgentEvaluator.run_all\u001b[0;34m(self, save_every, file_type, aggregate_by_task, aggregate_by_user, aggregate_by_agent_name, aggregator_functions, aggregation_chunk_size)\u001b[0m\n\u001b[1;32m    173\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model available for evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m sample_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Add result to DataFrame\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_result_to_dataframe(sample_result)\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/src/novaeval/evaluators/agent_evaluator.py:429\u001b[0m, in \u001b[0;36mAgentEvaluator.evaluate_sample\u001b[0;34m(self, sample, model)\u001b[0m\n\u001b[1;32m    425\u001b[0m     scorer_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_scorer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;66;03m# Call the scoring function directly\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     score_result \u001b[38;5;241m=\u001b[39m \u001b[43mscoring_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# Extract score and reasoning based on result type\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(score_result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;66;03m# Single score object\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/src/novaeval/scorers/agent_scorers.py:646\u001b[0m, in \u001b[0;36mtask_progression_scorer\u001b[0;34m(agent_data, model)\u001b[0m\n\u001b[1;32m    638\u001b[0m prompt \u001b[38;5;241m=\u001b[39m TASK_PROGRESSION_PROMPT\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    639\u001b[0m     agent_role\u001b[38;5;241m=\u001b[39magent_data\u001b[38;5;241m.\u001b[39magent_role,\n\u001b[1;32m    640\u001b[0m     agent_task\u001b[38;5;241m=\u001b[39magent_data\u001b[38;5;241m.\u001b[39magent_task,\n\u001b[1;32m    641\u001b[0m     system_prompt\u001b[38;5;241m=\u001b[39magent_data\u001b[38;5;241m.\u001b[39msystem_prompt,\n\u001b[1;32m    642\u001b[0m     agent_response\u001b[38;5;241m=\u001b[39magent_data\u001b[38;5;241m.\u001b[39magent_response,\n\u001b[1;32m    643\u001b[0m )\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 646\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_score_with_original_task(response)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# Return default low score if parsing fails\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/noveum_trace/decorators/llm.py:169\u001b[0m, in \u001b[0;36mtrace_llm.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m attach_context_to_span(span)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Execute the function\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# Capture completions if enabled\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m capture_completions:\n",
            "File \u001b[0;32m~/Desktop/noveum/NovaEval/src/novaeval/models/gemini.py:189\u001b[0m, in \u001b[0;36mGeminiModel.generate\u001b[0;34m(self, prompt, max_tokens, temperature, stop, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03mGenerate text using Gemini's API.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Generated text\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerateContentConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# Extract text from response, handling different response formats\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/google/genai/models.py:5898\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5896\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5897\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5898\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5899\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[1;32m   5900\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5901\u001b[0m   logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is done.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   5902\u001b[0m   remaining_remote_calls_afc \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/google/genai/models.py:4838\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   4835\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   4836\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 4838\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4839\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   4840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4842\u001b[0m response_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;28;01melse\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mbody)\n\u001b[1;32m   4844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_client\u001b[38;5;241m.\u001b[39mvertexai:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:1067\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1059\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1062\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1063\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m   1064\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1065\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1066\u001b[0m   )\n\u001b[0;32m-> 1067\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1069\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1070\u001b[0m   )\n\u001b[1;32m   1071\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:958\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_request\u001b[39m(\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    955\u001b[0m     http_request: HttpRequest,\n\u001b[1;32m    956\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    957\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m HttpResponse:\n\u001b[0;32m--> 958\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/google/genai/_api_client.py:941\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    938\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    939\u001b[0m   )\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 941\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_httpx_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    948\u001b[0m   errors\u001b[38;5;241m.\u001b[39mAPIError\u001b[38;5;241m.\u001b[39mraise_for_response(response)\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m    950\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m    951\u001b[0m   )\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_client.py:825\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[1;32m    810\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    812\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[1;32m    813\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    814\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[1;32m    824\u001b[0m )\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
            "File \u001b[0;32m~/Desktop/noveum/.venv/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1288\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
            "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1161\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-09-26 04:15:04 - noveum_trace.transport.batch_processor - INFO - â° TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
            "2025-09-26 04:15:04 - noveum_trace.transport.batch_processor - INFO - ðŸ“¤ SENDING BATCH: 2 traces via send_callback\n",
            "2025-09-26 04:15:04 - noveum_trace.transport.http_transport - INFO - ðŸš€ SENDING BATCH: 2 traces to https://api.noveum.ai/api/v1/traces\n",
            "2025-09-26 04:15:05 - noveum_trace.transport.http_transport - INFO - ðŸ“¡ HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
            "2025-09-26 04:15:05 - noveum_trace.transport.http_transport - INFO - âœ… Successfully sent batch of 2 traces\n",
            "2025-09-26 04:15:05 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully sent batch of 2 traces via callback\n"
          ]
        }
      ],
      "source": [
        "from demo_utils import run_complete_agent_evaluation\n",
        "\n",
        "#evaluating the split datasets\n",
        "run_complete_agent_evaluation('split_datasets/agent_comment_gen_dataset.json')\n",
        "run_complete_agent_evaluation('split_datasets/agent_query_gen_dataset.json')\n",
        "run_complete_agent_evaluation('split_datasets/email_gen_send_dataset.json')\n",
        "run_complete_agent_evaluation('split_datasets/post_validation_dataset.json')\n",
        "run_complete_agent_evaluation('split_datasets/tavily_search_results_dataset.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analysis of poor scores in comment generation agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task Progression:\n",
            "Score = 1.8\n",
            "Reasoning = The agent misunderstands the task.  Instead of providing information on exporting Zillow/Redfin data to Excel, it offers a link to an unrelated image generation API.  This shows minimal understanding and makes no progress towards the goal. The response is completely off-topic.\n",
            "\n",
            "Score = 2.8\n",
            "Reasoning = The agent's response shows some understanding of user frustration but fails to directly address the 'Unknown API error'.  Offering an unrelated API is off-topic. While empathetic, it doesn't solve the original problem, hindering task completion.  More focus on troubleshooting the error is needed.\n",
            "\n",
            "Score = 2.8\n",
            "Reasoning = The agent's response is polite and acknowledges the task, but it fails to directly address the Discord webhook instructions.  Instead, it offers an unrelated API suggestion. While helpful in a general sense, it shows minimal progress on the specific assigned task.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "comment_gen = pd.read_csv(\"demo_results/agent_comment_gen_dataset/agent_evaluation_results.csv\")\n",
        "\n",
        "split_size = 3\n",
        "\n",
        "task_progression = comment_gen.sort_values(by = 'task_progression', ascending= True).iloc[:split_size][['task_progression', 'task_progression_reasoning']]\n",
        "\n",
        "print(\"Task Progression:\")\n",
        "print()\n",
        "for idx, row in task_progression.iterrows():\n",
        "    print(f\"Score = {row['task_progression']}\")\n",
        "    print(f\"Reasoning = {row['task_progression_reasoning']}\")\n",
        "    print()  # blank line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context Relevancy Analysis:\n",
            "==================================================\n",
            "Score = 4.5\n",
            "Reasoning = The response mentions an API, aligning with the post's topic. However, the provided API link is irrelevant; it's for image generation, not real estate data.  The agent demonstrates some understanding but fails to provide a helpful solution to the user's query regarding Zillow/Redfin data export.  The tone is appropriate.\n",
            "\n",
            "Score = 6.5\n",
            "Reasoning = The response offers a relevant suggestion (using an API) but the provided API link seems unrelated to screenshotting a div.  While the tone is appropriate, the lack of direct relevance to taking a div screenshot lowers the score.  It shows some understanding but falls short of a complete solution.\n",
            "\n",
            "Score = 7.2\n",
            "Reasoning = The response offers a relevant solution by suggesting an alternative API.  The tone is empathetic and helpful. However, it lacks explicit acknowledgment of the 'unknown API error,' focusing instead on a presumed GIF upscaling context.  More direct problem-solving would improve the score.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Context Relevancy Analysis\n",
        "context_relevancy = comment_gen.sort_values(by='context_relevancy', ascending=True).iloc[:3][['context_relevancy', 'context_relevancy_reasoning']]\n",
        "\n",
        "print(\"Context Relevancy Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "for idx, row in context_relevancy.iterrows():\n",
        "    print(f\"Score = {row['context_relevancy']}\")\n",
        "    print(f\"Reasoning = {row['context_relevancy_reasoning']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Role Adherence Analysis:\n",
            "==================================================\n",
            "Score = 4.5\n",
            "Reasoning = The agent fails to provide relevant information for exporting Zillow/Redfin data to Excel.  The provided API link is unrelated to real estate data. The response is off-topic and doesn't fulfill the task.  There are no tool calls, further indicating a failure to address the prompt.\n",
            "\n",
            "Score = 4.7\n",
            "Reasoning = The agent fails to provide relevant information to answer the questions.  Instead of recommending coffee shops, it suggests an irrelevant API for each prompt. This demonstrates a significant deviation from the task, focusing on unrelated tools rather than addressing the core questions. The responses are inconsistent with an agent's expected role.\n",
            "\n",
            "Score = 6.8\n",
            "Reasoning = The agent offers a solution (external API) instead of directly addressing the 'unknown API error'. While empathetic, it deviates from simply commenting on the post.  No tool calls were made, which is consistent with the lack of specified tools. The response is partially relevant to the post's topic but lacks analytical depth expected from a purely commenting agent.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Role Adherence Analysis\n",
        "role_adherence = comment_gen.sort_values(by='role_adherence', ascending=True).iloc[:3][['role_adherence', 'role_adherence_reasoning']]\n",
        "\n",
        "print(\"Role Adherence Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "for idx, row in role_adherence.iterrows():\n",
        "    print(f\"Score = {row['role_adherence']}\")\n",
        "    print(f\"Reasoning = {row['role_adherence_reasoning']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "NOVAPILOT AGENT ANALYSIS - RECOMMEND IMPROVEMENTS\n",
            "============================================================\n",
            "This function runs the complete analysis pipeline equivalent to\n",
            "running the entire complete_analysis_demo.ipynb notebook.\n",
            "============================================================\n",
            "Setup complete! Log file: log/analysis_log_20250927_034313.txt\n",
            "Agent document loaded: 8492 characters\n",
            "Found 5 dataset directories to process:\n",
            "  - email_gen_send_dataset\n",
            "  - agent_comment_gen_dataset\n",
            "  - post_validation_dataset\n",
            "  - agent_query_gen_dataset\n",
            "  - tavily_search_results_dataset\n",
            "\n",
            "Processing email_gen_send_dataset...\n",
            "  Processing CSV: agent_evaluation_results.csv\n",
            "    Making Gemini call for scorer: task_progression\n",
            "    Making Gemini call for scorer: context_relevancy\n",
            "    Making Gemini call for scorer: role_adherence\n",
            "    Making Gemini call for scorer: tool_relevancy\n",
            "    Making Gemini call for scorer: parameter_correctness\n",
            "    Making summary call for email_gen_send_dataset\n",
            "\n",
            "Processing agent_comment_gen_dataset...\n",
            "  Processing CSV: agent_evaluation_results.csv\n",
            "    Making Gemini call for scorer: task_progression\n",
            "    Making Gemini call for scorer: context_relevancy\n",
            "    Making Gemini call for scorer: role_adherence\n",
            "    Making Gemini call for scorer: tool_relevancy\n",
            "    Making Gemini call for scorer: parameter_correctness\n",
            "    Making summary call for agent_comment_gen_dataset\n",
            "\n",
            "Processing post_validation_dataset...\n",
            "  Processing CSV: agent_evaluation_results.csv\n",
            "    Making Gemini call for scorer: task_progression\n",
            "    Making Gemini call for scorer: context_relevancy\n",
            "    Making Gemini call for scorer: role_adherence\n",
            "    Making Gemini call for scorer: tool_relevancy\n",
            "    Making Gemini call for scorer: parameter_correctness\n",
            "    Making summary call for post_validation_dataset\n",
            "\n",
            "Processing agent_query_gen_dataset...\n",
            "  Processing CSV: agent_evaluation_results.csv\n",
            "    Making Gemini call for scorer: task_progression\n",
            "    Making Gemini call for scorer: context_relevancy\n",
            "    Making Gemini call for scorer: role_adherence\n",
            "    Making Gemini call for scorer: tool_relevancy\n",
            "    Making Gemini call for scorer: parameter_correctness\n",
            "    Making summary call for agent_query_gen_dataset\n",
            "\n",
            "Processing tavily_search_results_dataset...\n",
            "  Processing CSV: agent_evaluation_results.csv\n",
            "    Making Gemini call for scorer: task_progression\n",
            "    Making Gemini call for scorer: context_relevancy\n",
            "    Making Gemini call for scorer: role_adherence\n",
            "    Making Gemini call for scorer: tool_relevancy\n",
            "    Making Gemini call for scorer: parameter_correctness\n",
            "    Making summary call for tavily_search_results_dataset\n",
            "\n",
            "Completed processing 5 datasets.\n",
            "\n",
            "Making final comprehensive analysis call...\n",
            "Final analysis completed and logged!\n",
            "All responses have been logged to: log/analysis_log_20250927_034313.txt\n",
            "\n",
            "==================================================\n",
            "ANALYSIS COMPLETE!\n",
            "==================================================\n",
            "Log file location: log/analysis_log_20250927_034313.txt\n",
            "Total datasets processed: 5\n",
            "Total summaries generated: 5\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from novapilot_utils import recommend_improvements\n",
        "\n",
        "# Advanced usage with custom parameters\n",
        "final_analysis, summaries, log_file = recommend_improvements(\n",
        "    demo_results_dir=\"demo_results/\",\n",
        "    agent_doc_path=\"reddit_agent.md\",\n",
        "    log_dir=\"log\",\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the analysis of the agent's workflow and the part-wise scorer feedback, the agent is experiencing a cascading failure that originates at the very beginning of its core logic. The initial, critical failure in query generation poisons the entire downstream process, leading to failures in every subsequent step.\n",
            "\n",
            "The root cause is the `search_agent`'s complete misinterpretation of its task. Instead of generating relevant search queries based on the provided API's title and description, it creates queries for entirely unrelated topics. This single point of failure guarantees that the rest of the workflow cannot succeed:\n",
            "\n",
            "1.  **Irrelevant Queries** (`agent_query_gen_dataset`) lead to...\n",
            "2.  **Irrelevant Search Results** from Tavily (`tavily_search_results_dataset`), which also appears to have a separate implementation bug.\n",
            "3.  **Zero Valid Posts**, as the irrelevant search results are correctly filtered out by the `post_validation` step, which then unhelpfully reports that nothing was processed (`post_validation_dataset`).\n",
            "4.  **Nonsensical Comments**, because if any post were to slip through, the `content_generation_agent` would be trying to connect a completely unrelated API to an unrelated Reddit post, resulting in off-topic and unhelpful comments (`agent_comment_gen_dataset`).\n",
            "5.  **Empty and Opaque Reports**, since no valid data (post-comment pairs) was ever generated, the final email step has nothing meaningful to report (`email_gen_send_dataset`).\n",
            "\n",
            "### Suggested Fixes:\n",
            "\n",
            "*   **fix_1: Overhaul the Query Generation Prompt.** The primary point of failure is the `search_agent`. The prompt being sent to Gemini 2.5 Pro for query generation is critically flawed. It must be re-engineered to be highly directive, forcing the model to ground its output *exclusively* in the provided API title and description. Use techniques like few-shot examples in the prompt, or a system message that explicitly forbids inventing unrelated topics (e.g., \"You are an assistant that generates search queries for Reddit. You will be given an API's name and description. Your task is to generate 5 queries that a user looking for a solution provided by THIS SPECIFIC API might search for. Do not create queries about any other topic.\").\n",
            "\n",
            "*   **fix_2: Debug the Tavily Tool Integration.** The `tavily_search_results_dataset` analysis points to a \"Missing required fields\" error, which is a code-level bug. The developer needs to investigate the LangChain integration and the agent's call to the Tavily tool. Ensure that the agent's code is correctly formatting the request and providing all necessary parameters to the Tavily API wrapper. This is a separate, technical bug that needs to be fixed alongside the logical failures.\n",
            "\n",
            "*   **fix_3: Enhance Context and Logging in the Post Validation Step.** While the `post_validation` step is likely functioning correctly by rejecting irrelevant posts, its output is useless for debugging. This step should be modified to provide context. Instead of just returning `{\"processed\": 0}`, it should report *why* nothing was validated. For example: `\"processed\": 0, \"reason\": \"No valid posts found from 20 initial URLs.\", \"rejection_summary\": {\"archived\": 15, \"nsfw\": 3, \"used_subreddit\": 2}`. This makes it clear whether the issue is a lack of input or overly strict filtering.\n",
            "\n",
            "*   **fix_4: Strengthen the Comment Generation Prompt with Guardrails.** Once the upstream issues are resolved, the `content_generation_agent`'s prompt should be improved. It currently generates irrelevant and overly promotional content. The prompt needs to be updated to include strict constraints, such as: 1) First, summarize the user's problem in the Reddit post. 2) Second, explain in one sentence how the provided API can solve that specific problem. 3) Third, combine these into a short, helpful, non-promotional comment that naturally includes the API link. This ensures the generated comment is always relevant and helpful.\n",
            "\n",
            "*   **fix_5: Implement Data-Driven Report Generation.** The final `email_gen_send` step fails because it lacks data. The code should be made more robust to handle a \"no results\" scenario gracefully. It should generate a different report/email stating that the run completed but found no suitable posts, including the API it attempted to use. This provides a clear status update instead of an opaque, empty email. The unprofessional tone (emojis, cryptic subjects) should also be addressed by using a more professional and standardized email template.\n"
          ]
        }
      ],
      "source": [
        "print(final_analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
