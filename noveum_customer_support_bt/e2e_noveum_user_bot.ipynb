{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Upload Dataset with Proper Environment Loading\n",
    "!cd /Users/mramanindia/work/NovaEval/noveum_customer_support_bt && source .env && python upload_dataset.py --dataset-json split_datasets/agent.rag_evaluation_metrics_dataset.json --item-type conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ff8d0",
   "metadata": {},
   "source": [
    "# Noveum AI Agent with RAG + Web Search\n",
    "\n",
    "An intelligent conversational agent that dynamically routes queries between **RAG (Retrieval-Augmented Generation)** for Noveum.ai-specific information and **Web Search** for external knowledge, providing comprehensive answers with full observability.\n",
    "\n",
    "## üöÄ What This Agent Does\n",
    "\n",
    "### Core Functionality\n",
    "- **Intelligent Query Routing**: Automatically determines whether to use RAG or Web Search based on query content\n",
    "- **Dual Knowledge Sources**: \n",
    "  - **RAG Mode**: Answers questions about Noveum.ai platform using scraped documentation\n",
    "  - **Web Search Mode**: Handles external queries using real-time web search\n",
    "- **Comprehensive Tracing**: Full observability with detailed metrics and performance tracking\n",
    "- **Modular Architecture**: Clean separation of concerns for easy maintenance and extension\n",
    "\n",
    "### Key Capabilities\n",
    "- üß† **Document Intelligence**: Scrapes and indexes Noveum.ai website content for semantic search\n",
    "- üåê **Real-time Web Search**: Uses DuckDuckGo for current events and external knowledge\n",
    "- üéØ **Smart Classification**: LLM-powered query routing with keyword fallback\n",
    "- üìä **Performance Monitoring**: Detailed metrics on response quality, latency, and token usage\n",
    "- üîÑ **Scalable Design**: Easy to extend with new data sources or routing logic\n",
    "\n",
    "## üìã Prerequisites & Requirements\n",
    "\n",
    "### Required Environment Variables\n",
    "```bash\n",
    "NOVEUM_API_KEY=your_noveum_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "```\n",
    "\n",
    "### Required Python Packages\n",
    "- `requests` - HTTP requests for web scraping\n",
    "- `beautifulsoup4` - HTML parsing\n",
    "- `trafilatura` - Advanced text extraction\n",
    "- `langchain` - LLM framework and vector operations\n",
    "- `langchain-openai` - OpenAI integration\n",
    "- `langchain-community` - Community tools (FAISS, DuckDuckGo)\n",
    "- `noveum-trace` - Observability and tracing\n",
    "- `python-dotenv` - Environment variable management\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.8+\n",
    "- Internet connection for web scraping and API calls\n",
    "- ~500MB disk space for vector store and scraped data\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "\n",
    "### 1. **Website Scraper** (`NoveumWebsiteScraper`)\n",
    "- Recursively scrapes noveum.ai website and sub-pages\n",
    "- Extracts clean text content using trafilatura\n",
    "- Discovers internal links automatically\n",
    "- Saves scraped data to JSON for persistence\n",
    "\n",
    "### 2. **RAG System** (`NoveumRAGSystem`)\n",
    "- Loads scraped documents and creates vector embeddings\n",
    "- Uses FAISS for fast similarity search\n",
    "- Generates context-aware responses using OpenAI GPT-4o-mini\n",
    "- Tracks retrieval effectiveness and response quality\n",
    "\n",
    "### 3. **Web Search System** (`NoveumWebSearchSystem`)\n",
    "- Integrates DuckDuckGo search for external queries\n",
    "- Synthesizes information from multiple web sources\n",
    "- Handles real-time information and current events\n",
    "- Formats search results into coherent responses\n",
    "\n",
    "### 4. **Query Router** (`NoveumQueryRouter`)\n",
    "- **Keyword-based classification**: Matches queries against predefined keyword lists\n",
    "- **LLM-based classification**: Uses GPT-4o-mini for complex query analysis\n",
    "- **Confidence scoring**: Evaluates routing decision quality\n",
    "- **Fallback handling**: Defaults to Web Search for ambiguous queries\n",
    "\n",
    "### 5. **Main Agent** (`NoveumAIAgent`)\n",
    "- Orchestrates all components\n",
    "- Manages system initialization and data loading\n",
    "- Provides unified interface for query processing\n",
    "- Handles error recovery and response formatting\n",
    "\n",
    "## üéØ How to Use\n",
    "\n",
    "### Quick Start\n",
    "```python\n",
    "# 1. Initialize the system (first time only)\n",
    "noveum_agent.initialize_system(force_scrape=True)\n",
    "\n",
    "# 2. Ask questions\n",
    "response = noveum_agent.process_query(\"What is Noveum and what does it do?\")\n",
    "noveum_agent.display_response(response)\n",
    "\n",
    "# 3. Or use convenience function\n",
    "ask_question(\"How do I integrate Noveum Trace?\")\n",
    "```\n",
    "\n",
    "### Advanced Usage\n",
    "```python\n",
    "# Run full demo with 20 test queries\n",
    "demo_noveum_agent()\n",
    "\n",
    "# Process queries programmatically\n",
    "response = noveum_agent.process_query(\"What are the latest AI news?\")\n",
    "print(f\"Mode: {response['mode']}\")\n",
    "print(f\"Answer: {response['answer']}\")\n",
    "print(f\"Sources: {response['sources']}\")\n",
    "```\n",
    "\n",
    "### Query Types\n",
    "\n",
    "#### RAG Queries (Noveum-specific)\n",
    "- \"What is Noveum and what does it do?\"\n",
    "- \"How do I integrate Noveum Trace?\"\n",
    "- \"What are Noveum's pricing plans?\"\n",
    "- \"What features does Noveum Trace offer?\"\n",
    "- \"How do I set up observability with Noveum?\"\n",
    "\n",
    "#### Web Search Queries (External knowledge)\n",
    "- \"What are the latest AI news today?\"\n",
    "- \"What's the weather like today?\"\n",
    "- \"Tell me about recent developments in machine learning\"\n",
    "- \"What are the current trends in observability tools?\"\n",
    "- \"What happened in tech news this week?\"\n",
    "\n",
    "## üìä Observability & Monitoring\n",
    "\n",
    "### Traced Operations\n",
    "- **System Initialization**: Website scraping and vector store creation\n",
    "- **Query Processing**: End-to-end query handling with performance metrics\n",
    "- **RAG Operations**: Document retrieval, context generation, and response creation\n",
    "- **Web Search Operations**: Search execution, result synthesis, and response generation\n",
    "- **Query Routing**: Classification decision making and confidence scoring\n",
    "\n",
    "### Key Metrics Tracked\n",
    "- **Performance**: Response latency, processing time, token usage\n",
    "- **Quality**: Response length, source diversity, context utilization\n",
    "- **Routing**: Classification confidence, keyword scores, decision rationale\n",
    "- **Model Usage**: Token consumption, cost estimation, efficiency scores\n",
    "- **Retrieval**: Document relevance, context quality, source effectiveness\n",
    "\n",
    "### Noveum Trace Integration\n",
    "- All operations are automatically traced with detailed spans\n",
    "- Comprehensive attribute tracking for debugging and optimization\n",
    "- Real-time monitoring through Noveum.ai dashboard\n",
    "- Export capabilities for further analysis\n",
    "\n",
    "## üîß Configuration\n",
    "\n",
    "### Default Settings\n",
    "```python\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Customization Options\n",
    "- **Scraping**: Adjust `max_pages_to_scrape` for more/less content\n",
    "- **RAG**: Modify `chunk_size` and `chunk_overlap` for different text splitting\n",
    "- **Search**: Change `max_search_results` for more/fewer sources\n",
    "- **Routing**: Add keywords to `rag_keywords` or `web_keywords` lists\n",
    "\n",
    "## üö® Error Handling\n",
    "\n",
    "### Common Issues\n",
    "- **API Key Missing**: Ensure `NOVEUM_API_KEY` and `OPENAI_API_KEY` are set\n",
    "- **Network Errors**: Check internet connection for scraping and API calls\n",
    "- **Vector Store Issues**: Delete `noveum_vectorstore` folder to regenerate\n",
    "- **Scraping Failures**: Set `force_scrape=True` to re-scrape website\n",
    "\n",
    "### Recovery Strategies\n",
    "- Automatic fallback to Web Search for RAG failures\n",
    "- Graceful error handling with informative messages\n",
    "- Retry mechanisms for transient network issues\n",
    "- Detailed error logging for debugging\n",
    "\n",
    "## üîÑ Maintenance\n",
    "\n",
    "### Regular Tasks\n",
    "- **Update Scraped Content**: Run with `force_scrape=True` periodically\n",
    "- **Monitor Performance**: Check Noveum Trace dashboard for metrics\n",
    "- **Review Routing**: Analyze query classification accuracy\n",
    "- **Update Keywords**: Add new terms to routing keyword lists\n",
    "\n",
    "### Scaling Considerations\n",
    "- **Vector Store**: Can be shared across multiple agent instances\n",
    "- **Scraped Data**: JSON file can be versioned and distributed\n",
    "- **API Limits**: Monitor OpenAI token usage and costs\n",
    "- **Performance**: Consider caching for frequently asked questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r ./noveum_agent_requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7a810bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "\n",
    "# LangChain ecosystem\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Noveum Trace integration\n",
    "import noveum_trace\n",
    "from noveum_trace.context_managers import trace_operation, trace_agent\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed. Environment variables will be read from system only.\")\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## set openai api key\n",
    "## set gemini api key\n",
    "## set noveum api key\n",
    "## set environment\n",
    "## set project'\n",
    "\n",
    "# These are required for the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noveum Trace initialized and configuration loaded!\n",
      "üîß Configuration: {'noveum_base_url': 'https://noveum.ai', 'max_pages_to_scrape': 50, 'chunk_size': 1000, 'chunk_overlap': 200, 'max_search_results': 5, 'rag_threshold': 0.7, 'noveum_docs_file': 'noveum_docs.json', 'vector_store_path': 'noveum_vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Noveum Trace Integration & Configuration\n",
    "# Initialize the Noveum Trace SDK\n",
    "noveum_trace.init(\n",
    "    project=\"customer_support_agent\",\n",
    "    api_key=os.getenv(\"NOVEUM_API_KEY\"),\n",
    "    environment=\"dev-aman\",\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,  # Similarity threshold for RAG retrieval\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize web search tool\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "print(\"‚úÖ Noveum Trace initialized and configuration loaded!\")\n",
    "print(f\"üîß Configuration: {CONFIG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c765c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Website scraper initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Website Scraper - Extract content from noveum.ai and sub-URLs\n",
    "class NoveumWebsiteScraper:\n",
    "    def __init__(self, base_url: str, max_pages: int = 50):\n",
    "        self.base_url = base_url\n",
    "        self.max_pages = max_pages\n",
    "        self.scraped_urls = set()\n",
    "        self.scraped_content = []\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "    \n",
    "    def is_valid_url(self, url: str) -> bool:\n",
    "        \"\"\"Check if URL is valid and belongs to noveum.ai domain\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            return (\n",
    "                parsed.netloc in ['noveum.ai', 'www.noveum.ai'] and\n",
    "                not any(ext in url.lower() for ext in ['.pdf', '.jpg', '.png', '.gif', '.css', '.js', '.xml', '.txt']) and\n",
    "                '#' not in url\n",
    "            )\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def extract_text_content(self, html_content: str, url: str) -> str:\n",
    "        \"\"\"Extract clean text content from HTML\"\"\"\n",
    "        try:\n",
    "            # Use trafilatura for better text extraction\n",
    "            extracted = trafilatura.extract(html_content)\n",
    "            if extracted:\n",
    "                return extracted.strip()\n",
    "            \n",
    "            # Fallback to BeautifulSoup\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Get text and clean up\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {url}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def find_internal_links(self, html_content: str, current_url: str) -> List[str]:\n",
    "        \"\"\"Find all internal links from the current page\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            links = []\n",
    "            \n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                \n",
    "                if self.is_valid_url(full_url) and full_url not in self.scraped_urls:\n",
    "                    links.append(full_url)\n",
    "            \n",
    "            return links\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding links in {current_url}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def scrape_page(self, url: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Scrape a single page and return content\"\"\"\n",
    "        try:\n",
    "            print(f\"üîç Scraping: {url}\")\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Extract text content\n",
    "            text_content = self.extract_text_content(response.text, url)\n",
    "            \n",
    "            if not text_content or len(text_content) < 100:  # Skip pages with too little content\n",
    "                print(f\"‚ö†Ô∏è  Skipping {url} - insufficient content\")\n",
    "                return None\n",
    "            \n",
    "            # Find internal links\n",
    "            internal_links = self.find_internal_links(response.text, url)\n",
    "            \n",
    "            page_data = {\n",
    "                \"url\": url,\n",
    "                \"title\": self.extract_title(response.text),\n",
    "                \"content\": text_content,\n",
    "                \"content_length\": len(text_content),\n",
    "                \"internal_links\": internal_links,\n",
    "                \"scraped_at\": time.time()\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Scraped {url} - {len(text_content)} chars, {len(internal_links)} internal links\")\n",
    "            return page_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error scraping {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_title(self, html_content: str) -> str:\n",
    "        \"\"\"Extract page title\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            title_tag = soup.find('title')\n",
    "            return title_tag.get_text().strip() if title_tag else \"Untitled\"\n",
    "        except:\n",
    "            return \"Untitled\"\n",
    "    \n",
    "    def scrape_website(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Main scraping function - scrape noveum.ai recursively\"\"\"\n",
    "        print(f\"üöÄ Starting to scrape {self.base_url}\")\n",
    "        \n",
    "        urls_to_scrape = [self.base_url]\n",
    "        self.scraped_urls.add(self.base_url)\n",
    "        \n",
    "        with trace_operation(\"noveum_website_scraping\") as scrape_span:\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.base_url\": self.base_url,\n",
    "                \"scraper.max_pages\": self.max_pages,\n",
    "                \"input_query\": f\"Scrape website: {self.base_url}\",\n",
    "                \"output_response\": f\"Scraping completed: {len(self.scraped_content)} pages scraped, {sum(page['content_length'] for page in self.scraped_content)} total characters extracted\"\n",
    "            })\n",
    "            \n",
    "            while urls_to_scrape and len(self.scraped_content) < self.max_pages:\n",
    "                current_url = urls_to_scrape.pop(0)\n",
    "                \n",
    "                # Scrape the current page\n",
    "                page_data = self.scrape_page(current_url)\n",
    "                \n",
    "                if page_data:\n",
    "                    self.scraped_content.append(page_data)\n",
    "                    \n",
    "                    # Add new internal links to the queue\n",
    "                    for link in page_data[\"internal_links\"]:\n",
    "                        if link not in self.scraped_urls and len(urls_to_scrape) < 100:  # Prevent infinite loops\n",
    "                            urls_to_scrape.append(link)\n",
    "                            self.scraped_urls.add(link)\n",
    "                    \n",
    "                    # Add page data to span\n",
    "                    scrape_span.add_event(\"page_scraped\", {\n",
    "                        \"input_query\": f\"Scrape page: {current_url}\",\n",
    "                        \"output_response\": f\"Page scraped successfully: {page_data['content_length']} characters, {len(page_data['internal_links'])} internal links found\",\n",
    "                        \"url\": current_url,\n",
    "                        \"content_length\": page_data[\"content_length\"],\n",
    "                        \"internal_links_found\": len(page_data[\"internal_links\"])\n",
    "                    })\n",
    "                \n",
    "                # Small delay to be respectful\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            # Final metrics\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.pages_scraped\": len(self.scraped_content),\n",
    "                \"scraper.total_urls_found\": len(self.scraped_urls),\n",
    "                \"scraper.total_content_length\": sum(page[\"content_length\"] for page in self.scraped_content)\n",
    "            })\n",
    "        \n",
    "        print(f\"‚úÖ Scraping complete! Scraped {len(self.scraped_content)} pages\")\n",
    "        return self.scraped_content\n",
    "    \n",
    "    def save_to_json(self, filename: str) -> None:\n",
    "        \"\"\"Save scraped content to JSON file\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.scraped_content, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ Saved scraped content to {filename}\")\n",
    "\n",
    "# Initialize scraper\n",
    "scraper = NoveumWebsiteScraper(CONFIG[\"noveum_base_url\"], CONFIG[\"max_pages_to_scrape\"])\n",
    "print(\"‚úÖ Website scraper initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d0e2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: RAG System - Vector search and retrieval over scraped content\n",
    "class NoveumRAGSystem:\n",
    "    def __init__(self, embeddings, llm, config):\n",
    "        self.embeddings = embeddings\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        self.vectorstore = None\n",
    "        self.documents = []\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=config[\"chunk_size\"],\n",
    "            chunk_overlap=config[\"chunk_overlap\"]\n",
    "        )\n",
    "    \n",
    "    def load_documents_from_json(self, json_file: str) -> List[Document]:\n",
    "        \"\"\"Load documents from scraped JSON file\"\"\"\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                scraped_data = json.load(f)\n",
    "            \n",
    "            documents = []\n",
    "            for page in scraped_data:\n",
    "                # Create document from page content\n",
    "                doc = Document(\n",
    "                    page_content=page[\"content\"],\n",
    "                    metadata={\n",
    "                        \"url\": page[\"url\"],\n",
    "                        \"title\": page[\"title\"],\n",
    "                        \"content_length\": page[\"content_length\"],\n",
    "                        \"scraped_at\": page[\"scraped_at\"]\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {len(documents)} documents from {json_file}\")\n",
    "            return documents\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå File {json_file} not found. Please run the scraper first.\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_vectorstore(self, documents: List[Document]) -> None:\n",
    "        \"\"\"Create FAISS vector store from documents\"\"\"\n",
    "        if not documents:\n",
    "            print(\"‚ùå No documents to create vector store\")\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Creating vector store...\")\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        split_docs = self.text_splitter.split_documents(documents)\n",
    "        print(f\"üìÑ Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vectorstore = FAISS.from_documents(split_docs, self.embeddings)\n",
    "        \n",
    "        # Save vector store\n",
    "        self.vectorstore.save_local(self.config[\"vector_store_path\"])\n",
    "        print(f\"üíæ Vector store saved to {self.config['vector_store_path']}\")\n",
    "    \n",
    "    def load_vectorstore(self) -> bool:\n",
    "        \"\"\"Load existing vector store from disk\"\"\"\n",
    "        try:\n",
    "            self.vectorstore = FAISS.load_local(\n",
    "                self.config[\"vector_store_path\"], \n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            print(f\"‚úÖ Loaded existing vector store from {self.config['vector_store_path']}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading vector store: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_relevant_docs(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Search for relevant documents using similarity search\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            print(\"‚ùå Vector store not initialized\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Perform similarity search\n",
    "            docs = self.vectorstore.similarity_search(query, k=k)\n",
    "            \n",
    "            # Filter by similarity threshold if needed\n",
    "            # Note: FAISS doesn't return scores by default, but we can add that if needed\n",
    "            \n",
    "            print(f\"üîç Found {len(docs)} relevant documents for query: '{query}'\")\n",
    "            return docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error searching documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def retrieve_context(self, query: str, max_docs: int = 5) -> str:\n",
    "        \"\"\"Retrieve and format context for the query\"\"\"\n",
    "        relevant_docs = self.search_relevant_docs(query, max_docs)\n",
    "        \n",
    "        if not relevant_docs:\n",
    "            return \"No relevant information found in Noveum documentation.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            context_parts.append(f\"Source {i} ({doc.metadata.get('url', 'Unknown URL')}):\\n{doc.page_content[:500]}...\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_rag_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using RAG\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"rag_agent\",\n",
    "            operation=\"llm-rag\",\n",
    "            capabilities=[\"document_retrieval\", \"context_generation\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_rag_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as rag_span:\n",
    "            \n",
    "            # Retrieve relevant context\n",
    "            context = self.retrieve_context(query, CONFIG[\"max_search_results\"])\n",
    "            \n",
    "            # Create prompt for RAG\n",
    "            rag_prompt = f\"\"\"You are a helpful assistant for Noveum.ai. Answer the user's question based on the provided context from Noveum's documentation.\n",
    "\n",
    "Context from Noveum documentation:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based primarily on the provided context\n",
    "2. If the context doesn't contain enough information, say so clearly\n",
    "3. Be specific and cite sources when possible\n",
    "4. Keep responses concise but informative\n",
    "5. If the question is not related to Noveum, politely redirect to ask about Noveum\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "            \n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(rag_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                if response.content:\n",
    "                    answer = response.content\n",
    "                else:\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(rag_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track retrieval, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"rag_evaluation_metrics\",\n",
    "                capabilities=[\"retrieval_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as rag_node:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer)\n",
    "                sources_count = len(context.split(\"Source\")) - 1 if \"Source\" in context else 0\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                rag_node.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_evaluation_query\",\n",
    "                    \n",
    "                    # Retrieval metrics\n",
    "                    \"retrieval.context_retrieved\": f\"Context: {context[:300]}{'...' if len(context) > 300 else ''}\",\n",
    "                    \"retrieval.context_length\": context_length,\n",
    "                    \"retrieval.sources_count\": sources_count,\n",
    "                    \"retrieval.context_quality\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"retrieval.effectiveness\": sources_count / 5.0,  # Normalized to max expected sources\n",
    "                    \"retrieval.context_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": rag_prompt,\n",
    "                    \"prompt.prompt_length\": len(rag_prompt),\n",
    "                    \"prompt.context_injection\": f\"Context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"rag_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 100 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 200 and sources_count > 2 else \"medium\" if answer_length > 100 else \"low\",\n",
    "                    \"response.source_citation\": sources_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.retrieval_effectiveness\": sources_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 150 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": sources_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 200 and sources_count > 2 and context_length > 500 else \"medium\" if answer_length > 100 and sources_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # RAG-specific metrics\n",
    "                    \"rag.retrieval_strategy\": \"semantic_similarity\",\n",
    "                    \"rag.vector_search_results\": sources_count,\n",
    "                    \"rag.context_synthesis\": \"multi_source\" if sources_count > 1 else \"single_source\",\n",
    "                    \"rag.document_coverage\": sources_count / 5.0,  # Normalized coverage\n",
    "                    \"rag.information_density\": answer_length / context_length if context_length > 0 else 0\n",
    "                })\n",
    "\n",
    "            # Set main RAG span attributes (simplified)\n",
    "            rag_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"rag_query\",\n",
    "                \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                \"rag.context_length\": context_length,\n",
    "                \"rag.sources_count\": sources_count,\n",
    "                \"rag.answer_length\": answer_length,\n",
    "                \"rag.mode\": \"retrieval_augmented_generation\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"RAG\",\n",
    "                \"sources\": [doc.metadata.get('url', 'Unknown') for doc in self.search_relevant_docs(query, CONFIG[\"max_search_results\"])],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = NoveumRAGSystem(embeddings, llm, CONFIG)\n",
    "print(\"‚úÖ RAG system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09823cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Web search system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Web Search Integration - DuckDuckGo search for external queries\n",
    "class NoveumWebSearchSystem:\n",
    "    def __init__(self, web_search_tool, llm, config):\n",
    "        self.web_search = web_search_tool\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "    \n",
    "    def search_web(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Perform web search and return formatted results\"\"\"\n",
    "        try:\n",
    "            # Perform web search\n",
    "            search_results = self.web_search.run(query)\n",
    "            \n",
    "            # Parse results (DuckDuckGo returns a string, need to parse it)\n",
    "            results = []\n",
    "            if isinstance(search_results, str):\n",
    "                # Split by lines and parse each result\n",
    "                lines = search_results.split('\\n')\n",
    "                for i, line in enumerate(lines[:max_results]):\n",
    "                    if line.strip():\n",
    "                        results.append({\n",
    "                            \"title\": f\"Search Result {i+1}\",\n",
    "                            \"snippet\": line.strip(),\n",
    "                            \"url\": f\"https://duckduckgo.com/?q={query.replace(' ', '+')}\"\n",
    "                        })\n",
    "            else:\n",
    "                # If it's already a list/dict format\n",
    "                results = search_results[:max_results]\n",
    "            \n",
    "            print(f\"üîç Found {len(results)} web search results for: '{query}'\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error performing web search: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def format_search_context(self, search_results: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format search results into context string\"\"\"\n",
    "        if not search_results:\n",
    "            return \"No search results found.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, result in enumerate(search_results, 1):\n",
    "            title = result.get('title', f'Result {i}')\n",
    "            snippet = result.get('snippet', 'No description available')\n",
    "            url = result.get('url', 'No URL available')\n",
    "            \n",
    "            context_parts.append(f\"Source {i} - {title}:\\n{snippet}\\nURL: {url}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_web_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using web search\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"web_search_agent\",\n",
    "            operation=\"web_search_generation\",\n",
    "            capabilities=[\"web_search\", \"content_synthesis\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_web_search_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as web_span:\n",
    "            \n",
    "            # Perform web search\n",
    "            search_results = self.search_web(query, self.config[\"max_search_results\"])\n",
    "            \n",
    "            # Format context\n",
    "            context = self.format_search_context(search_results)\n",
    "            \n",
    "            # Create prompt for web search response\n",
    "            web_prompt = f\"\"\"You are a helpful assistant. Answer the user's question based on the provided web search results.\n",
    "\n",
    "Web Search Results:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based on the provided web search results\n",
    "2. Synthesize information from multiple sources when relevant\n",
    "3. Be informative and accurate\n",
    "4. If the results don't contain enough information, say so clearly\n",
    "5. Keep responses concise but comprehensive\n",
    "6. Cite sources when possible\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(web_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                # Handle response content extraction\n",
    "                if hasattr(response, 'content'):\n",
    "                    # When response is a proper SDK object\n",
    "                    answer = response.content\n",
    "                elif isinstance(response, dict):\n",
    "                    # When response is returned as a plain dict\n",
    "                    answer = response.get('content', '')\n",
    "                else:\n",
    "                    # Fallback to string\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(web_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track web search, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"web_search_evaluation_metrics\",\n",
    "                capabilities=[\"web_search_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                search_results_count = len(search_results)\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer or \"\")\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_evaluation_query\",\n",
    "                    \n",
    "                    # Web search metrics\n",
    "                    \"web_search.results_count\": search_results_count,\n",
    "                    \"web_search.context_length\": context_length,\n",
    "                    \"web_search.context_synthesized\": f\"Context from {search_results_count} web sources\",\n",
    "                    \"web_search.search_effectiveness\": search_results_count / 5.0,  # Normalized to max expected results\n",
    "                    \"web_search.context_quality\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"web_search.source_diversity\": search_results_count,\n",
    "                    \"web_search.information_synthesis\": \"high\" if search_results_count > 3 and answer_length > 200 else \"medium\" if search_results_count > 1 else \"low\",\n",
    "                    \"web_search.external_knowledge_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": web_prompt,\n",
    "                    \"prompt.prompt_length\": len(web_prompt),\n",
    "                    \"prompt.context_injection\": f\"Web context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"web_search_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 150 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 300 and search_results_count > 3 else \"medium\" if answer_length > 150 else \"low\",\n",
    "                    \"response.source_citation\": search_results_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.search_effectiveness\": search_results_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 200 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": search_results_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 300 and search_results_count > 3 and context_length > 800 else \"medium\" if answer_length > 150 and search_results_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Web search specific metrics\n",
    "                    \"web_search.search_strategy\": \"duckduckgo_api\",\n",
    "                    \"web_search.real_time_data\": True,\n",
    "                    \"web_search.external_sources\": search_results_count,\n",
    "                    \"web_search.information_freshness\": \"current\",\n",
    "                    \"web_search.knowledge_synthesis\": \"multi_source\" if search_results_count > 1 else \"single_source\"\n",
    "                })\n",
    "\n",
    "            # Set main Web Search span attributes (simplified)\n",
    "            web_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"web_search_query\",\n",
    "                \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                \"web_search.results_count\": search_results_count,\n",
    "                \"web_search.context_length\": context_length,\n",
    "                \"web_search.response_length\": answer_length,\n",
    "                \"web_search.mode\": \"external_web_search\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"Web Search\",\n",
    "                \"sources\": [result.get('url', 'Unknown') for result in search_results],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize web search system\n",
    "web_search_system = NoveumWebSearchSystem(web_search, llm, CONFIG)\n",
    "print(\"‚úÖ Web search system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d47287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query router initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Query Router - Intelligent decision making between RAG and Web Search\n",
    "class NoveumQueryRouter:\n",
    "    def __init__(self, llm, config):\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        \n",
    "        # Keywords that suggest RAG should be used\n",
    "        self.rag_keywords = [\n",
    "            \"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\",\n",
    "            \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\",\n",
    "            \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\",\n",
    "            \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"\n",
    "        ]\n",
    "        \n",
    "        # Keywords that suggest Web Search should be used\n",
    "        self.web_keywords = [\n",
    "            \"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\",\n",
    "            \"today\", \"yesterday\", \"this week\", \"this month\", \"current\",\n",
    "            \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\",\n",
    "            \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\",\n",
    "            \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"\n",
    "        ]\n",
    "    \n",
    "    def classify_query(self, query: str) -> str:\n",
    "        \"\"\"Classify query to determine whether to use RAG or Web Search\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Check for RAG keywords\n",
    "        rag_score = sum(1 for keyword in self.rag_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for Web Search keywords\n",
    "        web_score = sum(1 for keyword in self.web_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for explicit mentions of Noveum\n",
    "        if \"noveum\" in query_lower:\n",
    "            return \"RAG\"\n",
    "        \n",
    "        # If both scores are 0, use LLM-based classification\n",
    "        if rag_score == 0 and web_score == 0:\n",
    "            return self._llm_classify_query(query)\n",
    "        \n",
    "        # Return the mode with higher score\n",
    "        return \"RAG\" if rag_score >= web_score else \"Web Search\"\n",
    "    \n",
    "    def _llm_classify_query(self, query: str) -> str:\n",
    "        \"\"\"Use LLM to classify query when keyword matching is inconclusive\"\"\"\n",
    "        try:\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "\n",
    "            # Extract model parameters for tracking\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span for classification\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                response = self.llm.invoke(classification_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "            \n",
    "                if hasattr(response, 'content'):\n",
    "                    result = response.content.strip().upper()\n",
    "                else:\n",
    "                    result = str(response).strip().upper()\n",
    "\n",
    "                # Extract token usage for classification\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                \n",
    "                # If still no tokens found, estimate\n",
    "                if total_tokens == 0:\n",
    "                    estimated_prompt_tokens = len(classification_prompt) // 4\n",
    "                    estimated_completion_tokens = len(result) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"classification_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 1.0 else \"medium\" if model_latency < 3.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(result) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(result),\n",
    "                    \"model.response_quality\": \"high\" if len(result) > 10 else \"medium\" if len(result) > 5 else \"low\",\n",
    "                    \"model.output_response\": f\"Classification Result: {result}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Log classification details for debugging\n",
    "            print(f\"üîç LLM Classification - Model: {model_name}, Tokens: {total_tokens}, Result: {result}\")\n",
    "            \n",
    "            if \"RAG\" in result:\n",
    "                return \"RAG\"\n",
    "            elif \"WEB\" in result or \"SEARCH\" in result:\n",
    "                return \"Web Search\"\n",
    "            else:\n",
    "                # Default to Web Search if unclear\n",
    "                return \"Web Search\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in LLM classification: {e}\")\n",
    "            # Default to Web Search on error\n",
    "            return \"Web Search\"\n",
    "    \n",
    "    def route_query(self, query: str) -> Tuple[str, Dict[str, Any]]:\n",
    "        \"\"\"Route query to appropriate system and return response\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"query_router\",\n",
    "            operation=\"query_routing\",\n",
    "            capabilities=[\"query_classification\", \"routing_decision\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_query_router\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as router_span:\n",
    "            \n",
    "            # Define classification prompt for tracing\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "            \n",
    "            # Classify the query\n",
    "            mode = self.classify_query(query)\n",
    "            \n",
    "            # Calculate routing evaluation metrics\n",
    "            query_lower = query.lower()\n",
    "            rag_keywords = [\"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\", \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\", \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\", \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"]\n",
    "            web_keywords = [\"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\", \"today\", \"yesterday\", \"this week\", \"this month\", \"current\", \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\", \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\", \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"]\n",
    "            \n",
    "            rag_score = sum(1 for keyword in rag_keywords if keyword in query_lower)\n",
    "            web_score = sum(1 for keyword in web_keywords if keyword in query_lower)\n",
    "            confidence_score = abs(rag_score - web_score) / max(rag_score + web_score, 1)\n",
    "            \n",
    "            # Other Details Span - Track routing analysis and decision metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"routing_evaluation_metrics\",\n",
    "                capabilities=[\"routing_analysis\", \"decision_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"routing_evaluation_query\",\n",
    "                    \n",
    "                    # Classification metrics\n",
    "                    \"classification.mode\": mode,\n",
    "                    \"classification.rag_keyword_score\": rag_score,\n",
    "                    \"classification.web_keyword_score\": web_score,\n",
    "                    \"classification.confidence_score\": confidence_score,\n",
    "                    \"classification.confidence_level\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"classification.method\": \"llm_based\" if rag_score == 0 and web_score == 0 else \"keyword_based\",\n",
    "                    \n",
    "                    # Query analysis metrics\n",
    "                    \"query.complexity\": \"complex\" if len(query) > 50 else \"medium\" if len(query) > 20 else \"simple\",\n",
    "                    \"query.intent\": \"noveum_specific\" if \"noveum\" in query_lower else \"general_knowledge\" if web_score > rag_score else \"documentation\",\n",
    "                    \"query.keyword_density\": (rag_score + web_score) / len(query.split()),\n",
    "                    \"query.domain_affinity\": \"noveum\" if rag_score > web_score else \"general\" if web_score > rag_score else \"neutral\",\n",
    "                    \n",
    "                    # Routing decision metrics\n",
    "                    \"routing.decision\": f\"Routed to {mode} based on analysis\",\n",
    "                    \"routing.rationale\": f\"RAG score: {rag_score}, Web score: {web_score}, Confidence: {confidence_score:.2f}\",\n",
    "                    \"routing.expected_performance\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"routing.alternative_mode\": \"Web Search\" if mode == \"RAG\" else \"RAG\",\n",
    "                    \"routing.decision_confidence\": confidence_score,\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.routing_accuracy\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"evaluation.keyword_coverage\": (rag_score + web_score) / len(rag_keywords + web_keywords),\n",
    "                    \"evaluation.query_understanding\": \"clear\" if confidence_score > 0.5 else \"ambiguous\" if confidence_score > 0.2 else \"unclear\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Router-specific metrics\n",
    "                    \"router.classification_strategy\": \"hybrid_keyword_llm\",\n",
    "                    \"router.keyword_matching\": \"used\" if rag_score > 0 or web_score > 0 else \"bypassed\",\n",
    "                    \"router.llm_fallback\": \"used\" if rag_score == 0 and web_score == 0 else \"not_needed\",\n",
    "                    \"router.decision_time\": \"instant\" if rag_score > 0 or web_score > 0 else \"llm_required\",\n",
    "                    \"output_response\": f\"Routing Decision: {mode} (Confidence: {confidence_score:.2f})\"\n",
    "                })\n",
    "\n",
    "            # Set main router span attributes (simplified)\n",
    "            router_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"routing_query\",\n",
    "                \"output_response\": f\"Routed to {mode} for query processing\",\n",
    "                \"router.classification\": mode,\n",
    "                \"router.confidence_score\": confidence_score,\n",
    "                \"router.rag_keyword_score\": rag_score,\n",
    "                \"router.web_keyword_score\": web_score,\n",
    "                \"router.mode\": \"intelligent_routing\"\n",
    "            })\n",
    "            \n",
    "            # Route to appropriate system\n",
    "            if mode == \"RAG\":\n",
    "                print(f\"üß† Routing to RAG system for: '{query}'\")\n",
    "                response = rag_system.generate_rag_response(query)\n",
    "            else:\n",
    "                print(f\"üåê Routing to Web Search for: '{query}'\")\n",
    "                response = web_search_system.generate_web_response(query)\n",
    "            \n",
    "            return mode, response\n",
    "\n",
    "# Initialize query router\n",
    "query_router = NoveumQueryRouter(llm, CONFIG)\n",
    "print(\"‚úÖ Query router initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noveum AI Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Executor - Orchestrates the complete agent workflow\n",
    "class NoveumAIAgent:\n",
    "    def __init__(self, scraper, rag_system, web_search_system, query_router, config):\n",
    "        self.scraper = scraper\n",
    "        self.rag_system = rag_system\n",
    "        self.web_search_system = web_search_system\n",
    "        self.query_router = query_router\n",
    "        self.config = config\n",
    "        self.is_initialized = False\n",
    "    \n",
    "    def initialize_system(self, force_scrape: bool = False) -> bool:\n",
    "        \"\"\"Initialize the system by setting up RAG with scraped data\"\"\"\n",
    "        print(\"üöÄ Initializing Noveum AI Agent...\")\n",
    "        \n",
    "        with trace_operation(\"system_initialization\") as init_span:\n",
    "            init_span.set_attributes({\n",
    "                \"system.force_scrape\": force_scrape,\n",
    "                \"system.config\": self.config,\n",
    "                \"input_query\": f\"Initialize system with force_scrape={force_scrape}\",\n",
    "                \"output_response\": \"System initialization: RAG system loaded, vector store ready, agent operational\"\n",
    "            })\n",
    "            \n",
    "            # Check if we need to scrape or if data already exists\n",
    "            if force_scrape or not os.path.exists(self.config[\"noveum_docs_file\"]):\n",
    "                print(\"üì• Scraping Noveum website...\")\n",
    "                \n",
    "                # Scrape the website\n",
    "                scraped_data = self.scraper.scrape_website()\n",
    "                \n",
    "                if not scraped_data:\n",
    "                    print(\"‚ùå Failed to scrape website data\")\n",
    "                    return False\n",
    "                \n",
    "                # Save scraped data\n",
    "                self.scraper.save_to_json(self.config[\"noveum_docs_file\"])\n",
    "                \n",
    "                init_span.add_event(\"website_scraped\", {\n",
    "                    \"input_query\": f\"Scrape website: {self.config['noveum_base_url']}\",\n",
    "                    \"output_response\": f\"Website scraping completed: {len(scraped_data)} pages scraped, {sum(page['content_length'] for page in scraped_data)} total characters extracted for RAG system\",\n",
    "                    \"pages_scraped\": len(scraped_data),\n",
    "                    \"total_content_length\": sum(page[\"content_length\"] for page in scraped_data)\n",
    "                })\n",
    "            else:\n",
    "                print(\"üìÅ Using existing scraped data...\")\n",
    "            \n",
    "            # Load documents and create/load vector store\n",
    "            documents = self.rag_system.load_documents_from_json(self.config[\"noveum_docs_file\"])\n",
    "            \n",
    "            if not documents:\n",
    "                print(\"‚ùå Failed to load documents\")\n",
    "                return False\n",
    "            \n",
    "            # Try to load existing vector store, create if doesn't exist\n",
    "            if not self.rag_system.load_vectorstore():\n",
    "                print(\"üîÑ Creating new vector store...\")\n",
    "                self.rag_system.create_vectorstore(documents)\n",
    "            \n",
    "            self.is_initialized = True\n",
    "            print(\"‚úÖ Noveum AI Agent initialized successfully!\")\n",
    "            \n",
    "            init_span.set_attributes({\n",
    "                \"system.initialized\": True,\n",
    "                \"system.documents_loaded\": len(documents),\n",
    "                \"system.vectorstore_ready\": self.rag_system.vectorstore is not None\n",
    "            })\n",
    "            \n",
    "            return True\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a user query and return response\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            print(\"‚ùå System not initialized. Please run initialize_system() first.\")\n",
    "            return {\n",
    "                \"answer\": \"System not initialized. Please run initialize_system() first.\",\n",
    "                \"mode\": \"Error\",\n",
    "                \"sources\": [],\n",
    "                \"error\": \"System not initialized\"\n",
    "            }\n",
    "        \n",
    "        print(f\"\\nüéØ Processing query: '{query}'\")\n",
    "        \n",
    "        with trace_operation(\"tool-orchestator\") as process_span:\n",
    "            process_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query.length\": len(query)\n",
    "            })\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Route query and get response\n",
    "                mode, response = self.query_router.route_query(query)\n",
    "                \n",
    "                # Add processing metrics\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                response.update({\n",
    "                    \"processing_time\": processing_time,\n",
    "                    \"timestamp\": time.time()\n",
    "                })\n",
    "                \n",
    "                # Add metrics to span\n",
    "                process_span.set_attributes({\n",
    "                    \"processing.mode\": mode,\n",
    "                    \"processing.time_seconds\": processing_time,\n",
    "                    \"processing.response_length\": len(response.get(\"answer\", \"\")),\n",
    "                    \"processing.sources_count\": len(response.get(\"sources\", [])),\n",
    "                    \"output_response\": f\"Final Answer: {response.get('answer', '')[:200]}{'...' if len(response.get('answer', '')) > 200 else ''}\",\n",
    "                    \"final_answer_mode\": mode,\n",
    "                    \"query_processed.input_query\": query,\n",
    "                    \"query_processed.output_response\": f\"Successfully processed query using {mode}, generated {len(response.get('answer', ''))} character response\",\n",
    "                    \"query_processed.mode\": mode,\n",
    "                    \"query_processed.processing_time\": processing_time,\n",
    "                    \"query_processed.response_length\": len(response.get(\"answer\", \"\"))\n",
    "                })\n",
    "                \n",
    "                print(f\"‚úÖ Query processed in {processing_time:.2f}s using {mode}\")\n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error processing query: {str(e)}\"\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                \n",
    "                process_span.add_event(\"query_processing_error\", {\n",
    "                    \"error\": str(e),\n",
    "                    \"input_query\": query,\n",
    "                    \"output_response\": f\"I encountered an error while processing your query: {str(e)}\"\n",
    "                })\n",
    "                \n",
    "                return {\n",
    "                    \"answer\": f\"I encountered an error while processing your query: {str(e)}\",\n",
    "                    \"mode\": \"Error\",\n",
    "                    \"sources\": [],\n",
    "                    \"error\": str(e),\n",
    "                    \"processing_time\": time.time() - start_time\n",
    "                }\n",
    "    \n",
    "    def display_response(self, response: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display the response in a formatted way\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ü§ñ NOVEUM AI AGENT RESPONSE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"üìä Mode: {response.get('mode', 'Unknown')}\")\n",
    "        print(f\"‚è±Ô∏è  Processing Time: {response.get('processing_time', 0):.2f}s\")\n",
    "        print(f\"üìÖ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(response.get('timestamp', time.time())))}\")\n",
    "        \n",
    "        if response.get('sources'):\n",
    "            print(f\"üìö Sources ({len(response['sources'])}):\")\n",
    "            for i, source in enumerate(response['sources'][:3], 1):  # Show first 3 sources\n",
    "                print(f\"   {i}. {source}\")\n",
    "            if len(response['sources']) > 3:\n",
    "                print(f\"   ... and {len(response['sources']) - 3} more\")\n",
    "        \n",
    "        print(\"\\nüí¨ Answer:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(response.get('answer', 'No answer provided'))\n",
    "        print(\"=\"*80)\n",
    "\n",
    "# Initialize the main agent\n",
    "noveum_agent = NoveumAIAgent(scraper, rag_system, web_search_system, query_router, CONFIG)\n",
    "print(\"‚úÖ Noveum AI Agent initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b30e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Demo functions ready!\n",
      "\n",
      "üöÄ To get started:\n",
      "1. Run: demo_noveum_agent()  # For a full demo\n",
      "2. Run: ask_question('Your question here')  # For a single question\n",
      "3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Usage Examples and Demo\n",
    "def demo_noveum_agent():\n",
    "    \"\"\"Demo function showing how to use the Noveum AI Agent\"\"\"\n",
    "    \n",
    "    print(\"üé¨ NOVEUM AI AGENT DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Initialize the system\n",
    "    print(\"\\n1Ô∏è‚É£ Initializing the system...\")\n",
    "    success = noveum_agent.initialize_system(force_scrape=False)  # Set to True to force re-scraping\n",
    "    \n",
    "    if not success:\n",
    "        print(\"‚ùå Failed to initialize system\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Demo queries - 20 comprehensive test questions\n",
    "    demo_queries = [\n",
    "        # RAG Queries (Noveum-specific)\n",
    "        \"What is Noveum and what does it do?\",  # Basic product info\n",
    "        \"How do I integrate Noveum Trace in my application?\",  # Technical integration\n",
    "        \"What are Noveum's pricing plans?\",  # Pricing information\n",
    "        \"What features does Noveum Trace offer?\",  # Feature overview\n",
    "        \"How do I set up observability with Noveum?\",  # Setup guidance\n",
    "        \"What APIs are available in Noveum platform?\",  # API documentation\n",
    "        \"How does Noveum handle agent tracing?\",  # Technical details\n",
    "        \"What monitoring capabilities does Noveum provide?\",  # Capabilities\n",
    "        \"How do I configure Noveum for my system?\",  # Configuration\n",
    "        \"What are the benefits of using Noveum Trace?\",  # Value proposition\n",
    "        \n",
    "        # Web Search Queries (External/Recent information)\n",
    "        \"What are the latest AI news today?\",  # Recent news\n",
    "        \"What's the weather like today?\",  # Current weather\n",
    "        \"Tell me about recent developments in machine learning\",  # Recent developments\n",
    "        \"What are the current trends in observability tools?\",  # Industry trends\n",
    "        \"What happened in tech news this week?\",  # Weekly tech news\n",
    "        \"What are the latest updates in Python programming?\",  # Recent updates\n",
    "        \"What's the current status of cryptocurrency markets?\",  # Market information\n",
    "        \"What are the newest features in cloud computing?\",  # Recent features\n",
    "        \"What's happening in the software development world today?\",  # Current events\n",
    "        \"What are the latest breakthroughs in artificial intelligence?\"  # Recent breakthroughs\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ Running {len(demo_queries)} demo queries...\")\n",
    "    \n",
    "    for i, query in enumerate(demo_queries, 1):\n",
    "        print(f\"\\n--- Demo Query {i} ---\")\n",
    "        response = noveum_agent.process_query(query)\n",
    "        noveum_agent.display_response(response)\n",
    "        \n",
    "        # Small delay between queries\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"\\nüéâ Demo completed! Check Noveum Trace dashboard for detailed observability data.\")\n",
    "    print(\"üí° You can now use noveum_agent.process_query('your question') for your own queries!\")\n",
    "\n",
    "# Interactive query function\n",
    "def ask_question(question: str):\n",
    "    \"\"\"Convenience function to ask a single question\"\"\"\n",
    "    if not noveum_agent.is_initialized:\n",
    "        print(\"‚ö†Ô∏è  System not initialized. Initializing now...\")\n",
    "        if not noveum_agent.initialize_system():\n",
    "            print(\"‚ùå Failed to initialize system\")\n",
    "            return\n",
    "    \n",
    "    response = noveum_agent.process_query(question)\n",
    "    noveum_agent.display_response(response)\n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ Demo functions ready!\")\n",
    "print(\"\\nüöÄ To get started:\")\n",
    "print(\"1. Run: demo_noveum_agent()  # For a full demo\")\n",
    "print(\"2. Run: ask_question('Your question here')  # For a single question\")\n",
    "print(\"3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_noveum_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b29876",
   "metadata": {},
   "source": [
    "## Downloading the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python noveum_customer_support_bt/traces/fetch_traces_api.py 50\n",
    "\n",
    "#. This script fetches traces for our project and saves them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python NovaEval/noveum_customer_support_bt/traces/combine_spans_api_compat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddd552",
   "metadata": {},
   "source": [
    "## Data Filteration and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_map.py ./traces/dataset_filtered.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e242af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_map.py NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fd0e1",
   "metadata": {},
   "source": [
    "## Running eval on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770777e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "!source .venv/bin/activate\n",
    "!cd noveum_customer_support_bt\n",
    "\n",
    "# 2. Create Dataset\n",
    "!python create_dataset.py --dataset-type agent --description \"Customer Support Agent Evaluation Dataset\" --pretty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9358c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Version\n",
    "!python create_dataset_version.py --pretty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224276f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting scores\n",
    "from demo_utils import run_complete_agent_evaluation\n",
    "import os\n",
    "\n",
    "# Process all JSON files in split_datasets directory\n",
    "for file in os.listdir('split_datasets'):\n",
    "    if file.endswith('.json'):\n",
    "        print(f'Processing {file}...')\n",
    "        run_complete_agent_evaluation(\n",
    "            f'split_datasets/{file}', \n",
    "            sample_size=25, \n",
    "            evaluation_name=file.replace('.json', ''),\n",
    "            output_dir='./demo_results'\n",
    "        )\n",
    "        print(f'Completed {file}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5ca2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created api_data.json with 20 items\n",
      "Sample items:\n",
      "  {'item_key': 'eda4fe22-9a2b-4b73-856b-f4f3309bf719', 'item_id': 'item_1'}\n",
      "  {'item_key': '0ffffba1-8a37-443c-8866-d53ffbfa7718', 'item_id': 'item_2'}\n",
      "  {'item_key': 'f1f37bd7-0851-4659-b493-b80d3800d920', 'item_id': 'item_3'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('demo_results/agent.query_routing_dataset/agent_evaluation_results.csv')\n",
    "\n",
    "# Create API data structure with all task_ids\n",
    "api_data = {\n",
    "    'items': [\n",
    "        {\n",
    "            'item_key': str(row['task_id']),\n",
    "            'item_id': f'item_{i+1}'  # Generate unique item IDs\n",
    "        }\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('api_data.json', 'w') as f:\n",
    "    json.dump(api_data, f, indent=2)\n",
    "\n",
    "print('Created api_data.json with', len(api_data['items']), 'items')\n",
    "print('Sample items:')\n",
    "for item in api_data['items'][:3]:\n",
    "    print(f'  {item}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col context_relevancy --reasoning-col context_relevancy_reasoning --api-data api_data.json --scorer-id context_relevancy_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col role_adherence --reasoning-col role_adherence_reasoning --api-data api_data.json --scorer-id role_adherence_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col parameter_correctness --reasoning-col parameter_correctness_reasoning --api-data api_data.json --scorer-id parameter_correctness_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83466df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
