[
  {
    "url": "https://noveum.ai",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "Monitor all your AI Agents\nimprove AI Agents today\nNoveum.ai helps you monitor, trace, and optimize your AI applications.\nNoveum.ai works with any AI framework â€“ LangChain, CrewAI, AutoGen, custom implementations, or direct LLM calls. One dashboard shows everything.\nMonitor, Evaluate, Improve Your AI Agents\nThe control plane for AI agents.\nMonitor Everything, Miss Nothing\nOur lightweight SDKs capture every trace and span across your AI agent ecosystemâ€”from simple LLM calls to complex multi-agent workflows. Get complete visibility without performance overhead.\nStart MonitoringEvaluate with 30+ Advanced Metrics\nNovaEval automatically scores every agent interaction using our comprehensive evaluation framework. Track accuracy, semantic similarity, safety, bias, and custom business metrics in real-time.\nView EvaluationsImprove Automatically with NovaPilot\nOur AI engineer analyzes performance data and automatically generates fixes for failing agents. Get detailed reports on model changes, prompt optimizations, and tool improvementsâ€”all without human intervention.\nTry Auto-ImprovementEnterprise Ready\nNoveum.ai is built for enterprise-scale AI applications, with support for multi-tenant, multi-region deployments and advanced security features.\nContact Saleswith the world's favorite AI Observability Platform\nEverything You Need to Master AI Agent Operations\nNoveum.ai helps you monitor, trace, and optimize your AI applications with comprehensive observability tools designed for modern LLM workflows.\nSee Every Agent, Every Interaction, Every Decision\n30+ Metrics That Actually Matter for Business\nYour AI Engineer That Never Sleeps\n100% visibility on every AI agent\nReduce AI Incidents by 85%\nGet comprehensive AI monitoring with automated incident prevention, faster debugging, and built-in compliance tools.\nInstead of spending days investigating AI agent failures, your team gets instant insights into what went wrong and how to fix it. Detailed traces and automated analysis eliminate guesswork.\n0+\nAI FrameworksWith the world's favorite AI observability platform\nEasy integration with your AI stack\nNoveum.ai integrates seamlessly with all popular AI frameworks and providers, giving you comprehensive observability across your entire AI pipeline.\nWorks great with: LangChain, OpenAI, Anthropic, AWS Bedrock, Azure OpenAI, Google Cloud (Vertex AI), CrewAI, LangGraph, LlamaIndex, AutoGen, custom SDKs, and more\nwith the world's favorite AI observability platform\nTrusted AI monitoring tools by thousands of developers\n0+\nAI Eval Metrics0.0%\nuptime SLA0M+\ntraces processed",
    "content_length": 2591,
    "internal_links": [
      "https://noveum.ai/en",
      "https://noveum.ai/en",
      "https://noveum.ai/en/blog",
      "https://noveum.ai/en/docs",
      "https://noveum.ai/en/careers",
      "https://noveum.ai/en/contact",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/en",
      "https://noveum.ai/en",
      "https://noveum.ai/en/blog",
      "https://noveum.ai/en/docs",
      "https://noveum.ai/en/contact",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/docs",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/auth/login",
      "https://noveum.ai/en",
      "https://noveum.ai/en/blog",
      "https://noveum.ai/en/docs",
      "https://noveum.ai/en/contact",
      "https://noveum.ai/en/pricing",
      "https://noveum.ai/en/docs/getting-started/sdk-integration",
      "https://noveum.ai/en/docs/getting-started/overview",
      "https://noveum.ai/en/auth/login"
    ],
    "scraped_at": 1759935886.929589
  },
  {
    "url": "https://noveum.ai/en",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "Monitor all your AI Agents\nimprove AI Agents today\nNoveum.ai helps you monitor, trace, and optimize your AI applications.\nNoveum.ai works with any AI framework â€“ LangChain, CrewAI, AutoGen, custom implementations, or direct LLM calls. One dashboard shows everything.\nMonitor, Evaluate, Improve Your AI Agents\nThe control plane for AI agents.\nMonitor Everything, Miss Nothing\nOur lightweight SDKs capture every trace and span across your AI agent ecosystemâ€”from simple LLM calls to complex multi-agent workflows. Get complete visibility without performance overhead.\nStart MonitoringEvaluate with 30+ Advanced Metrics\nNovaEval automatically scores every agent interaction using our comprehensive evaluation framework. Track accuracy, semantic similarity, safety, bias, and custom business metrics in real-time.\nView EvaluationsImprove Automatically with NovaPilot\nOur AI engineer analyzes performance data and automatically generates fixes for failing agents. Get detailed reports on model changes, prompt optimizations, and tool improvementsâ€”all without human intervention.\nTry Auto-ImprovementEnterprise Ready\nNoveum.ai is built for enterprise-scale AI applications, with support for multi-tenant, multi-region deployments and advanced security features.\nContact Saleswith the world's favorite AI Observability Platform\nEverything You Need to Master AI Agent Operations\nNoveum.ai helps you monitor, trace, and optimize your AI applications with comprehensive observability tools designed for modern LLM workflows.\nSee Every Agent, Every Interaction, Every Decision\n30+ Metrics That Actually Matter for Business\nYour AI Engineer That Never Sleeps\n100% visibility on every AI agent\nReduce AI Incidents by 85%\nGet comprehensive AI monitoring with automated incident prevention, faster debugging, and built-in compliance tools.\nInstead of spending days investigating AI agent failures, your team gets instant insights into what went wrong and how to fix it. Detailed traces and automated analysis eliminate guesswork.\n0+\nAI FrameworksWith the world's favorite AI observability platform\nEasy integration with your AI stack\nNoveum.ai integrates seamlessly with all popular AI frameworks and providers, giving you comprehensive observability across your entire AI pipeline.\nWorks great with: LangChain, OpenAI, Anthropic, AWS Bedrock, Azure OpenAI, Google Cloud (Vertex AI), CrewAI, LangGraph, LlamaIndex, AutoGen, custom SDKs, and more\nwith the world's favorite AI observability platform\nTrusted AI monitoring tools by thousands of developers\n0+\nAI Eval Metrics0.0%\nuptime SLA0M+\ntraces processed",
    "content_length": 2591,
    "internal_links": [],
    "scraped_at": 1759935887.816968
  },
  {
    "url": "https://noveum.ai/en/blog",
    "title": "Noveum.ai Blog | Noveum.ai",
    "content": "Noveum.ai Blog\nRead the latest news & articles from Noveum.ai (prev MagicAPI Inc).\nLearn what evals for AI agents are, why they are essential for production AI, and how Noveum.ai makes running evaluations practical without slowing down your development roadmap.\nAditi Upaddhyay\n9/25/2025\nMMLU benchmark comparison of GPT-OSS (thinking modes), GPT-5, O3, and GPT-4o-mini focusing on accuracy, runtime efficiency, and practical model selection.\nShivam Gupta\n8/13/2025\nWe compared Azure o1-mini vs gpt-4o-mini on 1,000 MMLU math samples using NovaEval. Hereâ€™s how we tested, what worked, what didnâ€™t, and when the 15Ã— cost premium makes sense.\nShashank Agarwal\n8/12/2025\nDiscover how Noveum.ai provides comprehensive tracing and observability for AI applications, from development debugging to production optimization.\nShashank Agarwal\n3/3/2025\nDiscover how Noveum.ai provides comprehensive tracing and observability for LLM applications, RAG systems, and multi-agent workflows with our powerful Python and TypeScript SDKs.\nShashank Agarwal\n3/2/2025",
    "content_length": 1046,
    "internal_links": [
      "https://noveum.ai/en/changelog",
      "https://noveum.ai/en/blog/evals-for-ai-agents",
      "https://noveum.ai/en/blog/evals-for-ai-agents",
      "https://noveum.ai/en/blog/gpt-oss-vs-gpt-5-vs-gpt-4o-mini-mmlu-evaluation-report",
      "https://noveum.ai/en/blog/gpt-oss-vs-gpt-5-vs-gpt-4o-mini-mmlu-evaluation-report",
      "https://noveum.ai/en/blog/comprehensive-mmlu-evaluation-analysis-report",
      "https://noveum.ai/en/blog/comprehensive-mmlu-evaluation-analysis-report",
      "https://noveum.ai/en/blog/from-logs-to-intelligent-choices-inside-noveum-ais-evaluation-process",
      "https://noveum.ai/en/blog/from-logs-to-intelligent-choices-inside-noveum-ais-evaluation-process",
      "https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform",
      "https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform",
      "https://noveum.ai/en/legal/privacy-policy",
      "https://noveum.ai/en/legal/terms"
    ],
    "scraped_at": 1759935888.8273768
  },
  {
    "url": "https://noveum.ai/en/docs",
    "title": "Welcome to Noveum.ai Docs | Documentation | Noveum.ai",
    "content": "Welcome to Noveum.ai Docs\nComprehensive AI tracing and observability for LLM applications, RAG systems, and AI agents\nWelcome to the Noveum.ai documentation! Here you'll find everything you need to integrate, configure, and optimize your AI applications using our comprehensive tracing and observability platform.\nWe provide powerful SDKs for Python and TypeScript that enable you to trace LLM calls, RAG pipelines, and multi-agent workflows with minimal code changes. Our documentation is organized to help you get started quickly while diving into advanced observability patterns and best practices.\nğŸš€ What is Noveum.ai?\nNoveum.ai is a comprehensive AI tracing and observability platform designed specifically for modern AI applications. Unlike traditional monitoring tools, Noveum understands the unique challenges of LLM applications, RAG systems, and AI agents.\nCore Components\n-\nğŸ Python SDK (\nnoveum-trace\n)- Decorator-based tracing for LLM calls, agents, and RAG pipelines\n- Automatic instrumentation for popular AI frameworks\n- Context propagation across async operations\n-\nğŸ“˜ TypeScript SDK (\n@noveum/trace\n)- Framework integrations for Next.js, Express.js, and Hono\n- TypeScript-first design with full type safety\n- Universal compatibility (Node.js, Edge Runtime, browsers)\n-\nğŸ“Š Noveum Platform\n- Real-time dashboard for analyzing traces and performance\n- Advanced filtering and search capabilities\n- Cost analysis and optimization insights\n- Team collaboration and project management\nğŸƒ Quick Start\n1. Choose Your SDK\n2. View Your Data\nWithin minutes, you'll see comprehensive traces in the Noveum dashboard:\n- ğŸ” Request/Response details and timing\n- ğŸ’° Cost tracking across providers\n- ğŸš€ Performance metrics (latency, throughput)\n- ğŸ› Error analysis and debugging context\nğŸ“š Documentation Structure\nGetting Started\n-\nOverview Introduction to Noveum.ai's tracing and observability capabilities.\n-\nSDK Integration Step-by-step guide to integrate Python or TypeScript SDKs into your application.\n-\nTracing Concepts Understanding traces, spans, and observability best practices for AI applications.\n-\nFramework Integrations Specific guides for Next.js, Express.js, FastAPI, and other popular frameworks.\nAdvanced Usage\n-\nMulti-Agent Tracing Observe complex agent workflows and inter-agent communications.\n-\nRAG Pipeline Observability Monitor retrieval, generation, and context handling in RAG systems.\n-\nCustom Instrumentation Add custom spans and attributes for domain-specific observability.\n-\nPerformance Optimization Use tracing data to identify bottlenecks and optimize AI application performance.\nPlatform Features\n-\nDashboard Overview Navigate the Noveum platform and understand key metrics.\n-\nProjects & Environments Organize your applications and manage different deployment environments.\n-\nTeam Collaboration Share insights and collaborate on AI application observability.\n-\nAPI Reference Direct API access for custom integrations and advanced use cases.\nğŸ¯ Use Cases\nLLM Application Monitoring\nTrack every LLM call across your application with automatic cost calculation, latency measurement, and error tracking.\nRAG System Observability\nMonitor the entire RAG pipeline from query understanding to document retrieval to answer generation.\nMulti-Agent Workflows\nObserve complex agent interactions, tool usage, and decision-making processes across distributed AI systems.\nPerformance Optimization\nIdentify slow operations, expensive API calls, and opportunities for caching or model optimization.\nğŸ”— SDK Resources\nPython SDK\n- ğŸ“¦ PyPI Package: noveum-trace\n- ğŸ™ GitHub Repository: Noveum/noveum-trace\n- ğŸ“– API Documentation: Python SDK Docs\nTypeScript SDK\n- ğŸ“¦ NPM Package: @noveum/trace\n- ğŸ™ GitHub Repository: Noveum/noveum-trace-ts\n- ğŸ“– API Documentation: TypeScript SDK Docs\nğŸ’¡ Key Benefits\n- ğŸ”§ Minimal Setup: Start tracing with just a few lines of code\n- ğŸ¯ AI-Native: Purpose-built for LLM, RAG, and agent observability\n- ğŸš€ Production Ready: Battle-tested at scale with intelligent sampling\n- ğŸ”’ Secure: End-to-end encryption with configurable data retention\n- ğŸŒ Universal: Works across frameworks, clouds, and deployment models\nğŸ¤ Community & Support\n- ğŸ’¬ Discord Community: Join our Discord\n- ğŸ“§ Email Support: [email protected]\n- ğŸ› Bug Reports: GitHub Issues\n- ğŸ“– Knowledge Base: Help Center\nReady to get started? Head to our SDK Integration Guide to begin tracing your AI applications in under 5 minutes!\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 4652,
    "internal_links": [
      "https://noveum.ai/en/docs/getting-started/tracing-concepts",
      "https://noveum.ai/en/docs/getting-started/framework-integrations",
      "https://noveum.ai/en/docs/advanced/multi-agent-tracing",
      "https://noveum.ai/en/docs/advanced/rag-observability",
      "https://noveum.ai/en/docs/advanced/custom-instrumentation",
      "https://noveum.ai/en/docs/advanced/performance-optimization",
      "https://noveum.ai/docs/getting-started/overview",
      "https://noveum.ai/docs/getting-started/sdk-integration",
      "https://noveum.ai/docs/getting-started/tracing-concepts",
      "https://noveum.ai/docs/getting-started/framework-integrations",
      "https://noveum.ai/docs/advanced/multi-agent-tracing",
      "https://noveum.ai/docs/advanced/rag-observability",
      "https://noveum.ai/docs/advanced/custom-instrumentation",
      "https://noveum.ai/docs/advanced/performance-optimization",
      "https://noveum.ai/docs/platform/dashboard",
      "https://noveum.ai/docs/platform/projects",
      "https://noveum.ai/docs/platform/teams",
      "https://noveum.ai/docs/platform/api",
      "https://noveum.ai/docs/getting-started/sdk-integration"
    ],
    "scraped_at": 1759935889.759006
  },
  {
    "url": "https://noveum.ai/en/careers",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "Why Work at Noveum.ai?\nJoin a team that's building the future of AI while maintaining a culture of innovation, transparency, and mutual respect.\nAI Agents Economy Pioneer\nBe at the forefront of the revolutionary AI Agents Economy and shape the future of autonomous AI systems.\nCreator of API.market\nJoin the team behind API.market, already loved by thousands of developers worldwide.\n100% Remote\nWork from anywhere in the world. We believe in flexibility and work-life balance.\nIndustry Leading Compensation\nCompetitive salaries and equity packages that reflect your value and contribution.\nAI-First Culture\nWe encourage using AI tools like Cursor IDE and ChatGPT. We'll train you to use them effectively.\nNo Politics, No Toxicity\nA healthy work environment focused on building great products and supporting each other.\nOpen Positions\nJoin our growing team and help build the next generation of AI agents and developer tools.\nMonitor, evaluate, and improve AI agents in production. Build eval pipelines, debug agent workflows, and deploy/tune models alongside observability to drive reliability and quality.\nKey Requirements:\nOur Culture & Values\nWe're building more than just technologyâ€”we're creating a workplace where innovation thrives and everyone can do their best work.\nDo No Harm\nWe build technology that benefits humanity and take responsibility for our impact on the world.\nBe the Good You Want to See\nWe lead by example and create positive change in our industry and communities.\nOwnership\nWe take ownership of our work, decisions, and outcomes. Everyone is empowered to make a difference.\nTransparency\nWe believe in open communication, honest feedback, and sharing knowledge across the team.\nReady to Join Our Mission?\nWe're looking for passionate individuals who want to shape the future of AI agents and build technology that makes a positive impact.",
    "content_length": 1864,
    "internal_links": [
      "https://noveum.ai/en/careers/apply/senior-ai-engineer",
      "https://noveum.ai/en/careers/apply/fullstack-developer-ai"
    ],
    "scraped_at": 1759935890.6604009
  },
  {
    "url": "https://noveum.ai/en/contact",
    "title": "Contact us | Noveum.ai",
    "content": "Blog\nChangelog\nContact\nGitHub\nCareers\nDocs\nLogin\nContact us\nWe are here to help you. Please use the form below to get in touch with us.\nName\nEmail\nMessage\nSend message",
    "content_length": 167,
    "internal_links": [],
    "scraped_at": 1759935891.625962
  },
  {
    "url": "https://noveum.ai/auth/login",
    "title": "Welcome back | Noveum.ai",
    "content": "Welcome back\nPlease enter your credentials to sign in.\nPassword\nOTP\nEmail\nPassword\nForgot password?\nSign in\nOr continue with\nGoogle\nGoogle\nGithub\nGithub\nLogin with passkey\nDon't have an account yet?\nCreate an account",
    "content_length": 216,
    "internal_links": [
      "https://noveum.ai/",
      "https://noveum.ai/auth/forgot-password",
      "https://noveum.ai/auth/signup"
    ],
    "scraped_at": 1759935892.526221
  },
  {
    "url": "https://noveum.ai/docs",
    "title": "Welcome to Noveum.ai Docs | Documentation | Noveum.ai",
    "content": "Welcome to Noveum.ai Docs\nComprehensive AI tracing and observability for LLM applications, RAG systems, and AI agents\nWelcome to the Noveum.ai documentation! Here you'll find everything you need to integrate, configure, and optimize your AI applications using our comprehensive tracing and observability platform.\nWe provide powerful SDKs for Python and TypeScript that enable you to trace LLM calls, RAG pipelines, and multi-agent workflows with minimal code changes. Our documentation is organized to help you get started quickly while diving into advanced observability patterns and best practices.\nğŸš€ What is Noveum.ai?\nNoveum.ai is a comprehensive AI tracing and observability platform designed specifically for modern AI applications. Unlike traditional monitoring tools, Noveum understands the unique challenges of LLM applications, RAG systems, and AI agents.\nCore Components\n-\nğŸ Python SDK (\nnoveum-trace\n)- Decorator-based tracing for LLM calls, agents, and RAG pipelines\n- Automatic instrumentation for popular AI frameworks\n- Context propagation across async operations\n-\nğŸ“˜ TypeScript SDK (\n@noveum/trace\n)- Framework integrations for Next.js, Express.js, and Hono\n- TypeScript-first design with full type safety\n- Universal compatibility (Node.js, Edge Runtime, browsers)\n-\nğŸ“Š Noveum Platform\n- Real-time dashboard for analyzing traces and performance\n- Advanced filtering and search capabilities\n- Cost analysis and optimization insights\n- Team collaboration and project management\nğŸƒ Quick Start\n1. Choose Your SDK\n2. View Your Data\nWithin minutes, you'll see comprehensive traces in the Noveum dashboard:\n- ğŸ” Request/Response details and timing\n- ğŸ’° Cost tracking across providers\n- ğŸš€ Performance metrics (latency, throughput)\n- ğŸ› Error analysis and debugging context\nğŸ“š Documentation Structure\nGetting Started\n-\nOverview Introduction to Noveum.ai's tracing and observability capabilities.\n-\nSDK Integration Step-by-step guide to integrate Python or TypeScript SDKs into your application.\n-\nTracing Concepts Understanding traces, spans, and observability best practices for AI applications.\n-\nFramework Integrations Specific guides for Next.js, Express.js, FastAPI, and other popular frameworks.\nAdvanced Usage\n-\nMulti-Agent Tracing Observe complex agent workflows and inter-agent communications.\n-\nRAG Pipeline Observability Monitor retrieval, generation, and context handling in RAG systems.\n-\nCustom Instrumentation Add custom spans and attributes for domain-specific observability.\n-\nPerformance Optimization Use tracing data to identify bottlenecks and optimize AI application performance.\nPlatform Features\n-\nDashboard Overview Navigate the Noveum platform and understand key metrics.\n-\nProjects & Environments Organize your applications and manage different deployment environments.\n-\nTeam Collaboration Share insights and collaborate on AI application observability.\n-\nAPI Reference Direct API access for custom integrations and advanced use cases.\nğŸ¯ Use Cases\nLLM Application Monitoring\nTrack every LLM call across your application with automatic cost calculation, latency measurement, and error tracking.\nRAG System Observability\nMonitor the entire RAG pipeline from query understanding to document retrieval to answer generation.\nMulti-Agent Workflows\nObserve complex agent interactions, tool usage, and decision-making processes across distributed AI systems.\nPerformance Optimization\nIdentify slow operations, expensive API calls, and opportunities for caching or model optimization.\nğŸ”— SDK Resources\nPython SDK\n- ğŸ“¦ PyPI Package: noveum-trace\n- ğŸ™ GitHub Repository: Noveum/noveum-trace\n- ğŸ“– API Documentation: Python SDK Docs\nTypeScript SDK\n- ğŸ“¦ NPM Package: @noveum/trace\n- ğŸ™ GitHub Repository: Noveum/noveum-trace-ts\n- ğŸ“– API Documentation: TypeScript SDK Docs\nğŸ’¡ Key Benefits\n- ğŸ”§ Minimal Setup: Start tracing with just a few lines of code\n- ğŸ¯ AI-Native: Purpose-built for LLM, RAG, and agent observability\n- ğŸš€ Production Ready: Battle-tested at scale with intelligent sampling\n- ğŸ”’ Secure: End-to-end encryption with configurable data retention\n- ğŸŒ Universal: Works across frameworks, clouds, and deployment models\nğŸ¤ Community & Support\n- ğŸ’¬ Discord Community: Join our Discord\n- ğŸ“§ Email Support: [email protected]\n- ğŸ› Bug Reports: GitHub Issues\n- ğŸ“– Knowledge Base: Help Center\nReady to get started? Head to our SDK Integration Guide to begin tracing your AI applications in under 5 minutes!\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 4652,
    "internal_links": [],
    "scraped_at": 1759935893.7828538
  },
  {
    "url": "https://noveum.ai/en/docs/getting-started/sdk-integration",
    "title": "SDK Integration Guide | Documentation | Noveum.ai",
    "content": "SDK Integration Guide\nIntegrate Noveum.ai tracing into your AI applications with Python or TypeScript SDKs\nThe Noveum.ai SDKs provide comprehensive tracing and observability for your AI applications with minimal code changes. Whether you're building LLM applications, RAG systems, or multi-agent workflows, our SDKs automatically capture essential metrics and traces.\nğŸš€ Quick Start\n1. Create Your Account & Get API Key\n- Sign up at noveum.ai\n- Create a project in your dashboard\n- Generate an API key from the integration page\n- Choose your SDK based on your application language\n2. Install the SDK\nRequirements: Python 3.8+\n3. Initialize the Client\nEnvironment Variables:\nğŸ¯ Basic Usage\nTrace LLM Calls\nAlternative - Context Manager:\nTrace RAG Pipelines\nğŸ”§ Framework Integrations\nNext.js Integration\nExpress.js Integration\nFastAPI Integration (Python)\nğŸ“Š Advanced Features\nCustom Attributes & Events\nSampling Configuration\nğŸ”— What's Captured Automatically\n- ğŸ“Š Performance Metrics: Latency, throughput, error rates\n- ğŸ’° Cost Tracking: Token usage, API costs across providers\n- ğŸ” Request/Response: Configurable capture of inputs/outputs\n- ğŸ·ï¸ Metadata: Model names, parameters, user context\n- ğŸŒŠ Context Flow: Trace relationships across services\n- ğŸ› Error Details: Stack traces, error classification\nğŸ“ˆ View Your Data\nOnce integrated, visit your Noveum Dashboard to:\n- ğŸ” Search & Filter traces by any attribute\n- ğŸ“Š Analyze Performance trends and bottlenecks\n- ğŸ’° Monitor Costs across different models and providers\n- ğŸ› Debug Issues with detailed trace timelines\n- ğŸ‘¥ Collaborate with your team on insights\nğŸ”’ Security & Privacy\n- ğŸ” Encryption: All data encrypted in transit and at rest\n- ğŸ›ï¸ Configurable Capture: Control what data is collected\n- ğŸ  Data Residency: Choose your data storage region\n- â° Retention Control: Set custom data retention policies\nNext Steps\n- Tracing Concepts - Learn about traces, spans, and observability best practices\n- Framework Integrations - Deep dive into specific framework setups\n- Multi-Agent Tracing - Observe complex agent workflows\n- Dashboard Guide - Master the Noveum platform interface\nExclusive Early Access\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2378,
    "internal_links": [],
    "scraped_at": 1759935895.715991
  },
  {
    "url": "https://noveum.ai/en/docs/getting-started/overview",
    "title": "Noveum.ai Overview | Documentation | Noveum.ai",
    "content": "Noveum.ai Overview\nComprehensive AI tracing and observability platform for LLM applications, RAG systems, and AI agents\nWelcome to Noveum.aiâ€”the comprehensive tracing and observability platform built specifically for AI applications. Whether you're building LLM-powered chatbots, RAG systems, multi-agent workflows, or any AI-driven application, Noveum provides the insights you need to understand, debug, and optimize your systems.\nğŸ¯ Why AI Applications Need Specialized Observability\nTraditional monitoring tools fall short when it comes to AI applications because they don't understand:\n- ğŸ“Š AI-Specific Metrics: Token usage, model costs, prompt effectiveness\n- ğŸ”€ Complex Workflows: Multi-step RAG pipelines, agent interactions, tool usage\n- ğŸ§  Context Flow: How data moves through embeddings, retrievals, and generations\n- ğŸ’° Cost Attribution: Which operations drive your AI spending\n- ğŸ¯ Quality Metrics: Beyond latency - understanding output quality and relevance\nNoveum.ai bridges this gap with purpose-built observability for the AI era.\nğŸš€ Core Platform Components\n1. ğŸ Python SDK (noveum-trace\n)\n- Decorator-based tracing for seamless integration\n- Automatic instrumentation for LangChain, LlamaIndex, and OpenAI\n- Async-aware context propagation\n- Production-ready with intelligent sampling and batching\n2. ğŸ“˜ TypeScript SDK (@noveum/trace\n)\n- Framework integrations for Next.js, Express.js, Hono\n- TypeScript-first with full type safety\n- Universal compatibility (Node.js, Edge Runtime, browsers)\n- Zero-config automatic instrumentation\n3. ğŸ“Š Noveum Platform\n- Real-time dashboard with AI-specific visualizations\n- Advanced search & filtering across traces and spans\n- Cost analysis and optimization recommendations\n- Team collaboration with shared insights and alerts\nğŸ” What Noveum Traces\nLLM Operations\n- Model calls across all providers (OpenAI, Anthropic, Google, etc.)\n- Token usage and cost calculation\n- Prompt engineering effectiveness\n- Response quality metrics\nRAG Pipelines\n- Document retrieval performance and relevance\n- Embedding generation costs and latency\n- Context assembly and prompt construction\n- Answer generation with source attribution\nMulti-Agent Systems\n- Agent interactions and communication patterns\n- Tool usage and external API calls\n- Decision trees and reasoning chains\n- Workflow orchestration across agents\nCustom Operations\n- Business logic specific to your domain\n- External integrations and API calls\n- Data processing pipelines\n- User interactions and session flows\nğŸ¯ Key Benefits\nğŸ”§ Developer Experience\n- 5-minute setup with minimal code changes\n- Intelligent defaults that work out-of-the-box\n- Rich SDKs with comprehensive documentation\n- Local development support with optional cloud sync\nğŸ“Š Production Insights\n- Real-time monitoring of AI application health\n- Performance optimization with bottleneck identification\n- Cost management with detailed spend analysis\n- Quality assurance through automated alerting\nğŸ”’ Enterprise Ready\n- Security first with end-to-end encryption\n- Compliance support for regulated industries\n- Scalable architecture handling millions of traces\n- Data sovereignty with region-specific storage\nğŸ‘¥ Team Collaboration\n- Shared dashboards for cross-functional teams\n- Incident management with trace-based debugging\n- Performance baselines and regression detection\n- Knowledge sharing through trace annotations\nğŸ“ˆ Common Use Cases\nğŸ¤– LLM Application Monitoring\nTrack every aspect of your LLM-powered application:\n- Monitor response quality and user satisfaction\n- Optimize prompt engineering for better results\n- Control costs across different models and providers\n- Debug edge cases and improve error handling\nğŸ” RAG System Optimization\nUnderstand and improve your RAG pipeline:\n- Measure retrieval accuracy and relevance\n- Optimize embedding models and vector search\n- Track context utilization and prompt effectiveness\n- Debug hallucinations and improve grounding\nğŸ¤ Multi-Agent Coordination\nObserve complex agent interactions:\n- Visualize agent communication patterns\n- Track tool usage and external dependencies\n- Optimize workflow efficiency and resource usage\n- Debug coordination failures and deadlocks\nğŸš€ Performance Engineering\nOptimize your AI application performance:\n- Identify slow operations and bottlenecks\n- Right-size models for your workload\n- Implement intelligent caching strategies\n- Scale services based on actual usage patterns\nğŸ¨ Platform Features\nğŸ” Trace Explorer\n- Hierarchical visualization of complex AI workflows\n- Timeline view showing operation sequences\n- Detailed span inspection with all attributes and events\n- Cross-trace correlation for distributed operations\nğŸ’° Cost Analytics\n- Real-time cost tracking across all AI providers\n- Cost attribution by user, feature, or operation\n- Budget alerts and spending forecasts\n- Optimization recommendations for cost reduction\nğŸ“Š Performance Dashboard\n- Latency percentiles and throughput metrics\n- Error rates and failure analysis\n- Model comparison across providers and versions\n- Custom metrics and business KPIs\nğŸš¨ Alerting & Monitoring\n- Intelligent alerts based on AI-specific thresholds\n- Anomaly detection for unusual patterns\n- Escalation policies for critical issues\n- Integration with Slack, PagerDuty, and more\nğŸ› ï¸ Integration Patterns\nIncremental Adoption\nStart small and expand coverage:\n- Single endpoint tracing for immediate value\n- Critical path instrumentation for core workflows\n- Full application coverage for comprehensive insights\n- Advanced features like custom metrics and alerts\nFramework Integration\nNative support for popular frameworks:\n- Next.js with App Router and API routes\n- Express.js and other Node.js frameworks\n- FastAPI and Flask for Python applications\n- Custom integrations for any framework\nCI/CD Integration\nEmbed observability in your development process:\n- Performance regression detection in CI\n- Trace-based testing for quality assurance\n- Deployment monitoring with rollback triggers\n- Feature flag integration for safe releases\nğŸŒŸ Getting Started\nReady to transform your AI application observability? Here's your path:\n- Quick Start - Integrate your first SDK in 5 minutes\n- Tracing Concepts - Learn the fundamentals\n- Framework Guides - Deep dive into your stack\n- Advanced Features - Unlock the full platform potential\nBuilt by developers, for developers. Noveum.ai understands that AI applications are different, and we've designed our platform from the ground up to meet their unique observability needs.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 6733,
    "internal_links": [
      "https://noveum.ai/docs/advanced"
    ],
    "scraped_at": 1759935896.711361
  },
  {
    "url": "https://noveum.ai/en/changelog",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "Changelog\nStay up to date with the latest changes in our product.\n2 months ago\n- ğŸ¯ Major Platform Evolution: NovaEval Framework - Launched comprehensive AI model evaluation framework with 20+ built-in scorers including accuracy, RAG metrics, conversational scoring, and specialized agent evaluation tools. Features production-grade deployment on Docker and Kubernetes. (GitHub | PyPI Package)\n- ğŸš€ Next-Generation Traces UI - Complete redesign featuring three-pane layout with directory tree navigation, advanced filtering, real-time search, mobile responsiveness, and comprehensive keyboard shortcuts. Includes connection status monitoring and performance optimizations.\n- ğŸ—„ï¸ ClickHouse Integration & BYOD Support - Full ClickHouse telemetry backend with connection pooling, retry mechanisms, advanced monitoring, and bring-your-own-database capabilities. Includes secure configuration management and performance optimizations.\n- ğŸ“¦ Noveum Trace SDK - Production-ready Python and TypeScript SDKs for comprehensive AI application tracing. Features automatic instrumentation, multi-agent support, and seamless integration with popular frameworks. (GitHub | PyPI Package)\n- ğŸ” Enhanced Security: Encrypted API key storage with support for OpenAI, AWS, Anthropic, and other major providers\n- ğŸ“Š Advanced Analytics: Real-time metrics dashboard with cost tracking, error rate monitoring, and performance insights\n- ğŸ”§ Developer Experience: Comprehensive integration guides, documentation updates, and SDK examples\n- ğŸ—ï¸ Infrastructure: Kubernetes deployments, Docker optimizations, and scalable architecture improvements\n3 months ago\n- ğŸ¨ Landing Page Redesign: Modern, responsive design with improved user experience and conversion optimization\n- ğŸ“ˆ Enhanced Dashboard Analytics: Real-time request tracking, latency monitoring, and cost analysis\n- ğŸ” Improved Logs Interface: Better search functionality, detailed trace views, and enhanced debugging capabilities\n- ğŸ‘¥ Team Management: Advanced member management with role-based access control and invitation system\n- ğŸ›¡ï¸ Security Improvements: Enhanced API key management and secure credential storage\n4 months ago\n- ğŸ“Š Advanced Metrics Collection: Comprehensive telemetry system with custom metrics support\n- âš¡ Performance Optimizations: Improved database queries and response times across the platform\n- ğŸ§© Model Comparison Tools: Side-by-side evaluation capabilities for AI model performance\n- ğŸŒ Cross-Platform Compatibility: Enhanced browser support and mobile responsiveness\n- ğŸ“ Documentation Updates: Comprehensive guides for integration and best practices\n5 months ago\n- ğŸ‰ Platform Foundation: Initial release of Noveum.ai AI observability platform\n- ğŸš€ Core Features: AI Gateway integration, basic evaluation metrics, and monitoring capabilities\n- ğŸ“ˆ Evaluation Jobs: Automated model evaluation with configurable metrics and reporting\n- ğŸ”Œ Provider Integrations: Support for major AI providers and custom model deployments",
    "content_length": 2960,
    "internal_links": [],
    "scraped_at": 1759935898.441791
  },
  {
    "url": "https://noveum.ai/en/blog/evals-for-ai-agents",
    "title": "Evals for AI Agents: What They Are, Why They Matter, and How Noveum.ai Makes Them Practical | Noveum.ai",
    "content": "Evals for AI Agents: What They Are, Why They Matter, and How Noveum.ai Makes Them Practical\nAditi Upaddhyay\n9/25/2025\nIf youâ€™ve ever shipped an AI agent, youâ€™ve probably felt this: it works great in your dev sandbox, but the moment it meets real users, things get messy. Suddenly, your â€œreliableâ€ agent is skipping steps, hallucinating facts, or taking 20 seconds to do something simple.\nThatâ€™s where evals come in. Theyâ€™re not about passing or failing in the old-school software senseâ€”theyâ€™re about continuously measuring whether your agent is doing the job you hired it for.\nIn this blog, weâ€™ll cover:\n- What evals for AI agents actually mean.\n- Why theyâ€™re a must-have (not a â€œnice-to-haveâ€).\n- How Noveum.ai helps you run evals without slowing down your roadmap.\nLetâ€™s dive in.\n1. What are Evals for AI Agents?\nThink of evals as health check-ups for your AI agents. Just like you wouldnâ€™t assume youâ€™re healthy without getting your vitals checked, you shouldnâ€™t assume your agent is â€œgood enoughâ€ without running evals.\nIn plain terms\nEvals are structured tests that tell you:\n- Did the agent do what it was supposed to?\n- How well did it do it?\n- Was it safe, accurate, and efficient?\nUnlike traditional QA, which looks for bugs, evals look for quality signalsâ€”correctness, completeness, tone, safety, cost, and speed.\nTypes of evals youâ€™ll hear about\n- Offline evals - Run before release, on a fixed dataset. Great for testing prompts or comparing models.\n- Online evals - Run in production on real traffic. Crucial for catching drift, edge cases, and \"silent failures.\"\n- End-to-end evals - Test an entire workflow, not just one answer.\n- Span-level evals - Check each step in the traceâ€”retrieval, reasoning, tool calls.\n- Safety evals - Spot harmful, biased, or policy-violating answers.\nScoring methods\n- Exact matches for structured answers.\n- Rubrics for tone and reasoning.\n- Panel of LLMs (multiple judges instead of one) to cut down bias.\n- Cost + latency tracking side by side with accuracy.\nğŸ‘‰ In short: evals give you visibility. Without them, youâ€™re just trusting your gut.\n2. Why are Evals Necessary for AI Agents?\nLetâ€™s be blunt: AI agents donâ€™t crash with an error message. They fail quietly.\n- A travel booking agent might â€œforgetâ€ a step in the workflow.\n- A fintech agent might miscalculate fees.\n- A support agent might confidently tell a customer something false.\nThese failures donâ€™t show up in logsâ€”they show up in churn, complaints, and unexpected cloud bills.\nReal-world challenges evals solve\n- Data drift: Users change how they ask questions. Models can degrade over time.\n- Messy inputs: People paste screenshots, slang, typosâ€”stuff you never tested for.\n- Hidden costs: A prompt tweak that looks harmless can double your token spend.\n- Compliance needs: For sensitive domains, you need proof your system is safe.\nThe balance every team faces\nYou want your agent to be:\n- Accurate (so users trust it),\n- Fast (so they donâ€™t drop off),\n- Affordable (so margins stay healthy).\nWithout evals, youâ€™re flying blind on all three.\nThatâ€™s why leading teams now treat evals like CI/CD for AI. Every prompt, model, or tool change gets tested against baselines before going live.\n3. How Noveum.ai Helps You Run Evals (Without the Headache)\nYou could build an eval system yourself. Many teams try. Most underestimate the complexity: trace capture, scoring frameworks, dashboards, alerts, model-judge orchestration, drift detectionâ€¦the list goes on.\nNoveum.ai was built to solve this problem end-to-end.\nSee exactly what your agent is doing (NovaTrace SDK)\n- Instrument once, capture everything: inputs, outputs, tokens, latency, tool calls.\n- Visualize every trace as a flow chartâ€”see where it struggled or wasted time.\n- Span-level clarity: you donâ€™t just see that it failed, you see why.\nScore with fairness and depth (NovaEval)\n- Panel-of-LLMs (patent pending): multiple judges reduce bias.\n- Pre-built scorers: ExactMatch, F1, RAG relevance, Safety.\n- Custom rubrics: Define â€œgoodâ€ in your domain (finance â‰  healthcare).\n- Mix human review where it matters most.\nTest like you deploy\n- Offline evals for prompt/model experiments.\n- Shadow or canary live traffic to catch issues before full rollout.\n- A/B test prompts, retrieval configs, or model swaps with dashboards that track accuracy + cost + latency.\nOperate with confidence\n- Set thresholds (e.g., accuracy â‰¥85%, p95 latency <2s, cost <X).\n- Get alerts in Slack/Email when metrics drift.\n- Versioned baselines so you never ship a regression by accident.\n- Suggestions on next steps (optimize prompt, use smaller model for easy cases, add safety guardrails).\nBuilt for scale\n- Multi-agent workflows? Handled.\n- Retrieval-heavy RAG agents? Scored at context level.\n- On-prem or cloud? Your choice.\n- Security-first, enterprise-ready.\nWhat a Good Evals Workflow Looks Like\n- Capture traces with NovaTrace.\n- Start small: 20â€“50 examples, basic rubrics.\n- Run offline evals to pick your baseline.\n- Ship to 5% canary traffic, score live samples.\n- Set alerts for dips in accuracy, spikes in cost, or unsafe answers.\n- Review dashboards weekly. Keep improving.\n- Expand eval sets as you hit new edge cases.\nThe result? You stop firefighting. You ship faster. And your AI agents earn trust instead of losing it.\nWhy Teams Pick Noveum.ai\n- Faster time-to-value - No need to reinvent tracing + eval infra.\n- More reliable signal - Panel-of-LLMs > single-judge bias.\n- Production-first - Canary + shadow testing keep evals alive after launch.\n- Actionable insights - Not just chartsâ€”concrete next steps.\n- Scales with your roadmap - From one agent to many, from single prompt to multi-agent orchestration.\nFinal Thoughts\nAI agents are powerful, but theyâ€™re unpredictable without the right checks in place. Evals are how you turn that unpredictability into measurable, improvable performance.\nAt Noveum.ai, weâ€™re not just giving you dashboards. Weâ€™re giving you a system that helps your agents get better week after weekâ€”automatically.\nIf youâ€™re serious about shipping reliable AI agents, itâ€™s time to put evals at the center of your workflow.\nğŸ‘‰ Contact our cofounder at [email protected] or book a call here: https://calendly.com/aditi-noveum\nGet Early Access to Noveum.ai Platform\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "content_length": 6415,
    "internal_links": [],
    "scraped_at": 1759935899.3275049
  },
  {
    "url": "https://noveum.ai/en/blog/gpt-oss-vs-gpt-5-vs-gpt-4o-mini-mmlu-evaluation-report",
    "title": "GPT-OSS vs GPT-5 vs GPT-4o-mini â€” MMLU Benchmark Comparison (Accuracy, Runtime, Thinking Modes) | Noveum.ai",
    "content": "GPT-OSS vs GPT-5 vs GPT-4o-mini â€” MMLU Benchmark Comparison (Accuracy, Runtime, Thinking Modes)\nShivam Gupta\n8/13/2025\nGenerated on: 2025-08-13\nThis report is a plain-English summary of how seven model setups perform on the MMLU benchmark across 10 subjects (about 500 questions each). We compare:\n- accuracy (who gets the most answers right)\n- speed/runtime (how fast the models finish)\n- the impact of GPT-OSS â€œthinking modesâ€ (low, medium, high, unspecified) on results and efficiency\nUse this to quickly choose the model or mode that best fits your needsâ€”fastest, most accurate, or most consistent.\nTL;DR\n- Most accurate: GPT-5 (91.38%)\n- Best speed/efficiency: GPT-OSS (low thinking mode)\n- Best balance (accuracy + runtime): O3 or GPT-OSS (medium thinking mode)\n1. Overall Model Performance\nThe evaluation tested 7 model configurations across different thinking modes, revealing significant performance variations and the impact of reasoning strategies:\n| Model | Accuracy | Questions | Performance Rank | Thinking Mode |\n|---|---|---|---|---|\n| GPT-5 (OpenAI) | 91.38% | 500 | 1st | unspecified |\n| O3 (OpenAI) | 88.60% | 500 | 2nd | unspecified |\n| GPT-OSS (unspecified) | 88.40% | 500 | 3rd | unspecified |\n| GPT-OSS (medium) | 87.20% | 500 | 4th | medium |\n| GPT-OSS (low) | 84.77% | 499 | 5th | low |\n| GPT-OSS (high) | 83.00% | 500 | 6th | high |\n| GPT-4o-mini (OpenAI) | 74.20% | 500 | 7th | unspecified |\nPerformance Insights:\n- Clear leader: GPT-5 tops accuracy (91.38%)\n- Strong contenders: O3 (88.60%) and GPT-OSS (unspecified: 88.40%)\n- Long tail: GPT-4o-mini trails at 74.20%\n- Gap: 17.18pp between first and last\n2. Subject-Wise Performance Analysis\nThe evaluation covered 10 academic subjects, revealing subject-specific strengths and weaknesses across all models:\nTop Performing Subjects\n- Elementary Mathematics: 95.71% average accuracy\n- College Physics: 94.29% average accuracy\n- Conceptual Physics: 90.57% average accuracy\nMost Challenging Subjects\n- College Chemistry: 63.63% average accuracy\n- College Mathematics: 81.43% average accuracy\n- High School Mathematics: 83.69% average accuracy\nSubject Difficulty Analysis:\n- Hardest: College Chemistry (36.37% difficulty)\n- Easiest: Elementary Mathematics (4.29% difficulty)\n- Pattern: Physics stays strong; advanced math varies by model\nSubject-Specific Performance Patterns:\nAbstract Algebra: GPT-OSS models dominate the top 2 positions, with both high and medium thinking modes achieving 92% accuracy. This suggests that GPT-OSS excels at mathematical reasoning tasks when given appropriate thinking parameters.\nCollege Chemistry: All models struggle, with GPT-5 performing best at 71.43%. The subject shows the highest variability, indicating fundamental challenges in chemical reasoning that persist across all thinking strategies.\nCollege Mathematics: O3 leads with 94% accuracy, followed closely by GPT-5. GPT-OSS models show consistent performance around 88%, suggesting good mathematical capabilities regardless of thinking mode.\nPhysics Subjects: Both college and conceptual physics show strong performance across models, with GPT-OSS low thinking mode achieving perfect scores in college physics, indicating efficient reasoning for physics problems.\nElementary Mathematics: All models perform exceptionally well (94%+), with GPT-5 leading at 98%. This suggests that basic mathematical reasoning is well-handled by all models.\n3. Thinking Mode Effects Analysis\nThe GPT-OSS model was tested across four thinking modes using an A100 40GB GPU, revealing critical insights into the relationship between reasoning depth and performance:\nThinking Mode Performance Comparison\n| Mode | Accuracy | Avg Thinking Tokens | GPU Runtime | Efficiency |\n|---|---|---|---|---|\n| Unspecified | 88.40% | 384.60 Â± 532.24 | 135.57s | Best Balance |\n| Medium | 87.20% | 390.57 Â± 570.66 | 138.42s | Most Efficient |\n| Low | 84.77% | 76.55 Â± 84.97 | 57.49s | Most Runtime-Efficient |\n| High | 83.00% | 1061.48 Â± 1311.63 | 279.54s | Least Efficient |\nKey Insights:\n- Low mode = fastest good-enough results (best runtime/accuracy tradeoff)\n- Medium mode = balanced choice for most workloads\n- Unspecified = highest accuracy within GPT-OSS, with extra runtime\n- High mode = slowest and often worse; use only for niche deep-reasoning cases\nRuntime-Performance Trade-offs:\n- Low mode: 0.68 seconds per percentage point of accuracy\n- Medium mode: 1.59 seconds per percentage point of accuracy\n- Unspecified mode: 1.53 seconds per percentage point of accuracy\n- High mode: 3.37 seconds per percentage point of accuracy\n4. Token Usage and Efficiency\nEfficiency Curves\n- Low mode: Best at 2â€“59 tokens (~90%); noticeable drop beyond 170 tokens\n- Medium mode: Broad sweet spot 15â€“446 tokens (~92.65%); balanced overall\n- High mode: Diminishing returns; accuracy declines past ~2500 tokens\n- Unspecified: Reliable 17â€“428 tokens (~93.77%); steady decline with complexity\n5. Runtime vs Accuracy\nRuntime-Effectiveness Rankings\n- Low Thinking Mode: 57.49s for 84.77% accuracy\n- Runtime per percentage point: 0.68s\n- Best value proposition for time-sensitive applications\n- Medium Thinking Mode: 138.42s for 87.20% accuracy\n- Runtime per percentage point: 1.59s\n- Good balance of performance and runtime\n- Unspecified Mode: 135.57s for 88.40% accuracy\n- Runtime per percentage point: 1.53s\n- Premium performance at higher runtime cost\n- High Thinking Mode: 279.54s for 83.00% accuracy\n- Runtime per percentage point: 3.37s\n- Least efficient option\nRuntime-Performance Insights:\n- Best ROI: Low mode\n- Best balance: Medium mode\n- Premium accuracy: Unspecified\n- Avoid: High mode unless required\nHow to choose (quick guide)\n- Max accuracy: Choose GPT-5\n- Speed/cost-sensitive: Choose GPT-OSS with thinking mode = low\n- Balanced: Choose O3 or GPT-OSS with thinking mode = medium\n- Chemistry-heavy workloads: Validate on your data; consider domain-tuned models\n6. Consistency (Subject Variance)\nConsistency Rankings (Lower CV = More Consistent)\n| Model | Mean Accuracy | CV | Consistency Rank |\n|---|---|---|---|\n| GPT-5 (OpenAI) | 91.34% | 8.58% | Most Consistent |\n| GPT-OSS Medium | 87.20% | 10.16% | 2nd |\n| GPT-OSS Unspecified | 88.40% | 10.21% | 3rd |\n| O3 (OpenAI) | 88.60% | 10.49% | 4th |\n| GPT-OSS Low | 84.78% | 11.60% | 5th |\n| GPT-OSS High | 83.00% | 11.82% | 6th |\n| GPT-4o-mini | 74.20% | 19.49% | Least Consistent |\nConsistency Insights:\n- GPT-5 shows remarkable consistency across subjects despite high performance\n- GPT-4o-mini exhibits high variability, suggesting subject-specific weaknesses\n- GPT-OSS models show moderate consistency with thinking mode effects\n- O3 model shows competitive performance (88.60%) with moderate consistency, positioning it as a strong alternative to GPT-5\n7. Thinking Tokens vs Accuracy\nThinking Token vs. Accuracy Correlations\nAll GPT-OSS models show negative correlations between thinking tokens and accuracy:\n- High Mode: -0.56 (strongest negative correlation)\n- Unspecified Mode: -0.38 (moderate negative correlation)\n- Medium Mode: -0.27 (moderate negative correlation)\n- Low Mode: Insufficient data for correlation (most responses use minimal tokens)\nInterpretation:\n- More thinking tokens correlate with lower accuracy\n- This suggests that simpler, more direct reasoning lead to better performance\n- Complex reasoning may introduce errors or overthinking\n- The relationship is consistent across all thinking modes for GPT-OSS 20B\n- High thinking mode shows the strongest negative correlation, indicating the most significant performance degradation with increased complexity\n8. Outliers (College Chemistry)\nSubject Outlier: College Chemistry\n- Z-score: -2.5354 (statistically significant outlier)\n- Mean Accuracy: 63.63%\n- Outlier Type: Low performer\nAnalysis:\n- College Chemistry shows significantly lower performance than expected\n- All models struggle with this subject, suggesting fundamental challenges\n- GPT-5 performs best at 71.43%, but even this is not good\n- The subject may require specialized knowledge or reasoning patterns not well-represented in the training data\n- Thinking mode variations show minimal impact, indicating the challenge is fundamental rather than reasoning-strategy dependent\n9. Recommendations\nFor Production Use\n- Runtime-Sensitive Applications: Use GPT-OSS with low thinking mode for best speed-accuracy ratio\n- Performance-Critical Applications: Use GPT-5 for maximum accuracy and consistency\n- Balanced Applications: Use O3 for high performance with moderate runtime, or GPT-OSS with medium thinking mode\n- Enterprise Applications: Consider O3 as a cost-effective alternative to GPT-5 when 88.6% accuracy is sufficient\nFor Research and Development\n- Consistency Studies: Focus on GPT-5 model for stable performance across subjects\n- Efficiency Optimization: Study low thinking mode patterns for runtime reduction\n- Subject-Specific Tuning: Develop specialized models for challenging subjects like Chemistry\n- Thinking Mode Research: Investigate why high thinking modes show performance degradation\nFor Model Selection\n- Academic Applications: Prioritize GPT-5 for comprehensive coverage, with O3 as a strong alternative\n- Resource-Constrained Environments: Choose GPT-OSS low thinking mode\n- Real-Time Applications: Consider medium thinking mode for speed-accuracy balance\n- Enterprise Deployments: O3 offers an excellent balance of performance (88.6%) and runtime efficiency\n10. Limitations and Future Work\nCurrent Limitations\n- All models have consistent sample sizes (approximately 500 questions each)\n- Single evaluation run per model configuration\n- Focus on GPT-OSS thinking modes only\n- Limited subject coverage (10 out of 57 MMLU subjects)\n- Runtime measurements based on A100 40GB GPU performance\nFuture Research Directions\n- Extended Subject Coverage: Evaluate all 57 MMLU subjects\n- Multiple Runs: Assess model consistency across multiple evaluations\n- Thinking Mode Optimization: Develop adaptive thinking mode selection based on problem complexity\n- Runtime Analysis: Include latency and throughput metrics across different GPU configurations\n- Cross-Model Comparison: Evaluate thinking modes across different model architectures\n- Performance Degradation Study: Investigate why high thinking modes show worse performance\nConclusion\nThis comprehensive MMLU evaluation provides critical insights into model performance, efficiency, and runtime characteristics across different thinking strategies. Key takeaways include:\n- GPT-5 remains the performance leader with excellent consistency (91.38% accuracy, 8.58% CV)\n- O3 emerges as a strong competitor with 88.6% accuracy, offering enterprise-grade performance\n- GPT-OSS offers excellent runtime-performance ratios across different thinking modes\n- Low thinking mode provides the best value for GPU runtime (57.49s for 84.77% accuracy)\n- Subject difficulty varies significantly, with Chemistry being most challenging (36.37% difficulty)\n- Model consistency varies widely, with GPT-5 showing remarkable stability\n- Thinking token efficiency shows that simpler reasoning often leads to better performance\n- High thinking modes show performance degradation, challenging the assumption that more complex reasoning improves results\nKey takeaways:\n- GPT-5 leads in accuracy and consistency (91.38%, CV 8.58%)\n- O3 is a strong, fast alternative (88.6%)\n- GPT-OSS (low mode) delivers the best speed/accuracy tradeoff\n- Chemistry is hardest; validate domain-specific workloads\n- More tokens â‰  better: excessive thinking often reduces accuracy\nPractical implication: prefer simpler, focused reasoning by default; scale up thinking depth only when problems demand it.\nReport generated from MMLU evaluation data covering 7 model configurations, 4 thinking modes, and 10 academic subjects across approximately 500 total samples per model. GPU runtime measurements based on A100 40GB GPU performance. Analysis generated on 2025-08-13.\nGet Early Access to Noveum.ai Platform\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "content_length": 12117,
    "internal_links": [],
    "scraped_at": 1759935900.21145
  },
  {
    "url": "https://noveum.ai/en/blog/comprehensive-mmlu-evaluation-analysis-report",
    "title": "o1-mini vs gpt-4o-mini â€” What We Learned from 1,000 MMLU Samples | Noveum.ai",
    "content": "o1-mini vs gpt-4o-mini â€” What We Learned from 1,000 MMLU Samples\nShashank Agarwal\n8/12/2025\no1-mini vs gpt-4o-mini: MMLU math comparison\nWe compared Azure o1-mini and gpt-4o-mini on 1,000 MMLU math questions across 10 subjects using NovaEval. The goal was simple: learn when paying more for o1â€‘mini actually makes sense.\nKey takeaways\n- o1â€‘mini: 73.3% vs gptâ€‘4oâ€‘mini: 57.2% (+16.1pp, p < 0.001)\n- Similar throughput and reliability for both models\n- o1â€‘mini costs ~15Ã— more per request; payoff depends on the cost of a wrong answer\nHow we tested\n- Dataset: 1,000 MMLU math questions; 809 processed per model after filtering/timeouts\n- Setup: Azure OpenAI deployments, identical prompts, seed 42, 10 workers\n- Framework: NovaEval with retries, checkpointing, and consistent answer extraction\nDetailed Results\nOverall Performance Metrics\n| Metric | gpt-4o-mini | o1-mini | Difference |\n|---|---|---|---|\n| Accuracy | 57.2% | 73.3% | +16.1% |\n| Correct Answers | 463/809 | 593/809 | +130 |\n| Processing Speed | 2.10 samples/sec | 2.27 samples/sec | +0.17 |\n| Total Time | 385.8 seconds | 357.0 seconds | -28.8s |\n| Error Rate | 0.2% (2 errors) | 0.1% (1 error) | -0.1% |\n| Status | Partial errors | Partial errors | - |\nStatistical Significance Analysis\n- Z-score: 5.24 (highly significant)\n- P-value: < 0.001 (extremely significant)\n- Effect Size (Cohen's h): 0.334 (Medium effect)\n- 95% Confidence Interval: [10.0%, 22.2%]\n- Statistical Power: > 99% (highly powered study)\nThe results demonstrate statistically significant and practically meaningful performance differences between the models.\nSubject-wise Performance Analysis\nPerformance by Mathematical Domain\n| Subject | gpt-4o-mini | o1-mini | Difference | Significant* |\n|---|---|---|---|---|\n| Abstract Algebra | 36.4% | 58.2% | +21.8% | âœ“ |\n| College Mathematics | 37.3% | 67.8% | +30.5% | âœ“ |\n| College Physics | 49.2% | 71.2% | +22.0% | âœ“ |\n| College Chemistry | 52.5% | 74.6% | +22.1% | âœ“ |\n| Conceptual Physics | 80.0% | 81.0% | +1.0% | âœ— |\n| Elementary Mathematics | 80.0% | 89.0% | +9.0% | âœ— |\n| High School Chemistry | 55.9% | 76.3% | +20.4% | âœ“ |\n| High School Mathematics | 40.7% | 79.7% | +39.0% | âœ“ |\n| High School Physics | 54.2% | 74.6% | +20.4% | âœ“ |\n| High School Statistics | 55.9% | 61.0% | +5.1% | âœ— |\n- Statistical significance at p < 0.05 level\nKey Subject Insights\n- Largest Performance Gap: High School Mathematics (39.0% difference)\n- Most Consistent Performance: Elementary Mathematics (both models > 80%)\n- Significant Improvements: 7 out of 10 subjects show statistically significant gains\n- College-level Advantage: o1-mini shows particularly strong performance in college-level subjects\nConfidence and Quality Analysis\nAnswer Extraction Confidence\n| Model | Overall Confidence | Correct Answers | Incorrect Answers |\n|---|---|---|---|\n| gpt-4o-mini | 0.859 | 0.859 | 0.859 |\n| o1-mini | 0.859 | 0.859 | 0.859 |\nBoth models demonstrate identical confidence patterns, suggesting consistent answer extraction methodology across different model architectures.\nResponse Quality Metrics\n- Average Response Length:\n- gpt-4o-mini: ~800 characters\n- o1-mini: ~850 characters\n- Extraction Success Rate: 99.9% for both models\n- Processing Reliability: > 99.8% success rate\nTechnical Implementation Details\nNovaEval Integration\nThe evaluation utilized a custom NovaEval implementation with the following components:\n- Azure OpenAI Client: Custom integration supporting both models\n- Answer Extraction: Multi-pattern regex-based extraction with confidence scoring\n- Concurrent Processing: 10-worker parallel processing for efficiency\n- Error Handling: Robust retry logic and checkpoint saving\nAnswer Extraction Methodology\n# Primary extraction patterns (in order of confidence)\npatterns = [\nr'^([A-D])', # Letter at start (confidence: 1.0)\nr'\\b([A-D])\\b', # Single letter (confidence: 0.9)\nr'answer\\s*is\\s*([A-D])', # \"answer is X\" (confidence: 0.8)\nr'([A-D])\\.', # Letter with period (confidence: 0.7)\nr'\\(([A-D])\\)', # Letter in parentheses (confidence: 0.6)\n# ... additional patterns with decreasing confidence\n]\nQuality Assurance\n- Reproducibility: Fixed random seed (42) ensures consistent results\n- Validation: Cross-validation with manual spot-checks\n- Error Monitoring: Real-time error tracking and logging\n- Checkpoint System: Regular saves prevent data loss\nCost Analysis\n- o1-mini costs 15x more than gpt-4o-mini ($0.001720 vs $0.000115 per request)\n- Break-even point: ~$0.01 per incorrect answer makes o1-mini cost-effective\n- ROI threshold: Applications where errors cost â‰¥$0.01 show positive ROI\n- Performance premium: 28% relative accuracy improvement for ~1,396% cost increase\nCost Breakdown Analysis\nTotal Evaluation Costs\n| Model | Total Cost | Cost per Request | Cost per Correct Answer | Accuracy |\n|---|---|---|---|---|\n| gpt-4o-mini | $0.0928 | $0.000115 | $0.000201 | 57.2% |\n| o1-mini | $1.3912 | $0.001720 | $0.002346 | 73.3% |\n| Difference | +$1.2984 | +$0.001605 | +$0.002145 | +16.1% |\nToken Usage Economics\ngpt-4o-mini Token Analysis:\n- Total Input Tokens: 154,036 (80.3% of total)\n- Total Output Tokens: 37,782 (19.7% of total)\n- Total Tokens: 191,818\n- Input Cost Share: 37.2% ($0.0345)\n- Output Cost Share: 62.8% ($0.0583)\no1-mini Token Analysis:\nToken breakdown omitted pending verified usage data. We will update this section with non-estimated counts to avoid artifacts.\nNote: Token estimation based on 1 token â‰ˆ 4 characters approximation\nBreak-Even Analysis\nCritical Break-Even Thresholds\nPrimary Break-Even Point: ~$0.01 per incorrect answer\n- With a per-request cost delta of $0.001605 and an accuracy delta of 0.161, the break-even error cost is: break-even â‰ˆ 0.001605 / 0.161 â‰ˆ $0.00997 per error (â‰ˆ $0.01). Example (10,000 requests): +1,610 additional correct answers at an added cost of ~$16.05.\nROI and Net Benefit (10K requests)\n- Net Benefit(10K, error_cost = C) â‰ˆ 1,610 Ã— C - $16.05\n- Examples:\n- C = $0.01 â†’ Net â‰ˆ $0.05 (â‰ˆ break-even)\n- C = $1.00 â†’ Net â‰ˆ $1,593.95\n- C = $10.00 â†’ Net â‰ˆ $16,083.95\nVolume-Based Break-Even Analysis\nScaling Economics (Cost Difference):\n| Request Volume | gpt-4o-mini Total Cost | o1-mini Total Cost | Cost Difference | Additional Correct |\n|---|---|---|---|---|\n| 100 | $0.01 | $0.17 | +$0.16 | 16 |\n| 1,000 | $0.12 | $1.72 | +$1.60 | 161 |\n| 10,000 | $1.15 | $17.20 | +$16.05 | 1,610 |\n| 100,000 | $11.50 | $172.00 | +$160.50 | 16,100 |\n| 1,000,000 | $115.00 | $1,720.00 | +$1,605.00 | 161,000 |\nUse Case Recommendations\nWhen o1-mini is Cost-Effective\nHigh-Value Applications (ROI > 100%)\n- Financial Trading Systems: Error cost $100-$10,000 per mistake\n- Medical Diagnosis Support: Error cost $1,000-$100,000 per mistake\n- Legal Document Analysis: Error cost $500-$50,000 per mistake\n- Quality Control Systems: Error cost $10-$1,000 per mistake\n- Critical Decision Support: Error cost $100-$10,000 per mistake\nMedium-Value Applications (ROI 25-100%)\n- Academic Research: Error cost $10-$100 per mistake\n- Business Intelligence: Error cost $50-$500 per mistake\n- Content Moderation: Error cost $1-$50 per mistake\n- Automated Grading: Error cost $5-$100 per mistake\nWhen gpt-4o-mini is Preferred\nCost-Sensitive Applications\n- Bulk Content Processing: High volume, low error cost\n- Development and Testing: Non-production environments\n- Exploratory Analysis: Initial data exploration\n- Non-Critical Evaluations: Low-stakes decision making\n- Budget-Constrained Projects: Limited financial resources\nSubject-Wise Cost Analysis\nCost Efficiency by Mathematical Domain\nTop Performing Subjects (o1-mini Cost Efficiency):\n| Subject | Accuracy | Cost per Request | Cost per Correct | Efficiency Score* |\n|---|---|---|---|---|\n| Elementary Mathematics | 89.0% | $0.00172 | $0.00193 | 517 |\n| Conceptual Physics | 81.0% | $0.00172 | $0.00212 | 471 |\n| High School Mathematics | 79.7% | $0.00172 | $0.00216 | 463 |\n| High School Physics | 74.6% | $0.00172 | $0.00231 | 434 |\n| College Chemistry | 74.6% | $0.00172 | $0.00231 | 434 |\n- Efficiency Score = (Accuracy / Cost per Request) Ã— 1000\nHighest Cost Premium Subjects:\n- High School Mathematics: 39.0% accuracy improvement, highest ROI\n- College Mathematics: 30.5% accuracy improvement, strong value\n- Abstract Algebra: 21.8% accuracy improvement, solid gains\nSubject-Specific Break-Even Analysis\nPremium Justified Subjects (Error cost threshold < $1.00):\n- High School Mathematics: $0.41 per error\n- College Mathematics: $0.53 per error\n- Abstract Algebra: $0.74 per error\nPremium Questionable Subjects (Error cost threshold > $2.00):\n- Conceptual Physics: $2.15 per error\n- Elementary Mathematics: $1.89 per error\n- High School Statistics: $3.21 per error\nStatistical Validation\nHypothesis Testing\nNull Hypothesis (Hâ‚€): No difference in accuracy between gpt-4o-mini and o1-mini Alternative Hypothesis (Hâ‚): o1-mini has higher accuracy than gpt-4o-mini\nTest Results:\n- Z-statistic: 5.24\n- Critical value: 1.96 (Î± = 0.05)\n- Decision: Reject Hâ‚€ (5.24 > 1.96)\n- Conclusion: Strong evidence for superior o1-mini performance\nEffect Size Interpretation\nCohen's h = 0.334 indicates a Medium Effect Size:\n- Small effect: h < 0.2\n- Medium effect: 0.2 â‰¤ h < 0.5\n- Large effect: h â‰¥ 0.5\nConfidence Intervals\nThe 95% confidence interval [10.0%, 22.2%] for the accuracy difference indicates:\n- Lower bound: o1-mini is at least 10.0% better\n- Upper bound: o1-mini could be up to 22.2% better\n- Point estimate: 16.1% improvement is most likely\nBusiness and Practical Implications\nModel Selection Guidance\nWhen to Choose o1-mini:\n- Mathematical reasoning tasks (73.3% accuracy advantage)\n- College-level problem solving (strong performance across all college subjects)\n- High-stakes applications where accuracy is paramount\n- Complex analytical tasks requiring step-by-step reasoning\nWhen to Consider gpt-4o-mini:\n- Cost-sensitive applications (if pricing differs significantly)\n- Simple mathematical tasks where 57.2% accuracy is sufficient\n- High-throughput scenarios where speed matters more than accuracy\n- General-purpose applications beyond mathematical reasoning\nPerformance-Cost Analysis\nBased on the evaluation results:\n- Performance Gain: 28% relative improvement (73.3% vs 57.2%)\n- Speed Difference: Minimal (2.27 vs 2.10 samples/sec)\n- Reliability: Comparable error rates (< 0.2% for both)\n- ROI Calculation: Depends on specific use case and pricing structure\nRisk Assessment\nLow Risk Factors:\n- Consistent performance across multiple mathematical domains\n- Statistical significance with large sample size (809 samples per model)\n- Reproducible results with proper methodology\n- Robust evaluation framework with error handling\nConsiderations:\n- Domain specificity: Results specific to mathematical reasoning\n- Sample representation: Limited to MMLU mathematical subjects\n- Model versions: Results tied to specific model deployments\nRecommendations\nImmediate Actions\n- Deploy o1-mini for mathematical applications with confidence\n- Implement A/B testing for specific use cases to validate results\n- Monitor performance in production environments\n- Establish quality metrics based on confidence scoring\nStrategic Considerations\n- Expand evaluation to other MMLU domains (science, humanities, etc.)\n- Conduct cost-benefit analysis based on actual pricing\n- Develop hybrid approaches leveraging strengths of both models\n- Create performance benchmarks for ongoing model evaluation\nQuality Assurance Framework\n- Confidence Thresholding: Flag responses with confidence < 0.7\n- Subject-specific Monitoring: Track performance by mathematical domain\n- Error Pattern Analysis: Identify and address systematic failures\n- Continuous Evaluation: Regular re-assessment with new model versions\nPrimary Findings\nThis comprehensive evaluation provides definitive evidence that o1-mini significantly outperforms gpt-4o-mini on mathematical reasoning tasks:\n- Substantial Accuracy Improvement: 16.1 percentage point gain (28% relative improvement)\n- Statistical Significance: p < 0.001 with large effect size\n- Broad Applicability: Consistent improvements across 7/10 mathematical subjects\n- Production Readiness: Reliable performance with minimal error rates\nScientific Rigor\nThe evaluation meets high standards for scientific rigor:\n- Large sample size (1,000 samples, 809 processed per model)\n- Proper statistical testing with appropriate methods\n- Reproducible methodology with documented procedures\n- Comprehensive analysis including effect sizes and confidence intervals\nBusiness Impact\nFor organizations requiring mathematical reasoning capabilities:\n- Clear model choice: o1-mini provides superior performance\n- Quantified benefits: 28% relative improvement in accuracy\n- Risk mitigation: Statistically validated results reduce deployment risk\n- Strategic advantage: Early adoption of superior reasoning capabilities\nFuture Directions\nThis evaluation establishes a gold standard methodology for model comparison and provides a foundation for future research into reasoning model capabilities. The results strongly support the adoption of o1-mini for mathematical reasoning applications while highlighting the importance of rigorous evaluation in model selection decisions\nGet Early Access to Noveum.ai Platform\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "content_length": 13352,
    "internal_links": [],
    "scraped_at": 1759935901.217552
  },
  {
    "url": "https://noveum.ai/en/blog/from-logs-to-intelligent-choices-inside-noveum-ais-evaluation-process",
    "title": "From Development to Production - Inside Noveum.ai's AI Observability Platform | Noveum.ai",
    "content": "From Development to Production - Inside Noveum.ai's AI Observability Platform\nShashank Agarwal\n3/3/2025\nIntroduction\nEvery AI application tells a storyâ€”but most developers never get to hear it. When your RAG pipeline returns irrelevant results, when your multi-agent system gets stuck in loops, or when your LLM costs suddenly spike, you're left guessing what went wrong and where.\nThat's exactly the challenge Noveum.ai solves. Rather than flying blind, our platform provides comprehensive tracing and observability specifically designed for AI applications. Whether you're building LLM-powered chatbots, RAG systems, or complex multi-agent workflows, Noveum.ai gives you the insights you need to understand, debug, and optimize your AI applications.\nThe AI Observability Challenge\nWhy Traditional Monitoring Falls Short\nTraditional application monitoring tools weren't built for AI applications. They can tell you if your API is responding, but they can't answer the questions that matter most for AI systems:\n- Why did my RAG pipeline retrieve irrelevant documents?\n- Which LLM calls are driving my costs?\n- How are my agents communicating with each other?\n- What's causing hallucinations in my responses?\n- Why is my embedding generation so slow?\nWhat Makes AI Applications Different\nAI applications have unique characteristics that require specialized observability:\n- ğŸ§  Context Flow: Data flows through embeddings, retrievals, and generations\n- ğŸ’° Variable Costs: Token usage creates unpredictable expenses\n- ğŸ”€ Complex Workflows: Multi-step pipelines with branching logic\n- ğŸ¤– Agent Interactions: Multiple AI entities coordinating tasks\n- ğŸ“Š Quality Metrics: Success isn't just about uptimeâ€”it's about output quality\nStep 1: SDK Integration\nEffortless Instrumentation\nAt the heart of Noveum.ai are our Python and TypeScript SDKs that integrate seamlessly into your existing codebase. With just a few lines of code, you can start capturing comprehensive traces of your AI operations.\nimport noveum_trace\n# Initialize once at startup\nnoveum_trace.init(\napi_key=\"your-api-key\",\nproject=\"customer-support-bot\",\nenvironment=\"production\"\n)\n# Trace LLM calls automatically\n@noveum_trace.trace_llm\ndef generate_response(user_question: str) -> str:\nreturn openai.chat.completions.create(\nmodel=\"gpt-4\",\nmessages=[{\"role\": \"user\", \"content\": user_question}]\n).choices[0].message.content\nWhat Gets Captured Automatically\nOnce integrated, Noveum.ai automatically captures:\n- ğŸ” Request/Response Data: Inputs, outputs, and transformations\n- â±ï¸ Performance Metrics: Latency, throughput, and bottlenecks\n- ğŸ’° Cost Tracking: Token usage and API costs across providers\n- ğŸ·ï¸ Rich Metadata: Model parameters, user context, and custom attributes\n- ğŸŒŠ Context Flow: How data moves through your AI pipeline\n- ğŸ› Error Details: Stack traces and failure analysis\nStep 2: Understanding Your AI Workflows\nRAG Pipeline Visibility\nRAG (Retrieval-Augmented Generation) systems involve multiple complex steps. Noveum.ai traces each phase, giving you complete visibility:\n@noveum_trace.trace(\"rag-pipeline\")\ndef answer_customer_question(question: str) -> str:\n# Phase 1: Query understanding\nwith noveum_trace.trace_step(\"query-analysis\") as step:\nintent = analyze_query_intent(question)\nstep.set_attribute(\"query.intent\", intent)\nstep.set_attribute(\"query.complexity\", get_complexity_score(question))\n# Phase 2: Document retrieval\nwith noveum_trace.trace_step(\"document-retrieval\") as step:\nembeddings = generate_embeddings(question)\ndocuments = vector_search(embeddings, k=5)\nstep.set_attribute(\"documents.retrieved\", len(documents))\nstep.set_attribute(\"documents.avg_similarity\", avg_similarity(documents))\nstep.set_attribute(\"retrieval.model\", \"text-embedding-ada-002\")\n# Phase 3: Answer generation\nwith noveum_trace.trace_step(\"answer-generation\") as step:\ncontext = build_context(documents)\nanswer = generate_answer_with_context(question, context)\nstep.set_attribute(\"context.length\", len(context))\nstep.set_attribute(\"answer.confidence\", calculate_confidence(answer))\nstep.set_attribute(\"generation.model\", \"gpt-4\")\nreturn answer\nMulti-Agent Coordination\nWhen multiple AI agents work together, Noveum.ai tracks their interactions and coordination:\nconst multiAgentTask = trace('customer-inquiry-resolution', async (inquiry: string) => {\n// Agent 1: Classification\nconst category = await span('classify-inquiry', async (spanInstance) => {\nspanInstance.setAttribute('agent.name', 'classifier');\nspanInstance.setAttribute('inquiry.length', inquiry.length);\nreturn await classificationAgent.categorize(inquiry);\n});\n// Agent 2: Research (if needed)\nlet context = null;\nif (category.needsResearch) {\ncontext = await span('research-context', async (spanInstance) => {\nspanInstance.setAttribute('agent.name', 'researcher');\nspanInstance.setAttribute('research.category', category.type);\nreturn await researchAgent.gatherContext(inquiry);\n});\n}\n// Agent 3: Response generation\nconst response = await span('generate-response', async (spanInstance) => {\nspanInstance.setAttribute('agent.name', 'responder');\nspanInstance.setAttribute('response.has_context', !!context);\nreturn await responseAgent.generate(inquiry, context);\n});\nreturn response;\n});\nStep 3: Real-Time Debugging and Optimization\nPerformance Bottleneck Identification\nNoveum.ai's dashboard automatically identifies performance issues:\n- ğŸŒ Slow Operations: Which LLM calls or embeddings are taking too long?\n- ğŸ”„ Redundant Processing: Are you generating the same embeddings multiple times?\n- ğŸ“Š Resource Usage: Which operations consume the most tokens or memory?\n- ğŸš¨ Error Patterns: What types of failures occur most frequently?\nCost Optimization Insights\nWith detailed cost tracking, you can optimize your AI spending:\n- Provider Comparison: See actual costs across OpenAI, Anthropic, Google, etc.\n- Model Analysis: Compare performance vs. cost for different models\n- Usage Patterns: Identify expensive operations and optimize them\n- Budget Alerts: Get notified when costs exceed thresholds\nQuality Assurance\nBeyond performance, Noveum.ai helps ensure output quality:\n- Response Analysis: Track confidence scores and quality metrics\n- A/B Testing: Compare different models or prompts\n- User Feedback: Correlate user satisfaction with trace data\n- Drift Detection: Identify when model performance degrades\nReal-World Example: Customer Support Bot\nLet's walk through a real example. You've built a customer support bot using RAG that helps users with product questions. Here's how Noveum.ai provides insights:\nDevelopment Phase\nDuring development, you discover through tracing that:\n- Embedding generation takes 200ms on average\n- Vector search finds relevant documents 85% of the time\n- Answer generation costs $0.02 per query with GPT-4\nProduction Deployment\nIn production, Noveum.ai reveals:\n- Peak usage occurs during business hours, causing latency spikes\n- Certain question types consistently retrieve irrelevant documents\n- Token usage is 30% higher than expected due to verbose context\nOptimization Cycle\nBased on these insights, you:\n- Cache embeddings for common questions (reduces latency by 60%)\n- Improve vector search by fine-tuning similarity thresholds\n- Switch to GPT-3.5 for simple questions (reduces costs by 40%)\n- Implement streaming for better user experience\nContinuous Improvement\nAs your bot evolves:\n- New conversation patterns are automatically captured\n- Quality metrics help identify areas for improvement\n- Cost trends inform capacity planning\n- Error analysis guides bug fixes and feature development\nAdvanced Observability Patterns\nCustom Metrics and Attributes\nNoveum.ai allows you to add domain-specific insights:\n@noveum_trace.trace(\"content-moderation\")\ndef moderate_content(text: str, user_id: str):\n# Add business context\nnoveum_trace.set_attribute(\"user.trust_level\", get_user_trust_level(user_id))\nnoveum_trace.set_attribute(\"content.category\", classify_content_type(text))\nnoveum_trace.set_attribute(\"moderation.policy_version\", \"v2.1\")\n# Perform moderation\nresult = run_content_moderation(text)\n# Add results\nnoveum_trace.set_attribute(\"moderation.risk_score\", result.risk_score)\nnoveum_trace.set_attribute(\"moderation.action_taken\", result.action)\nreturn result\nError Tracking and Alerting\nComprehensive error handling with actionable insights:\nconst processDocument = trace('document-processing', async (documentId: string) => {\ntry {\nconst result = await span('extract-text', async () => {\nreturn await extractTextFromDocument(documentId);\n});\nreturn await span('analyze-content', async (spanInstance) => {\nspanInstance.setAttribute('document.word_count', result.wordCount);\nspanInstance.setAttribute('document.language', result.language);\nreturn await analyzeContent(result.text);\n});\n} catch (error) {\n// Rich error context for debugging\nconst currentSpan = getCurrentSpan();\ncurrentSpan.setAttribute('error.type', error.constructor.name);\ncurrentSpan.setAttribute('error.message', error.message);\ncurrentSpan.setAttribute('error.recoverable', isRecoverableError(error));\ncurrentSpan.setStatus('ERROR', error.message);\nthrow error;\n}\n});\nThe Future of AI Observability\nWhat's Coming Next\nAs AI applications become more sophisticated, observability needs to evolve:\n- ğŸ¤– Agent Ecosystems: Observing complex multi-agent societies\n- ğŸ§  Reasoning Chains: Tracing LLM thought processes\n- ğŸ”„ Feedback Loops: Connecting user outcomes back to traces\n- ğŸ“Š Quality Metrics: Advanced measures of AI output quality\n- ğŸ›¡ï¸ Safety Monitoring: Detecting harmful or biased outputs\nBuilding Observability-First AI Applications\nThe future belongs to teams who build observability into their AI applications from day one:\n- Faster Debugging: Find and fix issues before they impact users\n- Data-Driven Optimization: Make decisions based on real usage patterns\n- Proactive Monitoring: Catch problems before they become incidents\n- Continuous Improvement: Use traces to guide development priorities\nConclusion\nThe power of Noveum.ai lies in its comprehensive observability approach:\n- ğŸš€ Easy Integration: Start tracing with minimal code changes\n- ğŸ” Deep Insights: Understand every aspect of your AI workflows\n- ğŸ“Š Actionable Analytics: Make data-driven optimization decisions\n- ğŸ› ï¸ Developer-Friendly: Built by AI engineers, for AI engineers\nEvery API call, every embedding generation, every agent interaction becomes part of a bigger picture that helps you build better AI applications. Instead of guessing why something went wrong, you have concrete data and detailed traces to guide your decisions.\nWhether you're debugging a complex RAG pipeline, optimizing multi-agent coordination, or simply trying to reduce your AI costs, Noveum.ai provides the visibility you need to succeed.\nReady to see your AI applications like never before? Start tracing today or talk to our team about your specific observability needs. We're here to help you build AI applications that are transparent, optimized, and reliableâ€”one trace at a time.\nGet Early Access to Noveum.ai Platform\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "content_length": 11174,
    "internal_links": [],
    "scraped_at": 1759935902.2391648
  },
  {
    "url": "https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform",
    "title": "Noveum.ai - Comprehensive AI Tracing and Observability Platform | Noveum.ai",
    "content": "Noveum.ai - Comprehensive AI Tracing and Observability Platform\nShashank Agarwal\n3/2/2025\nIntroduction\nArtificial Intelligence applications are becoming increasingly complex, with multi-step workflows, RAG pipelines, and sophisticated agent systems. But how do you debug when things go wrong? How do you optimize performance? How do you understand what's happening inside your AI applications? That's where Noveum.ai comes in.\nIn this post, I'll walk you through what Noveum.ai is, how it works, and why I believe it's essential for teams building production AI applications. My name is Shashank Agarwalâ€”founder of Noveum.ai, AI enthusiast, and someone who's been building and scaling large AI/ML platforms for over a decade. Let's dive in.\nWhy Noveum.ai?\nBuilding production AI applications involves complex workflows with multiple components: LLM calls, vector searches, data retrieval, agent reasoning, and more. Without proper observability, debugging becomes a nightmare, optimization is guesswork, and understanding user interactions is nearly impossible.\nNoveum.ai solves this by providing comprehensive tracing and observability specifically designed for AI applications.\nKey benefits of using Noveum.ai:\n- Complete Visibility: Trace every step of your LLM calls, RAG pipelines, and agent workflows\n- Easy Integration: Simple SDKs for Python and TypeScript with minimal code changes\n- Multi-Agent Support: Built-in support for complex multi-agent systems and workflows\n- Performance Insights: Detailed metrics on latency, token usage, costs, and success rates\n- Error Tracking: Automatic error capture and analysis for faster debugging\n- Framework Agnostic: Works with any LLM provider, framework, or architecture\nHow It Works\nStep 1: Install and Initialize the SDK\nNoveum.ai provides native SDKs for both Python and TypeScript applications. Getting started takes just minutes:\nPython SDK\npip install noveum-trace\nimport noveum_trace\n# Initialize the SDK\nnoveum_trace.init(\napi_key=\"your-noveum-api-key\",\nproject=\"my-ai-application\",\nenvironment=\"production\"\n)\nTypeScript SDK\nnpm install @noveum/trace\nimport { initializeClient } from '@noveum/trace';\nconst client = initializeClient({\napiKey: \"your-noveum-api-key\",\nproject: \"my-ai-application\",\nenvironment: \"production\",\n});\nStep 2: Add Tracing to Your Code\nWith Noveum.ai, adding comprehensive tracing to your AI applications is as simple as adding decorators or function calls:\nPython Examples\nBasic LLM Tracing:\n@noveum_trace.trace_llm\ndef call_openai(prompt: str) -> str:\nclient = openai.OpenAI()\nresponse = client.chat.completions.create(\nmodel=\"gpt-4\",\nmessages=[{\"role\": \"user\", \"content\": prompt}]\n)\nreturn response.choices[0].message.content\nMulti-Agent Workflows:\n@noveum_trace.trace_agent(agent_id=\"orchestrator\")\ndef orchestrate_workflow(task: str) -> dict:\n# Coordinate multiple agents\nresearch_result = research_agent(task)\nanalysis_result = analysis_agent(research_result)\nreturn synthesis_agent(research_result, analysis_result)\n@noveum_trace.trace_agent(agent_id=\"researcher\")\ndef research_agent(task: str) -> dict:\n# Research implementation with automatic tracing\nreturn {\"data\": \"...\", \"sources\": [...]}\nRAG Pipeline Tracing:\n@noveum_trace.trace_retrieval\ndef retrieve_documents(query: str) -> list:\n# Vector search implementation\nreturn vector_db.search(query)\n@noveum_trace.trace\ndef rag_pipeline(user_query: str) -> str:\ndocuments = retrieve_documents(user_query)\ncontext = prepare_context(documents)\nreturn generate_response(user_query, context)\nTypeScript Examples\nBasic Tracing:\nconst result = await trace('user-query-processing', async (traceInstance) => {\ntraceInstance.setAttribute('user.id', userId);\ntraceInstance.setAttribute('query.type', 'search');\n// Create spans for sub-operations\nconst embeddings = await span('generate-embeddings', async () => {\nreturn await openai.embeddings.create({\nmodel: 'text-embedding-ada-002',\ninput: userQuery,\n});\n});\nconst searchResults = await span('vector-search', async () => {\nreturn await vectorDB.search(embeddings.data[0].embedding);\n});\nreturn searchResults;\n});\nNext.js Integration:\n// app/api/chat/route.ts\nimport { withNoveumTracing } from '@noveum/trace/integrations/nextjs';\nexport const POST = withNoveumTracing(\nasync (request: NextRequest) => {\nconst { message } = await request.json();\nconst response = await processMessage(message);\nreturn NextResponse.json(response);\n},\n{\nclient,\nspanName: 'chat-completion',\ncaptureRequest: true,\n}\n);\nStep 3: Automatic Data Collection\nOnce integrated, Noveum.ai automatically captures:\n- Request/Response Data: Complete LLM prompts, responses, and parameters\n- Performance Metrics: Latency, token usage, throughput, and costs\n- Error Information: Stack traces, error messages, and failure patterns\n- Agent Interactions: Multi-agent communication and coordination patterns\n- Custom Attributes: Any additional context you want to track\nRich Metadata Example\n{\n\"trace_id\": \"trace_abc123\",\n\"span_id\": \"span_def456\",\n\"operation\": \"llm_completion\",\n\"model\": \"gpt-4\",\n\"provider\": \"openai\",\n\"duration_ms\": 1250,\n\"token_usage\": {\n\"input_tokens\": 150,\n\"output_tokens\": 75,\n\"total_tokens\": 225\n},\n\"cost\": {\n\"input_cost\": 0.0045,\n\"output_cost\": 0.0075,\n\"total_cost\": 0.012\n},\n\"attributes\": {\n\"user_id\": \"user_123\",\n\"session_id\": \"session_456\",\n\"query_type\": \"search\"\n},\n\"status\": \"success\"\n}\nStep 4: Analyze and Debug with the Dashboard\nNoveum.ai provides powerful dashboards to help you:\n- Trace Visualization: See complete request flows through your AI pipelines\n- Performance Analytics: Identify bottlenecks and optimization opportunities\n- Cost Analysis: Track spending across models, users, and features\n- Error Investigation: Quickly identify and debug issues in production\n- Agent Behavior: Understand how your multi-agent systems are performing\nStep 5: Continuous Optimization\nWith comprehensive tracing in place, you can:\n- A/B Test Models: Compare different LLMs on real production traffic\n- Optimize Prompts: See which prompts perform best for different use cases\n- Reduce Costs: Identify expensive operations and optimize them\n- Improve Quality: Monitor output quality and user satisfaction\n- Scale Confidently: Understand system behavior under load\nReal-World Example: RAG-Powered Customer Support\nImagine you're building an AI-powered customer support system with a RAG pipeline:\n- User Query: Customer asks about pricing\n- Document Retrieval: System searches knowledge base\n- Context Preparation: Relevant documents are processed\n- LLM Generation: GPT-4 generates response with context\n- Response Delivery: Answer is sent to customer\nWithout Noveum.ai: When the system gives wrong answers, you have no visibility into what went wrong. Was it poor retrieval? Bad context preparation? LLM hallucination?\nWith Noveum.ai: Every step is traced:\n@noveum_trace.trace\ndef handle_support_query(user_query: str, user_id: str) -> str:\n# Each step is automatically traced\n# Step 1: Query analysis\nquery_intent = analyze_query_intent(user_query)\n# Step 2: Document retrieval\nrelevant_docs = retrieve_documents(user_query, query_intent)\n# Step 3: Context preparation\ncontext = prepare_context(relevant_docs)\n# Step 4: LLM generation\nresponse = generate_response(user_query, context)\n# Step 5: Response validation\nvalidated_response = validate_response(response, user_query)\nreturn validated_response\nNow you can see:\n- Which queries are taking too long (retrieval vs. generation)\n- When retrieval is returning irrelevant documents\n- How much each interaction costs\n- Which responses users rate poorly\n- Complete audit trail for compliance\nAdvanced Features\nMulti-Agent System Observability\n@noveum_trace.trace_agent(agent_id=\"coordinator\")\ndef coordinate_research_project(topic: str) -> dict:\n# Assign tasks to specialist agents\nliterature_review = literature_agent(topic)\ndata_analysis = data_agent(topic)\nsynthesis = synthesis_agent(literature_review, data_analysis)\nreturn {\n\"literature\": literature_review,\n\"analysis\": data_analysis,\n\"synthesis\": synthesis\n}\nCustom Sampling and Filtering\nnoveum_trace.init(\napi_key=\"your-key\",\nproject=\"my-project\",\ntransport_config={\n\"sample_rate\": 0.1, # Sample 10% of traces\n\"capture_errors\": True, # Always capture errors\n\"capture_stack_traces\": False # Skip stack traces for performance\n}\n)\nContext Propagation\n// Automatic context propagation across async operations\nconst contextManager = getGlobalContextManager();\nawait contextManager.withSpan(span, async () => {\n// This function runs with span in context\nawait someNestedOperation();\n});\nWhy Choose Noveum.ai?\n- AI-Native Design: Built specifically for LLM applications, not generic APM tools\n- Easy Integration: Minutes to get started, not days of configuration\n- Framework Agnostic: Works with any LLM provider, vector database, or framework\n- Production Ready: Built for scale with intelligent sampling and batching\n- Privacy Focused: You control what data is captured and how it's stored\n- Open Source SDKs: Transparent, auditable, and extensible\nGetting Started\nReady to add comprehensive observability to your AI applications?\n- Sign up at noveum.ai\n- Create a project and get your API key\n- Install the SDK for your preferred language\n- Add tracing to your AI workflows\n- Explore insights in the Noveum.ai dashboard\nCheck out our integration guide for detailed setup instructions and examples.\nWrapping Up\nNoveum.ai brings the observability your AI applications deserve. No more black box debugging or guessing why your RAG pipeline failed. With comprehensive tracing, you get complete visibility into every LLM call, agent interaction, and data flow.\nThe AI landscape is complex and moving fast. With Noveum.ai, you'll have the insights you need to build, debug, and optimize AI applications with confidence.\nReady to see what's really happening inside your AI applications? Try Noveum.ai today and transform how you build and monitor AI systems.\nLet's build more reliable, observable AIâ€”together.\nGet Early Access to Noveum.ai Platform\nJoin the select group of AI teams optimizing their models with our data-driven platform. We're onboarding users in limited batches to ensure a premium experience.",
    "content_length": 10177,
    "internal_links": [
      "https://noveum.ai/integration"
    ],
    "scraped_at": 1759935903.28646
  },
  {
    "url": "https://noveum.ai/en/legal/privacy-policy",
    "title": "Privacy Policy | Noveum.ai",
    "content": "Privacy Policy\nThis is the placeholder page for your privacy policy. Edit the content/legal/privacy-policy.md\nfile to add your own content here.\nThis is the placeholder page for your privacy policy. Edit the content/legal/privacy-policy.md\nfile to add your own content here.",
    "content_length": 274,
    "internal_links": [],
    "scraped_at": 1759935904.1824288
  },
  {
    "url": "https://noveum.ai/en/legal/terms",
    "title": "Terms and conditions | Noveum.ai",
    "content": "Terms and conditions\nThis is the placeholder page for your terms and conditions. Edit the content/legal/terms.md\nfile to add your own content here.\nThis is the placeholder page for your terms and conditions. Edit the content/legal/terms.md\nfile to add your own content here.",
    "content_length": 274,
    "internal_links": [],
    "scraped_at": 1759935905.058074
  },
  {
    "url": "https://noveum.ai/en/docs/getting-started/tracing-concepts",
    "title": "Tracing Concepts for AI Applications | Documentation | Noveum.ai",
    "content": "Tracing Concepts for AI Applications\nUnderstanding traces, spans, and observability fundamentals for LLM applications, RAG systems, and AI agents\nUnderstanding the fundamentals of tracing is essential for getting the most out of Noveum.ai. This guide explains key concepts specifically in the context of AI applications, helping you design effective observability strategies for your LLM applications, RAG systems, and AI agents.\nğŸ¯ What is Tracing?\nTracing is the practice of tracking requests as they flow through your system, creating a detailed map of what happened, when, and how long each operation took. For AI applications, tracing provides crucial insights into:\n- ğŸ” Request Flow: How user queries move through your AI pipeline\n- â±ï¸ Performance: Where time is spent in your AI operations\n- ğŸ’° Costs: Which operations drive your AI spending\n- ğŸ› Debugging: What went wrong when errors occur\n- ğŸ“Š Quality: How well your AI system is performing\nğŸŒŸ Core Concepts\n1. Traces\nA trace represents a single journey through your systemâ€”like a user asking a question and getting an answer. Think of it as the complete story of one request.\nTrace Characteristics:\n- ğŸ†” Unique ID: Every trace has a unique identifier\n- â° Timeline: Start and end timestamps\n- ğŸŒ Distributed: Can span multiple services\n- ğŸ“Š Hierarchical: Contains multiple related spans\n2. Spans\nA span represents a single operation within a trace. Each span has a clear start and end time and represents work being done.\nSpan Characteristics:\n- ğŸ“› Name: Descriptive name of the operation\n- â±ï¸ Duration: How long the operation took\n- ğŸ‘¥ Parent-Child: Spans can contain other spans\n- ğŸ·ï¸ Attributes: Key-value metadata about the operation\n- ğŸ“ Events: Point-in-time occurrences during the span\n3. Attributes\nAttributes are key-value pairs that provide context about what happened during a span. They're crucial for understanding and filtering your traces.\nCommon AI Attribute Categories:\n- ğŸ¤– LLM Attributes:\nllm.model\n,llm.provider\n,llm.temperature\n- ğŸ’° Cost Attributes:\nllm.tokens.input\n,llm.tokens.output\n,llm.cost\n- ğŸ‘¤ User Attributes:\nuser.id\n,user.plan\n,user.location\n- ğŸ“„ Content Attributes:\nprompt.length\n,response.length\n,content.type\n- ğŸ” Quality Attributes:\nrelevance.score\n,confidence.level\n,accuracy.rating\n4. Events\nEvents represent things that happened at a specific point in time during a span. They're perfect for capturing important moments or milestones.\nğŸ§  AI-Specific Tracing Patterns\nRAG Pipeline Tracing\nRAG (Retrieval-Augmented Generation) systems have distinct phases that should be traced separately:\nMulti-Agent Tracing\nWhen dealing with multiple AI agents, trace their interactions and coordination:\nğŸ“Š Observability Best Practices\n1. Meaningful Span Names\nUse descriptive, consistent naming conventions:\n2. Rich Attributes\nInclude context that helps with debugging and analysis:\n3. Error Handling\nAlways capture error details:\n4. Performance Context\nInclude performance-relevant attributes:\nğŸ” Using Traces for Debugging\nCommon Debugging Scenarios\n1. Slow Response Times\n2. High Costs\n3. Quality Issues\n4. Error Patterns\nğŸ¯ Next Steps\nNow that you understand tracing concepts, you're ready to:\n- Implement SDK Integration - Add tracing to your application\n- Explore Framework Integrations - Framework-specific guidance\n- Learn Advanced Patterns - Custom instrumentation techniques\n- Master the Dashboard - Analyze your traces effectively\nRemember: Good observability is not about collecting all possible data, but about collecting the right data that helps you understand, debug, and optimize your AI applications.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 3822,
    "internal_links": [],
    "scraped_at": 1759935906.108872
  },
  {
    "url": "https://noveum.ai/en/docs/getting-started/framework-integrations",
    "title": "Framework Integrations | Documentation | Noveum.ai",
    "content": "Framework Integrations\nDeep-dive integration guides for Next.js, Express.js, FastAPI, Flask and other popular frameworks\nNoveum.ai provides native integrations for popular web frameworks, making it easy to add comprehensive tracing to your AI applications. This guide covers framework-specific setup, best practices, and advanced patterns.\nğŸš€ Quick Framework Overview\n| Framework | Language | Integration Type | Difficulty |\n|---|---|---|---|\n| Next.js | TypeScript | Middleware + Wrappers | â­ Easy |\n| Express.js | TypeScript | Middleware | â­ Easy |\n| Hono | TypeScript | Middleware + Decorators | â­ Easy |\n| FastAPI | Python | Middleware + Decorators | â­â­ Moderate |\n| Flask | Python | Extensions + Decorators | â­â­ Moderate |\n| Django | Python | Middleware + Decorators | â­â­â­ Advanced |\nğŸ“˜ TypeScript Frameworks\nNext.js Integration\nNext.js is one of the most popular frameworks for AI applications. Noveum provides seamless integration for both App Router and Pages Router.\nApp Router Setup\n1. Initialize Noveum (Root Layout)\n2. API Route Tracing\n3. Advanced API Route with Custom Tracing\nServer Actions Tracing\nExpress.js Integration\nExpress.js integration provides automatic tracing for all routes and middleware.\n1. Setup Middleware\n2. Manual Route Tracing\n3. Middleware with Custom Logic\nHono Integration\nHono is a lightweight framework perfect for edge computing and AI applications.\nğŸ Python Frameworks\nFastAPI Integration\nFastAPI is excellent for building high-performance AI APIs with automatic documentation.\n1. Setup with Middleware\n2. Traced Endpoints\n3. RAG Endpoint with Detailed Tracing\nFlask Integration\nFlask integration provides flexibility for existing applications.\n1. Setup with Extensions\n2. Traced Routes\n3. Background Task Tracing\nğŸ”§ Advanced Patterns\nEnvironment-Specific Configuration\nCustom Middleware\nError Boundary Integration\nğŸ¯ Next Steps\nChoose your framework and dive deeper:\n- Implement Basic Integration - Start with the basics\n- Learn Tracing Concepts - Understand the fundamentals\n- Explore Advanced Patterns - Custom instrumentation\n- Master the Dashboard - Analyze your traces\nFramework not listed? Check our Custom Integration Guide or contact our team for specific framework support.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2462,
    "internal_links": [],
    "scraped_at": 1759935907.308911
  },
  {
    "url": "https://noveum.ai/en/docs/advanced/multi-agent-tracing",
    "title": "Multi-Agent Tracing | Documentation | Noveum.ai",
    "content": "Multi-Agent Tracing\nObserve complex agent workflows and inter-agent communications with comprehensive tracing\nMulti-agent systems represent some of the most complex AI applications, involving multiple agents that coordinate, communicate, and collaborate to achieve shared goals. Noveum.ai provides specialized tracing capabilities to help you understand and optimize these intricate workflows.\nğŸ¯ Why Multi-Agent Tracing Matters\nMulti-agent systems introduce unique observability challenges:\n- Complex Dependencies: Agents depend on each other's outputs and decisions\n- Asynchronous Operations: Agents may operate concurrently or in parallel\n- Communication Patterns: Understanding how agents share information\n- Resource Coordination: Managing shared resources and preventing conflicts\n- Error Propagation: How failures in one agent affect the entire system\nğŸ—ï¸ Agent System Architecture\nAgent Types and Roles\nNoveum.ai can trace various agent patterns:\nTypeScript Multi-Agent Example\nğŸ“Š Tracing Multi-Agent Workflows\nCoordination Patterns\nSequential Agent Execution\nParallel Agent Execution\nHierarchical Agent Systems\nğŸ”— Inter-Agent Communication Tracing\nMessage Passing\nShared State Management\nğŸ“ˆ Multi-Agent Performance Analysis\nAgent Performance Metrics\nTrack key metrics for each agent:\nSystem-Wide Coordination Metrics\nğŸ”§ Best Practices for Multi-Agent Tracing\n1. Agent Identification\nAlways clearly identify agents in your traces:\n2. Communication Tracing\nTrace all inter-agent communications:\n3. Error Propagation Tracking\nMonitor how errors propagate through agent systems:\n4. Resource Coordination\nTrack shared resource usage:\nğŸ¯ Advanced Multi-Agent Patterns\nSelf-Organizing Agent Systems\nAdaptive Agent Workflows\nğŸ“Š Monitoring and Alerts\nSet up monitoring for multi-agent systems:\nMulti-agent tracing with Noveum.ai provides the visibility needed to understand, optimize, and scale complex agent systems. By implementing comprehensive tracing across all agent interactions, communications, and coordination patterns, you can build more reliable and efficient multi-agent AI applications.\nğŸ”— Next Steps\n- RAG Pipeline Observability - Monitor retrieval and generation systems\n- Custom Instrumentation - Add domain-specific tracing\n- Performance Optimization - Optimize based on tracing insights\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2537,
    "internal_links": [],
    "scraped_at": 1759935908.445167
  },
  {
    "url": "https://noveum.ai/en/docs/advanced/rag-observability",
    "title": "RAG Pipeline Observability | Documentation | Noveum.ai",
    "content": "RAG Pipeline Observability\nMonitor retrieval, generation, and context handling in RAG systems with comprehensive tracing\nRetrieval-Augmented Generation (RAG) systems combine the power of information retrieval with large language models to provide accurate, contextual responses. Monitoring these complex pipelines requires specialized observability to understand retrieval quality, context relevance, and generation effectiveness.\nğŸ¯ Why RAG Observability Matters\nRAG systems introduce unique challenges that traditional monitoring can't address:\n- Retrieval Quality: Are you finding the most relevant documents?\n- Context Utilization: How effectively is retrieved context being used?\n- Generation Fidelity: Is the LLM accurately using the provided context?\n- Pipeline Performance: Where are the bottlenecks in your RAG pipeline?\n- Cost Optimization: Which components consume the most resources?\nğŸ—ï¸ RAG Pipeline Architecture\nCore RAG Components\nNoveum.ai can trace each stage of your RAG pipeline:\nTypeScript RAG Implementation\nğŸ“Š Tracing Retrieval Components\nVector Database Operations\nDocument Ranking and Reranking\nContext Window Management\nğŸ¤– Tracing LLM Generation\nContext-Aware Generation\nResponse Evaluation and Feedback\nğŸ“ˆ RAG Pipeline Performance Analysis\nEnd-to-End Pipeline Metrics\nCost and Resource Tracking\nğŸ”§ Best Practices for RAG Observability\n1. Comprehensive Pipeline Tracing\n2. Quality Monitoring\n3. A/B Testing for RAG Components\nğŸ¯ Advanced RAG Patterns\nMulti-Modal RAG\nConversational RAG\nRAG observability with Noveum.ai provides the deep insights needed to build, optimize, and scale retrieval-augmented generation systems. By implementing comprehensive tracing across retrieval, context preparation, and generation stages, you can ensure your RAG pipeline delivers accurate, relevant, and cost-effective responses.\nğŸ”— Next Steps\n- Custom Instrumentation - Add domain-specific tracing\n- Multi-Agent Tracing - Observe agent workflows\n- Performance Optimization - Optimize based on tracing insights\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2253,
    "internal_links": [],
    "scraped_at": 1759935909.55895
  },
  {
    "url": "https://noveum.ai/en/docs/advanced/custom-instrumentation",
    "title": "Custom Instrumentation | Documentation | Noveum.ai",
    "content": "Custom Instrumentation\nAdd custom spans and attributes for domain-specific observability and advanced tracing patterns\nWhile Noveum.ai's automatic instrumentation covers common AI operations, custom instrumentation allows you to add domain-specific observability, track business metrics, and create detailed traces for unique workflows. This guide covers advanced techniques for implementing custom tracing patterns.\nğŸ¯ Why Custom Instrumentation?\nCustom instrumentation enables you to:\n- Track Business Metrics: Monitor domain-specific KPIs alongside technical metrics\n- Trace Complex Workflows: Create detailed observability for unique business logic\n- Add Context: Enrich traces with application-specific attributes\n- Monitor Custom Components: Instrument proprietary algorithms and processes\n- Optimize Performance: Track specific bottlenecks in your application\nğŸ› ï¸ Custom Span Creation\nBasic Custom Spans\nTypeScript Custom Instrumentation\nğŸ“Š Custom Metrics and Attributes\nBusiness Metrics Integration\nPerformance Profiling Integration\nğŸ”§ Custom Context Propagation\nThread-Safe Context Management\nAsync Context Propagation\nğŸ“ˆ Advanced Custom Patterns\nEvent-Driven Instrumentation\nCustom Sampling Strategies\nğŸ”— Integration with External Systems\nDatabase Operation Tracing\nCustom instrumentation with Noveum.ai provides the flexibility to create detailed, domain-specific observability that goes beyond standard LLM and AI operation tracing. By implementing custom spans, attributes, context propagation, and advanced patterns, you can build comprehensive monitoring tailored to your specific application needs.\nğŸ”— Next Steps\n- Performance Optimization - Use tracing insights to optimize performance\n- Multi-Agent Tracing - Observe agent workflows\n- RAG Pipeline Observability - Monitor retrieval and generation systems\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2056,
    "internal_links": [],
    "scraped_at": 1759935910.8084621
  },
  {
    "url": "https://noveum.ai/en/docs/advanced/performance-optimization",
    "title": "Performance Optimization | Documentation | Noveum.ai",
    "content": "Performance Optimization\nUse tracing data to identify bottlenecks and optimize AI application performance\nPerformance optimization for AI applications requires understanding the unique characteristics of LLM calls, vector operations, and complex workflows. Noveum.ai's tracing data provides detailed insights to identify bottlenecks, optimize resource usage, and improve overall system performance.\nğŸ¯ Why AI Performance Optimization Matters\nAI applications have unique performance characteristics:\n- Token-Based Costs: LLM usage is measured in tokens, making efficiency crucial\n- Variable Latency: AI operations can have unpredictable response times\n- Context Dependencies: Performance varies with input size and complexity\n- Resource Intensive: Vector operations and embeddings require significant compute\n- Cascading Effects: Slow AI components impact entire application workflows\nğŸ“Š Performance Analysis with Tracing Data\nIdentifying Performance Bottlenecks\nOptimization Implementation Strategies\nğŸš€ Advanced Optimization Techniques\nModel Selection Optimization\nResource Usage Optimization\nğŸ¯ Performance Optimization Best Practices\n1. Establish Performance Baselines\n2. Implement Gradual Optimization\n3. Monitor Optimization Impact\nPerformance optimization for AI applications requires a systematic approach combining detailed tracing insights, strategic implementation, and continuous monitoring. By leveraging Noveum.ai's comprehensive tracing data, you can identify bottlenecks, implement targeted optimizations, and achieve significant improvements in latency, cost, and resource efficiency.\nğŸ”— Next Steps\n- Multi-Agent Tracing - Observe agent workflows\n- RAG Pipeline Observability - Monitor retrieval and generation systems\n- Custom Instrumentation - Add domain-specific tracing\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2025,
    "internal_links": [],
    "scraped_at": 1759935912.062154
  },
  {
    "url": "https://noveum.ai/docs/getting-started/overview",
    "title": "Noveum.ai Overview | Documentation | Noveum.ai",
    "content": "Noveum.ai Overview\nComprehensive AI tracing and observability platform for LLM applications, RAG systems, and AI agents\nWelcome to Noveum.aiâ€”the comprehensive tracing and observability platform built specifically for AI applications. Whether you're building LLM-powered chatbots, RAG systems, multi-agent workflows, or any AI-driven application, Noveum provides the insights you need to understand, debug, and optimize your systems.\nğŸ¯ Why AI Applications Need Specialized Observability\nTraditional monitoring tools fall short when it comes to AI applications because they don't understand:\n- ğŸ“Š AI-Specific Metrics: Token usage, model costs, prompt effectiveness\n- ğŸ”€ Complex Workflows: Multi-step RAG pipelines, agent interactions, tool usage\n- ğŸ§  Context Flow: How data moves through embeddings, retrievals, and generations\n- ğŸ’° Cost Attribution: Which operations drive your AI spending\n- ğŸ¯ Quality Metrics: Beyond latency - understanding output quality and relevance\nNoveum.ai bridges this gap with purpose-built observability for the AI era.\nğŸš€ Core Platform Components\n1. ğŸ Python SDK (noveum-trace\n)\n- Decorator-based tracing for seamless integration\n- Automatic instrumentation for LangChain, LlamaIndex, and OpenAI\n- Async-aware context propagation\n- Production-ready with intelligent sampling and batching\n2. ğŸ“˜ TypeScript SDK (@noveum/trace\n)\n- Framework integrations for Next.js, Express.js, Hono\n- TypeScript-first with full type safety\n- Universal compatibility (Node.js, Edge Runtime, browsers)\n- Zero-config automatic instrumentation\n3. ğŸ“Š Noveum Platform\n- Real-time dashboard with AI-specific visualizations\n- Advanced search & filtering across traces and spans\n- Cost analysis and optimization recommendations\n- Team collaboration with shared insights and alerts\nğŸ” What Noveum Traces\nLLM Operations\n- Model calls across all providers (OpenAI, Anthropic, Google, etc.)\n- Token usage and cost calculation\n- Prompt engineering effectiveness\n- Response quality metrics\nRAG Pipelines\n- Document retrieval performance and relevance\n- Embedding generation costs and latency\n- Context assembly and prompt construction\n- Answer generation with source attribution\nMulti-Agent Systems\n- Agent interactions and communication patterns\n- Tool usage and external API calls\n- Decision trees and reasoning chains\n- Workflow orchestration across agents\nCustom Operations\n- Business logic specific to your domain\n- External integrations and API calls\n- Data processing pipelines\n- User interactions and session flows\nğŸ¯ Key Benefits\nğŸ”§ Developer Experience\n- 5-minute setup with minimal code changes\n- Intelligent defaults that work out-of-the-box\n- Rich SDKs with comprehensive documentation\n- Local development support with optional cloud sync\nğŸ“Š Production Insights\n- Real-time monitoring of AI application health\n- Performance optimization with bottleneck identification\n- Cost management with detailed spend analysis\n- Quality assurance through automated alerting\nğŸ”’ Enterprise Ready\n- Security first with end-to-end encryption\n- Compliance support for regulated industries\n- Scalable architecture handling millions of traces\n- Data sovereignty with region-specific storage\nğŸ‘¥ Team Collaboration\n- Shared dashboards for cross-functional teams\n- Incident management with trace-based debugging\n- Performance baselines and regression detection\n- Knowledge sharing through trace annotations\nğŸ“ˆ Common Use Cases\nğŸ¤– LLM Application Monitoring\nTrack every aspect of your LLM-powered application:\n- Monitor response quality and user satisfaction\n- Optimize prompt engineering for better results\n- Control costs across different models and providers\n- Debug edge cases and improve error handling\nğŸ” RAG System Optimization\nUnderstand and improve your RAG pipeline:\n- Measure retrieval accuracy and relevance\n- Optimize embedding models and vector search\n- Track context utilization and prompt effectiveness\n- Debug hallucinations and improve grounding\nğŸ¤ Multi-Agent Coordination\nObserve complex agent interactions:\n- Visualize agent communication patterns\n- Track tool usage and external dependencies\n- Optimize workflow efficiency and resource usage\n- Debug coordination failures and deadlocks\nğŸš€ Performance Engineering\nOptimize your AI application performance:\n- Identify slow operations and bottlenecks\n- Right-size models for your workload\n- Implement intelligent caching strategies\n- Scale services based on actual usage patterns\nğŸ¨ Platform Features\nğŸ” Trace Explorer\n- Hierarchical visualization of complex AI workflows\n- Timeline view showing operation sequences\n- Detailed span inspection with all attributes and events\n- Cross-trace correlation for distributed operations\nğŸ’° Cost Analytics\n- Real-time cost tracking across all AI providers\n- Cost attribution by user, feature, or operation\n- Budget alerts and spending forecasts\n- Optimization recommendations for cost reduction\nğŸ“Š Performance Dashboard\n- Latency percentiles and throughput metrics\n- Error rates and failure analysis\n- Model comparison across providers and versions\n- Custom metrics and business KPIs\nğŸš¨ Alerting & Monitoring\n- Intelligent alerts based on AI-specific thresholds\n- Anomaly detection for unusual patterns\n- Escalation policies for critical issues\n- Integration with Slack, PagerDuty, and more\nğŸ› ï¸ Integration Patterns\nIncremental Adoption\nStart small and expand coverage:\n- Single endpoint tracing for immediate value\n- Critical path instrumentation for core workflows\n- Full application coverage for comprehensive insights\n- Advanced features like custom metrics and alerts\nFramework Integration\nNative support for popular frameworks:\n- Next.js with App Router and API routes\n- Express.js and other Node.js frameworks\n- FastAPI and Flask for Python applications\n- Custom integrations for any framework\nCI/CD Integration\nEmbed observability in your development process:\n- Performance regression detection in CI\n- Trace-based testing for quality assurance\n- Deployment monitoring with rollback triggers\n- Feature flag integration for safe releases\nğŸŒŸ Getting Started\nReady to transform your AI application observability? Here's your path:\n- Quick Start - Integrate your first SDK in 5 minutes\n- Tracing Concepts - Learn the fundamentals\n- Framework Guides - Deep dive into your stack\n- Advanced Features - Unlock the full platform potential\nBuilt by developers, for developers. Noveum.ai understands that AI applications are different, and we've designed our platform from the ground up to meet their unique observability needs.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 6733,
    "internal_links": [],
    "scraped_at": 1759935913.302529
  },
  {
    "url": "https://noveum.ai/docs/getting-started/sdk-integration",
    "title": "SDK Integration Guide | Documentation | Noveum.ai",
    "content": "SDK Integration Guide\nIntegrate Noveum.ai tracing into your AI applications with Python or TypeScript SDKs\nThe Noveum.ai SDKs provide comprehensive tracing and observability for your AI applications with minimal code changes. Whether you're building LLM applications, RAG systems, or multi-agent workflows, our SDKs automatically capture essential metrics and traces.\nğŸš€ Quick Start\n1. Create Your Account & Get API Key\n- Sign up at noveum.ai\n- Create a project in your dashboard\n- Generate an API key from the integration page\n- Choose your SDK based on your application language\n2. Install the SDK\nRequirements: Python 3.8+\n3. Initialize the Client\nEnvironment Variables:\nğŸ¯ Basic Usage\nTrace LLM Calls\nAlternative - Context Manager:\nTrace RAG Pipelines\nğŸ”§ Framework Integrations\nNext.js Integration\nExpress.js Integration\nFastAPI Integration (Python)\nğŸ“Š Advanced Features\nCustom Attributes & Events\nSampling Configuration\nğŸ”— What's Captured Automatically\n- ğŸ“Š Performance Metrics: Latency, throughput, error rates\n- ğŸ’° Cost Tracking: Token usage, API costs across providers\n- ğŸ” Request/Response: Configurable capture of inputs/outputs\n- ğŸ·ï¸ Metadata: Model names, parameters, user context\n- ğŸŒŠ Context Flow: Trace relationships across services\n- ğŸ› Error Details: Stack traces, error classification\nğŸ“ˆ View Your Data\nOnce integrated, visit your Noveum Dashboard to:\n- ğŸ” Search & Filter traces by any attribute\n- ğŸ“Š Analyze Performance trends and bottlenecks\n- ğŸ’° Monitor Costs across different models and providers\n- ğŸ› Debug Issues with detailed trace timelines\n- ğŸ‘¥ Collaborate with your team on insights\nğŸ”’ Security & Privacy\n- ğŸ” Encryption: All data encrypted in transit and at rest\n- ğŸ›ï¸ Configurable Capture: Control what data is collected\n- ğŸ  Data Residency: Choose your data storage region\n- â° Retention Control: Set custom data retention policies\nNext Steps\n- Tracing Concepts - Learn about traces, spans, and observability best practices\n- Framework Integrations - Deep dive into specific framework setups\n- Multi-Agent Tracing - Observe complex agent workflows\n- Dashboard Guide - Master the Noveum platform interface\nExclusive Early Access\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2378,
    "internal_links": [],
    "scraped_at": 1759935914.586812
  },
  {
    "url": "https://noveum.ai/docs/getting-started/tracing-concepts",
    "title": "Tracing Concepts for AI Applications | Documentation | Noveum.ai",
    "content": "Tracing Concepts for AI Applications\nUnderstanding traces, spans, and observability fundamentals for LLM applications, RAG systems, and AI agents\nUnderstanding the fundamentals of tracing is essential for getting the most out of Noveum.ai. This guide explains key concepts specifically in the context of AI applications, helping you design effective observability strategies for your LLM applications, RAG systems, and AI agents.\nğŸ¯ What is Tracing?\nTracing is the practice of tracking requests as they flow through your system, creating a detailed map of what happened, when, and how long each operation took. For AI applications, tracing provides crucial insights into:\n- ğŸ” Request Flow: How user queries move through your AI pipeline\n- â±ï¸ Performance: Where time is spent in your AI operations\n- ğŸ’° Costs: Which operations drive your AI spending\n- ğŸ› Debugging: What went wrong when errors occur\n- ğŸ“Š Quality: How well your AI system is performing\nğŸŒŸ Core Concepts\n1. Traces\nA trace represents a single journey through your systemâ€”like a user asking a question and getting an answer. Think of it as the complete story of one request.\nTrace Characteristics:\n- ğŸ†” Unique ID: Every trace has a unique identifier\n- â° Timeline: Start and end timestamps\n- ğŸŒ Distributed: Can span multiple services\n- ğŸ“Š Hierarchical: Contains multiple related spans\n2. Spans\nA span represents a single operation within a trace. Each span has a clear start and end time and represents work being done.\nSpan Characteristics:\n- ğŸ“› Name: Descriptive name of the operation\n- â±ï¸ Duration: How long the operation took\n- ğŸ‘¥ Parent-Child: Spans can contain other spans\n- ğŸ·ï¸ Attributes: Key-value metadata about the operation\n- ğŸ“ Events: Point-in-time occurrences during the span\n3. Attributes\nAttributes are key-value pairs that provide context about what happened during a span. They're crucial for understanding and filtering your traces.\nCommon AI Attribute Categories:\n- ğŸ¤– LLM Attributes:\nllm.model\n,llm.provider\n,llm.temperature\n- ğŸ’° Cost Attributes:\nllm.tokens.input\n,llm.tokens.output\n,llm.cost\n- ğŸ‘¤ User Attributes:\nuser.id\n,user.plan\n,user.location\n- ğŸ“„ Content Attributes:\nprompt.length\n,response.length\n,content.type\n- ğŸ” Quality Attributes:\nrelevance.score\n,confidence.level\n,accuracy.rating\n4. Events\nEvents represent things that happened at a specific point in time during a span. They're perfect for capturing important moments or milestones.\nğŸ§  AI-Specific Tracing Patterns\nRAG Pipeline Tracing\nRAG (Retrieval-Augmented Generation) systems have distinct phases that should be traced separately:\nMulti-Agent Tracing\nWhen dealing with multiple AI agents, trace their interactions and coordination:\nğŸ“Š Observability Best Practices\n1. Meaningful Span Names\nUse descriptive, consistent naming conventions:\n2. Rich Attributes\nInclude context that helps with debugging and analysis:\n3. Error Handling\nAlways capture error details:\n4. Performance Context\nInclude performance-relevant attributes:\nğŸ” Using Traces for Debugging\nCommon Debugging Scenarios\n1. Slow Response Times\n2. High Costs\n3. Quality Issues\n4. Error Patterns\nğŸ¯ Next Steps\nNow that you understand tracing concepts, you're ready to:\n- Implement SDK Integration - Add tracing to your application\n- Explore Framework Integrations - Framework-specific guidance\n- Learn Advanced Patterns - Custom instrumentation techniques\n- Master the Dashboard - Analyze your traces effectively\nRemember: Good observability is not about collecting all possible data, but about collecting the right data that helps you understand, debug, and optimize your AI applications.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 3822,
    "internal_links": [],
    "scraped_at": 1759935915.863421
  },
  {
    "url": "https://noveum.ai/docs/getting-started/framework-integrations",
    "title": "Framework Integrations | Documentation | Noveum.ai",
    "content": "Framework Integrations\nDeep-dive integration guides for Next.js, Express.js, FastAPI, Flask and other popular frameworks\nNoveum.ai provides native integrations for popular web frameworks, making it easy to add comprehensive tracing to your AI applications. This guide covers framework-specific setup, best practices, and advanced patterns.\nğŸš€ Quick Framework Overview\n| Framework | Language | Integration Type | Difficulty |\n|---|---|---|---|\n| Next.js | TypeScript | Middleware + Wrappers | â­ Easy |\n| Express.js | TypeScript | Middleware | â­ Easy |\n| Hono | TypeScript | Middleware + Decorators | â­ Easy |\n| FastAPI | Python | Middleware + Decorators | â­â­ Moderate |\n| Flask | Python | Extensions + Decorators | â­â­ Moderate |\n| Django | Python | Middleware + Decorators | â­â­â­ Advanced |\nğŸ“˜ TypeScript Frameworks\nNext.js Integration\nNext.js is one of the most popular frameworks for AI applications. Noveum provides seamless integration for both App Router and Pages Router.\nApp Router Setup\n1. Initialize Noveum (Root Layout)\n2. API Route Tracing\n3. Advanced API Route with Custom Tracing\nServer Actions Tracing\nExpress.js Integration\nExpress.js integration provides automatic tracing for all routes and middleware.\n1. Setup Middleware\n2. Manual Route Tracing\n3. Middleware with Custom Logic\nHono Integration\nHono is a lightweight framework perfect for edge computing and AI applications.\nğŸ Python Frameworks\nFastAPI Integration\nFastAPI is excellent for building high-performance AI APIs with automatic documentation.\n1. Setup with Middleware\n2. Traced Endpoints\n3. RAG Endpoint with Detailed Tracing\nFlask Integration\nFlask integration provides flexibility for existing applications.\n1. Setup with Extensions\n2. Traced Routes\n3. Background Task Tracing\nğŸ”§ Advanced Patterns\nEnvironment-Specific Configuration\nCustom Middleware\nError Boundary Integration\nğŸ¯ Next Steps\nChoose your framework and dive deeper:\n- Implement Basic Integration - Start with the basics\n- Learn Tracing Concepts - Understand the fundamentals\n- Explore Advanced Patterns - Custom instrumentation\n- Master the Dashboard - Analyze your traces\nFramework not listed? Check our Custom Integration Guide or contact our team for specific framework support.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2462,
    "internal_links": [],
    "scraped_at": 1759935917.23431
  },
  {
    "url": "https://noveum.ai/docs/advanced/multi-agent-tracing",
    "title": "Multi-Agent Tracing | Documentation | Noveum.ai",
    "content": "Multi-Agent Tracing\nObserve complex agent workflows and inter-agent communications with comprehensive tracing\nMulti-agent systems represent some of the most complex AI applications, involving multiple agents that coordinate, communicate, and collaborate to achieve shared goals. Noveum.ai provides specialized tracing capabilities to help you understand and optimize these intricate workflows.\nğŸ¯ Why Multi-Agent Tracing Matters\nMulti-agent systems introduce unique observability challenges:\n- Complex Dependencies: Agents depend on each other's outputs and decisions\n- Asynchronous Operations: Agents may operate concurrently or in parallel\n- Communication Patterns: Understanding how agents share information\n- Resource Coordination: Managing shared resources and preventing conflicts\n- Error Propagation: How failures in one agent affect the entire system\nğŸ—ï¸ Agent System Architecture\nAgent Types and Roles\nNoveum.ai can trace various agent patterns:\nTypeScript Multi-Agent Example\nğŸ“Š Tracing Multi-Agent Workflows\nCoordination Patterns\nSequential Agent Execution\nParallel Agent Execution\nHierarchical Agent Systems\nğŸ”— Inter-Agent Communication Tracing\nMessage Passing\nShared State Management\nğŸ“ˆ Multi-Agent Performance Analysis\nAgent Performance Metrics\nTrack key metrics for each agent:\nSystem-Wide Coordination Metrics\nğŸ”§ Best Practices for Multi-Agent Tracing\n1. Agent Identification\nAlways clearly identify agents in your traces:\n2. Communication Tracing\nTrace all inter-agent communications:\n3. Error Propagation Tracking\nMonitor how errors propagate through agent systems:\n4. Resource Coordination\nTrack shared resource usage:\nğŸ¯ Advanced Multi-Agent Patterns\nSelf-Organizing Agent Systems\nAdaptive Agent Workflows\nğŸ“Š Monitoring and Alerts\nSet up monitoring for multi-agent systems:\nMulti-agent tracing with Noveum.ai provides the visibility needed to understand, optimize, and scale complex agent systems. By implementing comprehensive tracing across all agent interactions, communications, and coordination patterns, you can build more reliable and efficient multi-agent AI applications.\nğŸ”— Next Steps\n- RAG Pipeline Observability - Monitor retrieval and generation systems\n- Custom Instrumentation - Add domain-specific tracing\n- Performance Optimization - Optimize based on tracing insights\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2537,
    "internal_links": [],
    "scraped_at": 1759935918.6890082
  },
  {
    "url": "https://noveum.ai/docs/advanced/rag-observability",
    "title": "RAG Pipeline Observability | Documentation | Noveum.ai",
    "content": "RAG Pipeline Observability\nMonitor retrieval, generation, and context handling in RAG systems with comprehensive tracing\nRetrieval-Augmented Generation (RAG) systems combine the power of information retrieval with large language models to provide accurate, contextual responses. Monitoring these complex pipelines requires specialized observability to understand retrieval quality, context relevance, and generation effectiveness.\nğŸ¯ Why RAG Observability Matters\nRAG systems introduce unique challenges that traditional monitoring can't address:\n- Retrieval Quality: Are you finding the most relevant documents?\n- Context Utilization: How effectively is retrieved context being used?\n- Generation Fidelity: Is the LLM accurately using the provided context?\n- Pipeline Performance: Where are the bottlenecks in your RAG pipeline?\n- Cost Optimization: Which components consume the most resources?\nğŸ—ï¸ RAG Pipeline Architecture\nCore RAG Components\nNoveum.ai can trace each stage of your RAG pipeline:\nTypeScript RAG Implementation\nğŸ“Š Tracing Retrieval Components\nVector Database Operations\nDocument Ranking and Reranking\nContext Window Management\nğŸ¤– Tracing LLM Generation\nContext-Aware Generation\nResponse Evaluation and Feedback\nğŸ“ˆ RAG Pipeline Performance Analysis\nEnd-to-End Pipeline Metrics\nCost and Resource Tracking\nğŸ”§ Best Practices for RAG Observability\n1. Comprehensive Pipeline Tracing\n2. Quality Monitoring\n3. A/B Testing for RAG Components\nğŸ¯ Advanced RAG Patterns\nMulti-Modal RAG\nConversational RAG\nRAG observability with Noveum.ai provides the deep insights needed to build, optimize, and scale retrieval-augmented generation systems. By implementing comprehensive tracing across retrieval, context preparation, and generation stages, you can ensure your RAG pipeline delivers accurate, relevant, and cost-effective responses.\nğŸ”— Next Steps\n- Custom Instrumentation - Add domain-specific tracing\n- Multi-Agent Tracing - Observe agent workflows\n- Performance Optimization - Optimize based on tracing insights\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2253,
    "internal_links": [],
    "scraped_at": 1759935920.029203
  },
  {
    "url": "https://noveum.ai/docs/advanced/custom-instrumentation",
    "title": "Custom Instrumentation | Documentation | Noveum.ai",
    "content": "Custom Instrumentation\nAdd custom spans and attributes for domain-specific observability and advanced tracing patterns\nWhile Noveum.ai's automatic instrumentation covers common AI operations, custom instrumentation allows you to add domain-specific observability, track business metrics, and create detailed traces for unique workflows. This guide covers advanced techniques for implementing custom tracing patterns.\nğŸ¯ Why Custom Instrumentation?\nCustom instrumentation enables you to:\n- Track Business Metrics: Monitor domain-specific KPIs alongside technical metrics\n- Trace Complex Workflows: Create detailed observability for unique business logic\n- Add Context: Enrich traces with application-specific attributes\n- Monitor Custom Components: Instrument proprietary algorithms and processes\n- Optimize Performance: Track specific bottlenecks in your application\nğŸ› ï¸ Custom Span Creation\nBasic Custom Spans\nTypeScript Custom Instrumentation\nğŸ“Š Custom Metrics and Attributes\nBusiness Metrics Integration\nPerformance Profiling Integration\nğŸ”§ Custom Context Propagation\nThread-Safe Context Management\nAsync Context Propagation\nğŸ“ˆ Advanced Custom Patterns\nEvent-Driven Instrumentation\nCustom Sampling Strategies\nğŸ”— Integration with External Systems\nDatabase Operation Tracing\nCustom instrumentation with Noveum.ai provides the flexibility to create detailed, domain-specific observability that goes beyond standard LLM and AI operation tracing. By implementing custom spans, attributes, context propagation, and advanced patterns, you can build comprehensive monitoring tailored to your specific application needs.\nğŸ”— Next Steps\n- Performance Optimization - Use tracing insights to optimize performance\n- Multi-Agent Tracing - Observe agent workflows\n- RAG Pipeline Observability - Monitor retrieval and generation systems\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2056,
    "internal_links": [],
    "scraped_at": 1759935921.483979
  },
  {
    "url": "https://noveum.ai/docs/advanced/performance-optimization",
    "title": "Performance Optimization | Documentation | Noveum.ai",
    "content": "Performance Optimization\nUse tracing data to identify bottlenecks and optimize AI application performance\nPerformance optimization for AI applications requires understanding the unique characteristics of LLM calls, vector operations, and complex workflows. Noveum.ai's tracing data provides detailed insights to identify bottlenecks, optimize resource usage, and improve overall system performance.\nğŸ¯ Why AI Performance Optimization Matters\nAI applications have unique performance characteristics:\n- Token-Based Costs: LLM usage is measured in tokens, making efficiency crucial\n- Variable Latency: AI operations can have unpredictable response times\n- Context Dependencies: Performance varies with input size and complexity\n- Resource Intensive: Vector operations and embeddings require significant compute\n- Cascading Effects: Slow AI components impact entire application workflows\nğŸ“Š Performance Analysis with Tracing Data\nIdentifying Performance Bottlenecks\nOptimization Implementation Strategies\nğŸš€ Advanced Optimization Techniques\nModel Selection Optimization\nResource Usage Optimization\nğŸ¯ Performance Optimization Best Practices\n1. Establish Performance Baselines\n2. Implement Gradual Optimization\n3. Monitor Optimization Impact\nPerformance optimization for AI applications requires a systematic approach combining detailed tracing insights, strategic implementation, and continuous monitoring. By leveraging Noveum.ai's comprehensive tracing data, you can identify bottlenecks, implement targeted optimizations, and achieve significant improvements in latency, cost, and resource efficiency.\nğŸ”— Next Steps\n- Multi-Agent Tracing - Observe agent workflows\n- RAG Pipeline Observability - Monitor retrieval and generation systems\n- Custom Instrumentation - Add domain-specific tracing\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 2025,
    "internal_links": [],
    "scraped_at": 1759935922.847022
  },
  {
    "url": "https://noveum.ai/docs/platform/dashboard",
    "title": "Dashboard Overview | Documentation | Noveum.ai",
    "content": "Dashboard Overview\nNavigate the Noveum platform and understand key metrics for your AI applications\nDashboard Overview\nThe Noveum.ai dashboard provides comprehensive visibility into your AI application's performance, giving you real-time insights into traces, costs, and system health. Built specifically for AI workloads, it offers both high-level analytics and detailed trace inspection capabilities.\nğŸ¯ Key Dashboard Features\nReal-Time Traces Monitoring\n- Live Trace Stream: Monitor LLM calls, RAG operations, and agent activities in real-time\n- Advanced Filtering: Filter by project, environment, status, date ranges, and custom attributes\n- Search Functionality: Quickly find specific traces using full-text search across all trace data\n- Status Indicators: Visual status badges for success, error, and pending operations\nPerformance Analytics\n- Latency Metrics: Track response times across different operations and time periods\n- Cost Analysis: Monitor spending across different LLM providers and operations\n- Throughput Monitoring: Observe request volumes and system capacity\n- Error Rate Tracking: Identify and monitor failure patterns\nInteractive Trace Inspection\n- Detailed Trace View: Expand any trace to see complete request/response data\n- Span Hierarchy: Navigate complex multi-step operations with visual span trees\n- Timing Analysis: Understand where time is spent in your AI operations\n- Context Preservation: See how data flows through embeddings, retrievals, and generations\nğŸ“Š Dashboard Components\nTraces List Interface\nThe main traces interface offers two viewing modes:\nClassic Interface\n- Tabular view of all traces with sortable columns\n- Quick filtering and search capabilities\n- Expandable detail panels for trace inspection\nThree-Pane Interface\n- Directory tree navigation for complex trace hierarchies\n- Split-pane view for simultaneous trace browsing and detail inspection\n- Advanced filtering with visual feedback\nFilter Controls\n- Environment Filter: Switch between development, staging, and production\n- Project Filter: Focus on specific applications or services\n- Status Filter: View only successful, failed, or pending operations\n- Date Range: Analyze performance over custom time periods\n- Clear Filters: Quick reset to view all traces\nConnection Status\n- Real-time Status: Monitor connection health to your trace storage\n- Error Reporting: Clear error messages when connectivity issues occur\n- Refresh Controls: Manual refresh capability for troubleshooting\nğŸ” Trace Detail Analysis\nComprehensive Trace Information\nEach trace provides detailed insights including:\n- Basic Metadata: Timestamp, duration, status, project, and environment\n- Request Context: User ID, session ID, and custom attributes\n- Response Data: Complete LLM responses, tool outputs, and generated content\n- Performance Metrics: Token usage, costs, and timing breakdowns\n- Error Details: Stack traces and error context when operations fail\nSpan Analysis\n- Operation Types: Automatic categorization of LLM calls, vector searches, tool usage\n- Attribute Inspection: View all custom attributes and metadata\n- Timing Visualization: Understand operation sequencing and bottlenecks\n- Parent-Child Relationships: Navigate complex workflow hierarchies\nFlow Visualization\n- Interactive Flow Charts: Visual representation of operation sequences\n- Dependency Mapping: See how different components interact\n- Error Path Analysis: Trace failure points through your system\nğŸ¨ Interface Customization\nLayout Options\n- Responsive Design: Optimized for desktop and mobile viewing\n- Panel Sizing: Adjustable interface panels for different screen sizes\n- Dark/Light Themes: Switch between themes for comfortable viewing\nData Display\n- Sortable Columns: Sort traces by any metric (time, duration, cost, status)\n- Configurable Views: Customize which trace attributes are displayed\n- Export Capabilities: Download trace data for external analysis\nğŸ“ˆ Getting Started with the Dashboard\nInitial Setup\n- Connect Your Applications: Ensure your AI applications are instrumented with Noveum SDKs\n- Verify Data Flow: Check the connection status indicator for successful trace ingestion\n- Explore Filters: Use environment and project filters to focus on relevant data\nBest Practices\n- Set Up Projects: Organize your applications into logical projects for better filtering\n- Use Environments: Separate development, staging, and production traces\n- Monitor Regularly: Check dashboard daily for performance trends and issues\n- Deep Dive on Errors: Use detailed trace inspection to troubleshoot failures\nPerformance Tips\n- Filter Early: Use filters to reduce data volume for faster loading\n- Time Range Selection: Limit date ranges for better performance with large datasets\n- Regular Refresh: Enable auto-refresh for monitoring live systems\nğŸ”— Integration with Other Platform Features\nThe dashboard seamlessly integrates with other Noveum platform capabilities:\n- Projects: Filter and organize traces by project structure\n- Team Collaboration: Share trace URLs with team members for collaborative debugging\n- API Access: Export trace data programmatically using the Noveum API\n- Alert Systems: Set up notifications based on dashboard metrics\nğŸ’¡ Advanced Features\nCustom Attributes\n- Search by Attributes: Find traces using custom metadata you've added\n- Attribute Filtering: Create complex filters using custom attributes\n- Attribute Visualization: See custom data alongside standard metrics\nBulk Operations\n- Multi-Select: Select multiple traces for batch operations\n- Bulk Export: Download multiple traces simultaneously\n- Comparative Analysis: Compare performance across multiple traces\nReal-Time Updates\n- Live Refresh: Automatic updates as new traces arrive\n- Connection Monitoring: Real-time status of your trace ingestion pipeline\n- Performance Indicators: Live metrics for system health monitoring\nReady to dive deeper? Explore Projects & Environments to organize your AI applications, or check out Team Collaboration to share insights with your team.\nGet Early Access to Noveum.ai Platform\nBe the first one to get notified when we open Noveum Platform to more users. All users get access to Observability suite for free, early users get free eval jobs and premium support for the first year.",
    "content_length": 6265,
    "internal_links": [],
    "scraped_at": 1759935923.99634
  },
  {
    "url": "https://noveum.ai/en/careers/apply/senior-ai-engineer",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "EngineeringFull-time\nPython AI/ML Engineer\nRemote\nFull-time\nâ‚¹12-36 LPA\n100% Remote\nJob Description\nJoin Noveum's core AI team that monitors, evaluates, and improves AI agents in production. You will design rigorous eval pipelines, build and debug agentic workflows, deploy and tune models, and close the loop with observability to drive reliability, quality, and cost/performance. This is a high-ownership role working directly with founders and customers to ship end-to-end fixes and new agent capabilities.\nKey Responsibilities\n- Design and implement production-grade AI agent architectures and tools\n- Build rigorous evaluation pipelines; define metrics, datasets, and pass/fail thresholds\n- Instrument, monitor, and debug agents using tracing/observability to improve reliability\n- Deploy, fine-tune, and optimize models (latency, cost, and accuracy)\n- Collaborate with founders and customers to scope, build, and ship new agent capabilities\n- Mentor and raise the bar on engineering quality and operational excellence\nRequirements\n- 5+ years in AI/ML engineering with hands-on model development and deployment\n- Expertise in Python with PyTorch and/or TensorFlow\n- Production experience with LLMs/GenAI (OpenAI, Anthropic, etc.)\n- Proven experience building agentic systems or complex ML pipelines\n- Strong MLOps foundations: packaging, CI/CD, containers, cloud\n- Bias for ownership: able to self-unblock, deliver end-to-end, and operate independently\nPreferred Qualifications\n- Hands-on experience designing/running evals for LLMs/agents\n- Experience building new agents and tools for real customer workflows\n- Open-source contributions or public work in AI/ML\n- Next.js familiarity is a plus but not required",
    "content_length": 1715,
    "internal_links": [],
    "scraped_at": 1759935928.3825111
  },
  {
    "url": "https://noveum.ai/en/careers/apply/fullstack-developer-ai",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "EngineeringFull-time\nFullStack Next.js Engineer\nRemote\nFull-time\nâ‚¹12-36 LPA\n100% Remote\nJob Description\nBuild end-to-end product features using Next.js App Router, TypeScript, Tailwind CSS, and Node.js.\nKey Responsibilities\n- Own features across UI and backend with Next.js App Router\n- Implement accessible, responsive UI using Tailwind CSS and shadcn/ui\n- Design and integrate Node.js APIs with Prisma/Postgres\n- Collaborate with design/product to ship high-quality experiences\n- Write tests and ensure performance, security, and reliability\nRequirements\n- 3-6+ years building web apps with React/Next.js\n- Strong TypeScript and modern React patterns\n- Next.js (App Router), server components, SSR/ISR\n- Tailwind CSS, shadcn/ui, Radix UI\n- Node.js APIs, Prisma, Postgres\n- Git, CI, and basic Docker knowledge\nPreferred Qualifications\n- Experience with AI/LLM integrations\n- Performance optimization and accessibility mindset\n- Experience in monorepos and pnpm",
    "content_length": 961,
    "internal_links": [],
    "scraped_at": 1759935929.383203
  },
  {
    "url": "https://noveum.ai/",
    "title": "AI Observability, LLM Evals & Agent Monitoring | Noveum.ai",
    "content": "Monitor all your AI Agents\nimprove AI Agents today\nNoveum.ai helps you monitor, trace, and optimize your AI applications.\nNoveum.ai works with any AI framework â€“ LangChain, CrewAI, AutoGen, custom implementations, or direct LLM calls. One dashboard shows everything.\nMonitor, Evaluate, Improve Your AI Agents\nThe control plane for AI agents.\nMonitor Everything, Miss Nothing\nOur lightweight SDKs capture every trace and span across your AI agent ecosystemâ€”from simple LLM calls to complex multi-agent workflows. Get complete visibility without performance overhead.\nStart MonitoringEvaluate with 30+ Advanced Metrics\nNovaEval automatically scores every agent interaction using our comprehensive evaluation framework. Track accuracy, semantic similarity, safety, bias, and custom business metrics in real-time.\nView EvaluationsImprove Automatically with NovaPilot\nOur AI engineer analyzes performance data and automatically generates fixes for failing agents. Get detailed reports on model changes, prompt optimizations, and tool improvementsâ€”all without human intervention.\nTry Auto-ImprovementEnterprise Ready\nNoveum.ai is built for enterprise-scale AI applications, with support for multi-tenant, multi-region deployments and advanced security features.\nContact Saleswith the world's favorite AI Observability Platform\nEverything You Need to Master AI Agent Operations\nNoveum.ai helps you monitor, trace, and optimize your AI applications with comprehensive observability tools designed for modern LLM workflows.\nSee Every Agent, Every Interaction, Every Decision\n30+ Metrics That Actually Matter for Business\nYour AI Engineer That Never Sleeps\n100% visibility on every AI agent\nReduce AI Incidents by 85%\nGet comprehensive AI monitoring with automated incident prevention, faster debugging, and built-in compliance tools.\nInstead of spending days investigating AI agent failures, your team gets instant insights into what went wrong and how to fix it. Detailed traces and automated analysis eliminate guesswork.\n0+\nAI FrameworksWith the world's favorite AI observability platform\nEasy integration with your AI stack\nNoveum.ai integrates seamlessly with all popular AI frameworks and providers, giving you comprehensive observability across your entire AI pipeline.\nWorks great with: LangChain, OpenAI, Anthropic, AWS Bedrock, Azure OpenAI, Google Cloud (Vertex AI), CrewAI, LangGraph, LlamaIndex, AutoGen, custom SDKs, and more\nwith the world's favorite AI observability platform\nTrusted AI monitoring tools by thousands of developers\n0+\nAI Eval Metrics0.0%\nuptime SLA0M+\ntraces processed",
    "content_length": 2591,
    "internal_links": [],
    "scraped_at": 1759935930.515405
  },
  {
    "url": "https://noveum.ai/auth/forgot-password",
    "title": "Forgot your password? | Noveum.ai",
    "content": "Forgot your password?\nPlease enter your email address and we will send you a link to reset your password.\nEmail\nSend link\nBack to signin",
    "content_length": 136,
    "internal_links": [],
    "scraped_at": 1759935931.469873
  },
  {
    "url": "https://noveum.ai/auth/signup",
    "title": "Create an account | Noveum.ai",
    "content": "Create an account\nWe are happy that you want to join us. Please fill in the form below to create your account.\nOr continue with\nAlready have an account? Sign in\nWe are happy that you want to join us. Please fill in the form below to create your account.\nOr continue with",
    "content_length": 270,
    "internal_links": [],
    "scraped_at": 1759935932.3582091
  }
]