{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb0a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix: Upload Dataset with Proper Environment Loading\n",
    "!cd /Users/mramanindia/work/NovaEval/noveum_customer_support_bt && source .env && python upload_dataset.py --dataset-json split_datasets/agent.rag_evaluation_metrics_dataset.json --item-type conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780ff8d0",
   "metadata": {},
   "source": [
    "# Noveum AI Agent with RAG + Web Search\n",
    "\n",
    "An intelligent conversational agent that dynamically routes queries between **RAG (Retrieval-Augmented Generation)** for Noveum.ai-specific information and **Web Search** for external knowledge, providing comprehensive answers with full observability.\n",
    "\n",
    "## üöÄ What This Agent Does\n",
    "\n",
    "### Core Functionality\n",
    "- **Intelligent Query Routing**: Automatically determines whether to use RAG or Web Search based on query content\n",
    "- **Dual Knowledge Sources**: \n",
    "  - **RAG Mode**: Answers questions about Noveum.ai platform using scraped documentation\n",
    "  - **Web Search Mode**: Handles external queries using real-time web search\n",
    "- **Comprehensive Tracing**: Full observability with detailed metrics and performance tracking\n",
    "- **Modular Architecture**: Clean separation of concerns for easy maintenance and extension\n",
    "\n",
    "### Key Capabilities\n",
    "- üß† **Document Intelligence**: Scrapes and indexes Noveum.ai website content for semantic search\n",
    "- üåê **Real-time Web Search**: Uses DuckDuckGo for current events and external knowledge\n",
    "- üéØ **Smart Classification**: LLM-powered query routing with keyword fallback\n",
    "- üìä **Performance Monitoring**: Detailed metrics on response quality, latency, and token usage\n",
    "- üîÑ **Scalable Design**: Easy to extend with new data sources or routing logic\n",
    "\n",
    "## üìã Prerequisites & Requirements\n",
    "\n",
    "### Required Environment Variables\n",
    "```bash\n",
    "NOVEUM_API_KEY=your_noveum_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "```\n",
    "\n",
    "### Required Python Packages\n",
    "- `requests` - HTTP requests for web scraping\n",
    "- `beautifulsoup4` - HTML parsing\n",
    "- `trafilatura` - Advanced text extraction\n",
    "- `langchain` - LLM framework and vector operations\n",
    "- `langchain-openai` - OpenAI integration\n",
    "- `langchain-community` - Community tools (FAISS, DuckDuckGo)\n",
    "- `noveum-trace` - Observability and tracing\n",
    "- `python-dotenv` - Environment variable management\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.8+\n",
    "- Internet connection for web scraping and API calls\n",
    "- ~500MB disk space for vector store and scraped data\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "\n",
    "### 1. **Website Scraper** (`NoveumWebsiteScraper`)\n",
    "- Recursively scrapes noveum.ai website and sub-pages\n",
    "- Extracts clean text content using trafilatura\n",
    "- Discovers internal links automatically\n",
    "- Saves scraped data to JSON for persistence\n",
    "\n",
    "### 2. **RAG System** (`NoveumRAGSystem`)\n",
    "- Loads scraped documents and creates vector embeddings\n",
    "- Uses FAISS for fast similarity search\n",
    "- Generates context-aware responses using OpenAI GPT-4o-mini\n",
    "- Tracks retrieval effectiveness and response quality\n",
    "\n",
    "### 3. **Web Search System** (`NoveumWebSearchSystem`)\n",
    "- Integrates DuckDuckGo search for external queries\n",
    "- Synthesizes information from multiple web sources\n",
    "- Handles real-time information and current events\n",
    "- Formats search results into coherent responses\n",
    "\n",
    "### 4. **Query Router** (`NoveumQueryRouter`)\n",
    "- **Keyword-based classification**: Matches queries against predefined keyword lists\n",
    "- **LLM-based classification**: Uses GPT-4o-mini for complex query analysis\n",
    "- **Confidence scoring**: Evaluates routing decision quality\n",
    "- **Fallback handling**: Defaults to Web Search for ambiguous queries\n",
    "\n",
    "### 5. **Main Agent** (`NoveumAIAgent`)\n",
    "- Orchestrates all components\n",
    "- Manages system initialization and data loading\n",
    "- Provides unified interface for query processing\n",
    "- Handles error recovery and response formatting\n",
    "\n",
    "## üéØ How to Use\n",
    "\n",
    "### Quick Start\n",
    "```python\n",
    "# 1. Initialize the system (first time only)\n",
    "noveum_agent.initialize_system(force_scrape=True)\n",
    "\n",
    "# 2. Ask questions\n",
    "response = noveum_agent.process_query(\"What is Noveum and what does it do?\")\n",
    "noveum_agent.display_response(response)\n",
    "\n",
    "# 3. Or use convenience function\n",
    "ask_question(\"How do I integrate Noveum Trace?\")\n",
    "```\n",
    "\n",
    "### Advanced Usage\n",
    "```python\n",
    "# Run full demo with 20 test queries\n",
    "demo_noveum_agent()\n",
    "\n",
    "# Process queries programmatically\n",
    "response = noveum_agent.process_query(\"What are the latest AI news?\")\n",
    "print(f\"Mode: {response['mode']}\")\n",
    "print(f\"Answer: {response['answer']}\")\n",
    "print(f\"Sources: {response['sources']}\")\n",
    "```\n",
    "\n",
    "### Query Types\n",
    "\n",
    "#### RAG Queries (Noveum-specific)\n",
    "- \"What is Noveum and what does it do?\"\n",
    "- \"How do I integrate Noveum Trace?\"\n",
    "- \"What are Noveum's pricing plans?\"\n",
    "- \"What features does Noveum Trace offer?\"\n",
    "- \"How do I set up observability with Noveum?\"\n",
    "\n",
    "#### Web Search Queries (External knowledge)\n",
    "- \"What are the latest AI news today?\"\n",
    "- \"What's the weather like today?\"\n",
    "- \"Tell me about recent developments in machine learning\"\n",
    "- \"What are the current trends in observability tools?\"\n",
    "- \"What happened in tech news this week?\"\n",
    "\n",
    "## üìä Observability & Monitoring\n",
    "\n",
    "### Traced Operations\n",
    "- **System Initialization**: Website scraping and vector store creation\n",
    "- **Query Processing**: End-to-end query handling with performance metrics\n",
    "- **RAG Operations**: Document retrieval, context generation, and response creation\n",
    "- **Web Search Operations**: Search execution, result synthesis, and response generation\n",
    "- **Query Routing**: Classification decision making and confidence scoring\n",
    "\n",
    "### Key Metrics Tracked\n",
    "- **Performance**: Response latency, processing time, token usage\n",
    "- **Quality**: Response length, source diversity, context utilization\n",
    "- **Routing**: Classification confidence, keyword scores, decision rationale\n",
    "- **Model Usage**: Token consumption, cost estimation, efficiency scores\n",
    "- **Retrieval**: Document relevance, context quality, source effectiveness\n",
    "\n",
    "### Noveum Trace Integration\n",
    "- All operations are automatically traced with detailed spans\n",
    "- Comprehensive attribute tracking for debugging and optimization\n",
    "- Real-time monitoring through Noveum.ai dashboard\n",
    "- Export capabilities for further analysis\n",
    "\n",
    "## üîß Configuration\n",
    "\n",
    "### Default Settings\n",
    "```python\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Customization Options\n",
    "- **Scraping**: Adjust `max_pages_to_scrape` for more/less content\n",
    "- **RAG**: Modify `chunk_size` and `chunk_overlap` for different text splitting\n",
    "- **Search**: Change `max_search_results` for more/fewer sources\n",
    "- **Routing**: Add keywords to `rag_keywords` or `web_keywords` lists\n",
    "\n",
    "## üö® Error Handling\n",
    "\n",
    "### Common Issues\n",
    "- **API Key Missing**: Ensure `NOVEUM_API_KEY` and `OPENAI_API_KEY` are set\n",
    "- **Network Errors**: Check internet connection for scraping and API calls\n",
    "- **Vector Store Issues**: Delete `noveum_vectorstore` folder to regenerate\n",
    "- **Scraping Failures**: Set `force_scrape=True` to re-scrape website\n",
    "\n",
    "### Recovery Strategies\n",
    "- Automatic fallback to Web Search for RAG failures\n",
    "- Graceful error handling with informative messages\n",
    "- Retry mechanisms for transient network issues\n",
    "- Detailed error logging for debugging\n",
    "\n",
    "## üîÑ Maintenance\n",
    "\n",
    "### Regular Tasks\n",
    "- **Update Scraped Content**: Run with `force_scrape=True` periodically\n",
    "- **Monitor Performance**: Check Noveum Trace dashboard for metrics\n",
    "- **Review Routing**: Analyze query classification accuracy\n",
    "- **Update Keywords**: Add new terms to routing keyword lists\n",
    "\n",
    "### Scaling Considerations\n",
    "- **Vector Store**: Can be shared across multiple agent instances\n",
    "- **Scraped Data**: JSON file can be versioned and distributed\n",
    "- **API Limits**: Monitor OpenAI token usage and costs\n",
    "- **Performance**: Consider caching for frequently asked questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88c54bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests==2.32.3 (from -r ./noveum_agent_requirements.txt (line 3))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting beautifulsoup4==4.12.3 (from -r ./noveum_agent_requirements.txt (line 4))\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r ./noveum_agent_requirements.txt (line 5))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting langchain==0.3.26 (from -r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community==0.3.18 (from -r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached langchain_community-0.3.18-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core==0.3.66 (from -r ./noveum_agent_requirements.txt (line 10))\n",
      "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-openai==0.3.25 (from -r ./noveum_agent_requirements.txt (line 11))\n",
      "  Using cached langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting trafilatura>=1.6.4 (from -r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached trafilatura-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting lxml>=5.3.0 (from -r ./noveum_agent_requirements.txt (line 15))\n",
      "  Using cached lxml-6.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (3.6 kB)\n",
      "Collecting faiss-cpu==1.12.0 (from -r ./noveum_agent_requirements.txt (line 18))\n",
      "  Using cached faiss_cpu-1.12.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting duckduckgo-search>=6.1.12 (from -r ./noveum_agent_requirements.txt (line 22))\n",
      "  Using cached duckduckgo_search-8.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: pandas>=2.2.3 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from -r ./noveum_agent_requirements.txt (line 25)) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from -r ./noveum_agent_requirements.txt (line 26)) (4.67.1)\n",
      "Requirement already satisfied: noveum_trace>=0.3.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from -r ./noveum_agent_requirements.txt (line 29)) (0.3.9)\n",
      "Collecting jupyter==1.0.0 (from -r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Collecting ipykernel==6.29.4 (from -r ./noveum_agent_requirements.txt (line 33))\n",
      "  Using cached ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from requests==2.32.3->-r ./noveum_agent_requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from requests==2.32.3->-r ./noveum_agent_requirements.txt (line 3)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from requests==2.32.3->-r ./noveum_agent_requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from requests==2.32.3->-r ./noveum_agent_requirements.txt (line 3)) (2025.10.5)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4==4.12.3->-r ./noveum_agent_requirements.txt (line 4))\n",
      "  Using cached soupsieve-2.8-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Downloading langsmith-0.4.37-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (2.12.3)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached sqlalchemy-2.0.44-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (6.0.3)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached aiohttp-3.13.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9)) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9)) (2.11.0)\n",
      "Collecting langsmith>=0.1.17 (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9)) (2.3.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.66->-r ./noveum_agent_requirements.txt (line 10))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core==0.3.66->-r ./noveum_agent_requirements.txt (line 10))\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langchain-core==0.3.66->-r ./noveum_agent_requirements.txt (line 10)) (4.15.0)\n",
      "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11))\n",
      "  Using cached openai-1.109.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11))\n",
      "  Using cached tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting notebook (from jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached notebook-7.4.7-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting qtconsole (from jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached qtconsole-5.7.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jupyter-console (from jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting ipywidgets (from jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: appnope in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (7.1.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (5.14.3)\n",
      "Collecting courlan>=1.3.2 (from trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached courlan-1.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting htmldate>=1.9.2 (from trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached htmldate-1.9.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting justext>=3.0.1 (from trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached justext-3.0.2-py2.py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: click>=8.1.8 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from duckduckgo-search>=6.1.12->-r ./noveum_agent_requirements.txt (line 22)) (8.3.0)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search>=6.1.12->-r ./noveum_agent_requirements.txt (line 22))\n",
      "  Using cached primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r ./noveum_agent_requirements.txt (line 25)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r ./noveum_agent_requirements.txt (line 25)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r ./noveum_agent_requirements.txt (line 25)) (2025.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting babel>=2.16.0 (from courlan>=1.3.2->trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting tld>=0.13 (from courlan>=1.3.2->trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached tld-0.13.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9))\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting dateparser>=1.1.2 (from htmldate>=1.9.2->trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting lxml>=5.3.0 (from -r ./noveum_agent_requirements.txt (line 15))\n",
      "  Using cached lxml-5.4.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: decorator in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.6.3)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.66->-r ./noveum_agent_requirements.txt (line 10))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (4.5.0)\n",
      "INFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached orjson-3.11.3-cp312-cp312-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8))\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11)) (4.11.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11))\n",
      "  Using cached jiter-0.11.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->-r ./noveum_agent_requirements.txt (line 25)) (1.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.25->-r ./noveum_agent_requirements.txt (line 11)) (2025.10.23)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: jinja2>=3.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32)) (3.1.6)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32)) (3.0.3)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached mistune-3.1.4-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter_server-2.17.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab<4.5,>=4.4.9 (from notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Downloading jupyterlab-4.4.10-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached QtPy-2.4.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting tzlocal>=0.2 (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached tzlocal-5.3.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r ./noveum_agent_requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.8.5)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32)) (80.9.0)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting lxml_html_clean (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura>=1.6.4->-r ./noveum_agent_requirements.txt (line 14))\n",
      "  Using cached lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.2.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r ./noveum_agent_requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r ./noveum_agent_requirements.txt (line 33)) (0.2.3)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32)) (2.23)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached lark-1.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r ./noveum_agent_requirements.txt (line 32))\n",
      "  Using cached arrow-1.4.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_community-0.3.18-py3-none-any.whl (2.5 MB)\n",
      "Using cached langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Using cached langchain_openai-0.3.25-py3-none-any.whl (69 kB)\n",
      "Using cached faiss_cpu-1.12.0-cp312-cp312-macosx_14_0_arm64.whl (3.4 MB)\n",
      "Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "Using cached trafilatura-2.0.0-py3-none-any.whl (132 kB)\n",
      "Using cached duckduckgo_search-8.1.1-py3-none-any.whl (18 kB)\n",
      "Using cached aiohttp-3.13.1-cp312-cp312-macosx_11_0_arm64.whl (490 kB)\n",
      "Using cached courlan-1.3.2-py3-none-any.whl (33 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached htmldate-1.9.3-py3-none-any.whl (31 kB)\n",
      "Using cached lxml-5.4.0-cp312-cp312-macosx_10_9_universal2.whl (8.1 MB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached justext-3.0.2-py2.py3-none-any.whl (837 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Using cached openai-1.109.1-py3-none-any.whl (948 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached primp-0.15.0-cp38-abi3-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached soupsieve-2.8-py3-none-any.whl (36 kB)\n",
      "Using cached sqlalchemy-2.0.44-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tiktoken-0.12.0-cp312-cp312-macosx_11_0_arm64.whl (994 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Using cached notebook-7.4.7-py3-none-any.whl (14.3 MB)\n",
      "Using cached qtconsole-5.7.0-py3-none-any.whl (125 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.8.0-cp312-cp312-macosx_11_0_arm64.whl (50 kB)\n",
      "Using cached jiter-0.11.1-cp312-cp312-macosx_11_0_arm64.whl (315 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jupyter_server-2.17.0-py3-none-any.whl (388 kB)\n",
      "Downloading jupyterlab-4.4.10-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m135.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:02\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached mistune-3.1.4-py3-none-any.whl (53 kB)\n",
      "Using cached multidict-6.7.0-cp312-cp312-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached orjson-3.11.3-cp312-cp312-macosx_15_0_arm64.whl (127 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached propcache-0.4.1-cp312-cp312-macosx_11_0_arm64.whl (47 kB)\n",
      "Using cached QtPy-2.4.3-py3-none-any.whl (95 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached tld-0.13.1-py2.py3-none-any.whl (274 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Using cached yarl-1.22.0-cp312-cp312-macosx_11_0_arm64.whl (94 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Using cached json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "Using cached jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached tzlocal-5.3.1-py3-none-any.whl (18 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
      "Using cached lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rpds_py-0.27.1-cp312-cp312-macosx_11_0_arm64.whl (345 kB)\n",
      "Using cached argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl (31 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.4.0-py3-none-any.whl (68 kB)\n",
      "Using cached lark-1.3.0-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, zstandard, widgetsnbextension, websocket-client, webcolors, uri-template, tzlocal, typing-inspect, tld, tinycss2, terminado, SQLAlchemy, soupsieve, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, requests, python-json-logger, python-dotenv, propcache, prometheus-client, primp, pandocfilters, packaging, orjson, multidict, mistune, lxml, lark, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, jiter, httpx-sse, frozenlist, fqdn, distro, defusedxml, bleach, babel, attrs, async-lru, aiohappyeyeballs, yarl, tiktoken, rfc3987-syntax, requests-toolbelt, referencing, qtpy, marshmallow, lxml_html_clean, jupyter-server-terminals, jsonpatch, faiss-cpu, duckduckgo-search, dateparser, courlan, beautifulsoup4, arrow, argon2-cffi-bindings, aiosignal, openai, langsmith, jsonschema-specifications, isoduration, ipywidgets, ipykernel, htmldate, dataclasses-json, argon2-cffi, aiohttp, qtconsole, langchain-core, justext, jupyter-console, jsonschema, trafilatura, nbformat, langchain-text-splitters, langchain-openai, nbclient, langchain, jupyter-events, nbconvert, langchain-community, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.5\n",
      "    Uninstalling requests-2.32.5:\n",
      "      Successfully uninstalled requests-2.32.5\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.1.1\n",
      "    Uninstalling python-dotenv-1.1.1:\n",
      "      Successfully uninstalled python-dotenv-1.1.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 4.0.1\n",
      "    Uninstalling marshmallow-4.0.1:\n",
      "      Successfully uninstalled marshmallow-4.0.1\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 7.0.1\n",
      "    Uninstalling ipykernel-7.0.1:\n",
      "      Successfully uninstalled ipykernel-7.0.1\n",
      "Successfully installed SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.4.0 async-lru-2.0.5 attrs-25.4.0 babel-2.17.0 beautifulsoup4-4.12.3 bleach-6.2.0 courlan-1.3.2 dataclasses-json-0.6.7 dateparser-1.2.2 defusedxml-0.7.1 distro-1.9.0 duckduckgo-search-8.1.1 faiss-cpu-1.12.0 fastjsonschema-2.21.2 fqdn-1.5.1 frozenlist-1.8.0 htmldate-1.9.3 httpx-sse-0.4.3 ipykernel-6.29.4 ipywidgets-8.1.7 isoduration-20.11.0 jiter-0.11.1 json5-0.12.1 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 jupyter-1.0.0 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.3.0 jupyter-server-2.17.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.10 jupyterlab-pygments-0.3.0 jupyterlab-server-2.28.0 jupyterlab_widgets-3.0.15 justext-3.0.2 langchain-0.3.26 langchain-community-0.3.18 langchain-core-0.3.66 langchain-openai-0.3.25 langchain-text-splitters-0.3.8 langsmith-0.3.45 lark-1.3.0 lxml-5.4.0 lxml_html_clean-0.4.3 marshmallow-3.26.1 mistune-3.1.4 multidict-6.7.0 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.7 notebook-shim-0.2.4 openai-1.109.1 orjson-3.11.3 packaging-24.2 pandocfilters-1.5.1 primp-0.15.0 prometheus-client-0.23.1 propcache-0.4.1 python-dotenv-1.0.1 python-json-logger-4.0.0 qtconsole-5.7.0 qtpy-2.4.3 referencing-0.37.0 requests-2.32.3 requests-toolbelt-1.0.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.1 send2trash-1.8.3 soupsieve-2.8 terminado-0.18.1 tiktoken-0.12.0 tinycss2-1.4.0 tld-0.13.1 trafilatura-2.0.0 typing-inspect-0.9.0 tzlocal-5.3.1 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.9.0 widgetsnbextension-4.0.14 yarl-1.22.0 zstandard-0.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r ./noveum_agent_requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7a810bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "\n",
    "# LangChain ecosystem\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Noveum Trace integration\n",
    "import noveum_trace\n",
    "from noveum_trace.context_managers import trace_operation, trace_agent\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed. Environment variables will be read from system only.\")\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## set openai api key\n",
    "## set gemini api key\n",
    "## set noveum api key\n",
    "## set environment\n",
    "## set project'\n",
    "\n",
    "# These are required for the project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noveum Trace initialized and configuration loaded!\n",
      "üîß Configuration: {'noveum_base_url': 'https://noveum.ai', 'max_pages_to_scrape': 50, 'chunk_size': 1000, 'chunk_overlap': 200, 'max_search_results': 5, 'rag_threshold': 0.7, 'noveum_docs_file': 'noveum_docs.json', 'vector_store_path': 'noveum_vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Noveum Trace Integration & Configuration\n",
    "# Initialize the Noveum Trace SDK\n",
    "noveum_trace.init(\n",
    "    project=\"customer_support_agent\",\n",
    "    api_key=os.getenv(\"NOVEUM_API_KEY\"),\n",
    "    environment=\"dev-aman\",\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,  # Similarity threshold for RAG retrieval\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize web search tool\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "print(\"‚úÖ Noveum Trace initialized and configuration loaded!\")\n",
    "print(f\"üîß Configuration: {CONFIG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c765c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Website scraper initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Website Scraper - Extract content from noveum.ai and sub-URLs\n",
    "class NoveumWebsiteScraper:\n",
    "    def __init__(self, base_url: str, max_pages: int = 50):\n",
    "        self.base_url = base_url\n",
    "        self.max_pages = max_pages\n",
    "        self.scraped_urls = set()\n",
    "        self.scraped_content = []\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "    \n",
    "    def is_valid_url(self, url: str) -> bool:\n",
    "        \"\"\"Check if URL is valid and belongs to noveum.ai domain\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            return (\n",
    "                parsed.netloc in ['noveum.ai', 'www.noveum.ai'] and\n",
    "                not any(ext in url.lower() for ext in ['.pdf', '.jpg', '.png', '.gif', '.css', '.js', '.xml', '.txt']) and\n",
    "                '#' not in url\n",
    "            )\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def extract_text_content(self, html_content: str, url: str) -> str:\n",
    "        \"\"\"Extract clean text content from HTML\"\"\"\n",
    "        try:\n",
    "            # Use trafilatura for better text extraction\n",
    "            extracted = trafilatura.extract(html_content)\n",
    "            if extracted:\n",
    "                return extracted.strip()\n",
    "            \n",
    "            # Fallback to BeautifulSoup\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Get text and clean up\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {url}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def find_internal_links(self, html_content: str, current_url: str) -> List[str]:\n",
    "        \"\"\"Find all internal links from the current page\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            links = []\n",
    "            \n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                \n",
    "                if self.is_valid_url(full_url) and full_url not in self.scraped_urls:\n",
    "                    links.append(full_url)\n",
    "            \n",
    "            return links\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding links in {current_url}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def scrape_page(self, url: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Scrape a single page and return content\"\"\"\n",
    "        try:\n",
    "            print(f\"üîç Scraping: {url}\")\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Extract text content\n",
    "            text_content = self.extract_text_content(response.text, url)\n",
    "            \n",
    "            if not text_content or len(text_content) < 100:  # Skip pages with too little content\n",
    "                print(f\"‚ö†Ô∏è  Skipping {url} - insufficient content\")\n",
    "                return None\n",
    "            \n",
    "            # Find internal links\n",
    "            internal_links = self.find_internal_links(response.text, url)\n",
    "            \n",
    "            page_data = {\n",
    "                \"url\": url,\n",
    "                \"title\": self.extract_title(response.text),\n",
    "                \"content\": text_content,\n",
    "                \"content_length\": len(text_content),\n",
    "                \"internal_links\": internal_links,\n",
    "                \"scraped_at\": time.time()\n",
    "            }\n",
    "            \n",
    "            print(f\"‚úÖ Scraped {url} - {len(text_content)} chars, {len(internal_links)} internal links\")\n",
    "            return page_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error scraping {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_title(self, html_content: str) -> str:\n",
    "        \"\"\"Extract page title\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            title_tag = soup.find('title')\n",
    "            return title_tag.get_text().strip() if title_tag else \"Untitled\"\n",
    "        except:\n",
    "            return \"Untitled\"\n",
    "    \n",
    "    def scrape_website(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Main scraping function - scrape noveum.ai recursively\"\"\"\n",
    "        print(f\"üöÄ Starting to scrape {self.base_url}\")\n",
    "        \n",
    "        urls_to_scrape = [self.base_url]\n",
    "        self.scraped_urls.add(self.base_url)\n",
    "        \n",
    "        with trace_operation(\"noveum_website_scraping\") as scrape_span:\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.base_url\": self.base_url,\n",
    "                \"scraper.max_pages\": self.max_pages,\n",
    "                \"input_query\": f\"Scrape website: {self.base_url}\",\n",
    "                \"output_response\": f\"Scraping completed: {len(self.scraped_content)} pages scraped, {sum(page['content_length'] for page in self.scraped_content)} total characters extracted\"\n",
    "            })\n",
    "            \n",
    "            while urls_to_scrape and len(self.scraped_content) < self.max_pages:\n",
    "                current_url = urls_to_scrape.pop(0)\n",
    "                \n",
    "                # Scrape the current page\n",
    "                page_data = self.scrape_page(current_url)\n",
    "                \n",
    "                if page_data:\n",
    "                    self.scraped_content.append(page_data)\n",
    "                    \n",
    "                    # Add new internal links to the queue\n",
    "                    for link in page_data[\"internal_links\"]:\n",
    "                        if link not in self.scraped_urls and len(urls_to_scrape) < 100:  # Prevent infinite loops\n",
    "                            urls_to_scrape.append(link)\n",
    "                            self.scraped_urls.add(link)\n",
    "                    \n",
    "                    # Add page data to span\n",
    "                    scrape_span.add_event(\"page_scraped\", {\n",
    "                        \"input_query\": f\"Scrape page: {current_url}\",\n",
    "                        \"output_response\": f\"Page scraped successfully: {page_data['content_length']} characters, {len(page_data['internal_links'])} internal links found\",\n",
    "                        \"url\": current_url,\n",
    "                        \"content_length\": page_data[\"content_length\"],\n",
    "                        \"internal_links_found\": len(page_data[\"internal_links\"])\n",
    "                    })\n",
    "                \n",
    "                # Small delay to be respectful\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            # Final metrics\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.pages_scraped\": len(self.scraped_content),\n",
    "                \"scraper.total_urls_found\": len(self.scraped_urls),\n",
    "                \"scraper.total_content_length\": sum(page[\"content_length\"] for page in self.scraped_content)\n",
    "            })\n",
    "        \n",
    "        print(f\"‚úÖ Scraping complete! Scraped {len(self.scraped_content)} pages\")\n",
    "        return self.scraped_content\n",
    "    \n",
    "    def save_to_json(self, filename: str) -> None:\n",
    "        \"\"\"Save scraped content to JSON file\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.scraped_content, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"üíæ Saved scraped content to {filename}\")\n",
    "\n",
    "# Initialize scraper\n",
    "scraper = NoveumWebsiteScraper(CONFIG[\"noveum_base_url\"], CONFIG[\"max_pages_to_scrape\"])\n",
    "print(\"‚úÖ Website scraper initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d0e2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: RAG System - Vector search and retrieval over scraped content\n",
    "class NoveumRAGSystem:\n",
    "    def __init__(self, embeddings, llm, config):\n",
    "        self.embeddings = embeddings\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        self.vectorstore = None\n",
    "        self.documents = []\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=config[\"chunk_size\"],\n",
    "            chunk_overlap=config[\"chunk_overlap\"]\n",
    "        )\n",
    "    \n",
    "    def load_documents_from_json(self, json_file: str) -> List[Document]:\n",
    "        \"\"\"Load documents from scraped JSON file\"\"\"\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                scraped_data = json.load(f)\n",
    "            \n",
    "            documents = []\n",
    "            for page in scraped_data:\n",
    "                # Create document from page content\n",
    "                doc = Document(\n",
    "                    page_content=page[\"content\"],\n",
    "                    metadata={\n",
    "                        \"url\": page[\"url\"],\n",
    "                        \"title\": page[\"title\"],\n",
    "                        \"content_length\": page[\"content_length\"],\n",
    "                        \"scraped_at\": page[\"scraped_at\"]\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            print(f\"‚úÖ Loaded {len(documents)} documents from {json_file}\")\n",
    "            return documents\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ùå File {json_file} not found. Please run the scraper first.\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_vectorstore(self, documents: List[Document]) -> None:\n",
    "        \"\"\"Create FAISS vector store from documents\"\"\"\n",
    "        if not documents:\n",
    "            print(\"‚ùå No documents to create vector store\")\n",
    "            return\n",
    "        \n",
    "        print(\"üîÑ Creating vector store...\")\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        split_docs = self.text_splitter.split_documents(documents)\n",
    "        print(f\"üìÑ Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vectorstore = FAISS.from_documents(split_docs, self.embeddings)\n",
    "        \n",
    "        # Save vector store\n",
    "        self.vectorstore.save_local(self.config[\"vector_store_path\"])\n",
    "        print(f\"üíæ Vector store saved to {self.config['vector_store_path']}\")\n",
    "    \n",
    "    def load_vectorstore(self) -> bool:\n",
    "        \"\"\"Load existing vector store from disk\"\"\"\n",
    "        try:\n",
    "            self.vectorstore = FAISS.load_local(\n",
    "                self.config[\"vector_store_path\"], \n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            print(f\"‚úÖ Loaded existing vector store from {self.config['vector_store_path']}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading vector store: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_relevant_docs(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Search for relevant documents using similarity search\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            print(\"‚ùå Vector store not initialized\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Perform similarity search\n",
    "            docs = self.vectorstore.similarity_search(query, k=k)\n",
    "            \n",
    "            # Filter by similarity threshold if needed\n",
    "            # Note: FAISS doesn't return scores by default, but we can add that if needed\n",
    "            \n",
    "            print(f\"üîç Found {len(docs)} relevant documents for query: '{query}'\")\n",
    "            return docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error searching documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def retrieve_context(self, query: str, max_docs: int = 5) -> str:\n",
    "        \"\"\"Retrieve and format context for the query\"\"\"\n",
    "        relevant_docs = self.search_relevant_docs(query, max_docs)\n",
    "        \n",
    "        if not relevant_docs:\n",
    "            return \"No relevant information found in Noveum documentation.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            context_parts.append(f\"Source {i} ({doc.metadata.get('url', 'Unknown URL')}):\\n{doc.page_content[:500]}...\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_rag_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using RAG\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"rag_agent\",\n",
    "            operation=\"llm-rag\",\n",
    "            capabilities=[\"document_retrieval\", \"context_generation\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_rag_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as rag_span:\n",
    "            \n",
    "            # Retrieve relevant context\n",
    "            context = self.retrieve_context(query, CONFIG[\"max_search_results\"])\n",
    "            \n",
    "            # Create prompt for RAG\n",
    "            rag_prompt = f\"\"\"You are a helpful assistant for Noveum.ai. Answer the user's question based on the provided context from Noveum's documentation.\n",
    "\n",
    "Context from Noveum documentation:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based primarily on the provided context\n",
    "2. If the context doesn't contain enough information, say so clearly\n",
    "3. Be specific and cite sources when possible\n",
    "4. Keep responses concise but informative\n",
    "5. If the question is not related to Noveum, politely redirect to ask about Noveum\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "            \n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(rag_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                if response.content:\n",
    "                    answer = response.content\n",
    "                else:\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(rag_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track retrieval, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"rag_evaluation_metrics\",\n",
    "                capabilities=[\"retrieval_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as rag_node:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer)\n",
    "                sources_count = len(context.split(\"Source\")) - 1 if \"Source\" in context else 0\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                rag_node.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_evaluation_query\",\n",
    "                    \n",
    "                    # Retrieval metrics\n",
    "                    \"retrieval.context_retrieved\": f\"Context: {context[:300]}{'...' if len(context) > 300 else ''}\",\n",
    "                    \"retrieval.context_length\": context_length,\n",
    "                    \"retrieval.sources_count\": sources_count,\n",
    "                    \"retrieval.context_quality\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"retrieval.effectiveness\": sources_count / 5.0,  # Normalized to max expected sources\n",
    "                    \"retrieval.context_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": rag_prompt,\n",
    "                    \"prompt.prompt_length\": len(rag_prompt),\n",
    "                    \"prompt.context_injection\": f\"Context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"rag_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 100 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 200 and sources_count > 2 else \"medium\" if answer_length > 100 else \"low\",\n",
    "                    \"response.source_citation\": sources_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.retrieval_effectiveness\": sources_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 150 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": sources_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 200 and sources_count > 2 and context_length > 500 else \"medium\" if answer_length > 100 and sources_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # RAG-specific metrics\n",
    "                    \"rag.retrieval_strategy\": \"semantic_similarity\",\n",
    "                    \"rag.vector_search_results\": sources_count,\n",
    "                    \"rag.context_synthesis\": \"multi_source\" if sources_count > 1 else \"single_source\",\n",
    "                    \"rag.document_coverage\": sources_count / 5.0,  # Normalized coverage\n",
    "                    \"rag.information_density\": answer_length / context_length if context_length > 0 else 0\n",
    "                })\n",
    "\n",
    "            # Set main RAG span attributes (simplified)\n",
    "            rag_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"rag_query\",\n",
    "                \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                \"rag.context_length\": context_length,\n",
    "                \"rag.sources_count\": sources_count,\n",
    "                \"rag.answer_length\": answer_length,\n",
    "                \"rag.mode\": \"retrieval_augmented_generation\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"RAG\",\n",
    "                \"sources\": [doc.metadata.get('url', 'Unknown') for doc in self.search_relevant_docs(query, CONFIG[\"max_search_results\"])],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = NoveumRAGSystem(embeddings, llm, CONFIG)\n",
    "print(\"‚úÖ RAG system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "09823cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Web search system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Web Search Integration - DuckDuckGo search for external queries\n",
    "class NoveumWebSearchSystem:\n",
    "    def __init__(self, web_search_tool, llm, config):\n",
    "        self.web_search = web_search_tool\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "    \n",
    "    def search_web(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Perform web search and return formatted results\"\"\"\n",
    "        try:\n",
    "            # Perform web search\n",
    "            search_results = self.web_search.run(query)\n",
    "            \n",
    "            # Parse results (DuckDuckGo returns a string, need to parse it)\n",
    "            results = []\n",
    "            if isinstance(search_results, str):\n",
    "                # Split by lines and parse each result\n",
    "                lines = search_results.split('\\n')\n",
    "                for i, line in enumerate(lines[:max_results]):\n",
    "                    if line.strip():\n",
    "                        results.append({\n",
    "                            \"title\": f\"Search Result {i+1}\",\n",
    "                            \"snippet\": line.strip(),\n",
    "                            \"url\": f\"https://duckduckgo.com/?q={query.replace(' ', '+')}\"\n",
    "                        })\n",
    "            else:\n",
    "                # If it's already a list/dict format\n",
    "                results = search_results[:max_results]\n",
    "            \n",
    "            print(f\"üîç Found {len(results)} web search results for: '{query}'\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error performing web search: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def format_search_context(self, search_results: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format search results into context string\"\"\"\n",
    "        if not search_results:\n",
    "            return \"No search results found.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, result in enumerate(search_results, 1):\n",
    "            title = result.get('title', f'Result {i}')\n",
    "            snippet = result.get('snippet', 'No description available')\n",
    "            url = result.get('url', 'No URL available')\n",
    "            \n",
    "            context_parts.append(f\"Source {i} - {title}:\\n{snippet}\\nURL: {url}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_web_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using web search\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"web_search_agent\",\n",
    "            operation=\"web_search_generation\",\n",
    "            capabilities=[\"web_search\", \"content_synthesis\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_web_search_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as web_span:\n",
    "            \n",
    "            # Perform web search\n",
    "            search_results = self.search_web(query, self.config[\"max_search_results\"])\n",
    "            \n",
    "            # Format context\n",
    "            context = self.format_search_context(search_results)\n",
    "            \n",
    "            # Create prompt for web search response\n",
    "            web_prompt = f\"\"\"You are a helpful assistant. Answer the user's question based on the provided web search results.\n",
    "\n",
    "Web Search Results:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based on the provided web search results\n",
    "2. Synthesize information from multiple sources when relevant\n",
    "3. Be informative and accurate\n",
    "4. If the results don't contain enough information, say so clearly\n",
    "5. Keep responses concise but comprehensive\n",
    "6. Cite sources when possible\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(web_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                # Handle response content extraction\n",
    "                if hasattr(response, 'content'):\n",
    "                    # When response is a proper SDK object\n",
    "                    answer = response.content\n",
    "                elif isinstance(response, dict):\n",
    "                    # When response is returned as a plain dict\n",
    "                    answer = response.get('content', '')\n",
    "                else:\n",
    "                    # Fallback to string\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(web_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track web search, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"web_search_evaluation_metrics\",\n",
    "                capabilities=[\"web_search_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                search_results_count = len(search_results)\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer or \"\")\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_evaluation_query\",\n",
    "                    \n",
    "                    # Web search metrics\n",
    "                    \"web_search.results_count\": search_results_count,\n",
    "                    \"web_search.context_length\": context_length,\n",
    "                    \"web_search.context_synthesized\": f\"Context from {search_results_count} web sources\",\n",
    "                    \"web_search.search_effectiveness\": search_results_count / 5.0,  # Normalized to max expected results\n",
    "                    \"web_search.context_quality\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"web_search.source_diversity\": search_results_count,\n",
    "                    \"web_search.information_synthesis\": \"high\" if search_results_count > 3 and answer_length > 200 else \"medium\" if search_results_count > 1 else \"low\",\n",
    "                    \"web_search.external_knowledge_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": web_prompt,\n",
    "                    \"prompt.prompt_length\": len(web_prompt),\n",
    "                    \"prompt.context_injection\": f\"Web context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"web_search_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 150 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 300 and search_results_count > 3 else \"medium\" if answer_length > 150 else \"low\",\n",
    "                    \"response.source_citation\": search_results_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.search_effectiveness\": search_results_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 200 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": search_results_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 300 and search_results_count > 3 and context_length > 800 else \"medium\" if answer_length > 150 and search_results_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Web search specific metrics\n",
    "                    \"web_search.search_strategy\": \"duckduckgo_api\",\n",
    "                    \"web_search.real_time_data\": True,\n",
    "                    \"web_search.external_sources\": search_results_count,\n",
    "                    \"web_search.information_freshness\": \"current\",\n",
    "                    \"web_search.knowledge_synthesis\": \"multi_source\" if search_results_count > 1 else \"single_source\"\n",
    "                })\n",
    "\n",
    "            # Set main Web Search span attributes (simplified)\n",
    "            web_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"web_search_query\",\n",
    "                \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                \"web_search.results_count\": search_results_count,\n",
    "                \"web_search.context_length\": context_length,\n",
    "                \"web_search.response_length\": answer_length,\n",
    "                \"web_search.mode\": \"external_web_search\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"Web Search\",\n",
    "                \"sources\": [result.get('url', 'Unknown') for result in search_results],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize web search system\n",
    "web_search_system = NoveumWebSearchSystem(web_search, llm, CONFIG)\n",
    "print(\"‚úÖ Web search system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d47287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query router initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Query Router - Intelligent decision making between RAG and Web Search\n",
    "class NoveumQueryRouter:\n",
    "    def __init__(self, llm, config):\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        \n",
    "        # Keywords that suggest RAG should be used\n",
    "        self.rag_keywords = [\n",
    "            \"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\",\n",
    "            \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\",\n",
    "            \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\",\n",
    "            \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"\n",
    "        ]\n",
    "        \n",
    "        # Keywords that suggest Web Search should be used\n",
    "        self.web_keywords = [\n",
    "            \"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\",\n",
    "            \"today\", \"yesterday\", \"this week\", \"this month\", \"current\",\n",
    "            \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\",\n",
    "            \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\",\n",
    "            \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"\n",
    "        ]\n",
    "    \n",
    "    def classify_query(self, query: str) -> str:\n",
    "        \"\"\"Classify query to determine whether to use RAG or Web Search\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Check for RAG keywords\n",
    "        rag_score = sum(1 for keyword in self.rag_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for Web Search keywords\n",
    "        web_score = sum(1 for keyword in self.web_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for explicit mentions of Noveum\n",
    "        if \"noveum\" in query_lower:\n",
    "            return \"RAG\"\n",
    "        \n",
    "        # If both scores are 0, use LLM-based classification\n",
    "        if rag_score == 0 and web_score == 0:\n",
    "            return self._llm_classify_query(query)\n",
    "        \n",
    "        # Return the mode with higher score\n",
    "        return \"RAG\" if rag_score >= web_score else \"Web Search\"\n",
    "    \n",
    "    def _llm_classify_query(self, query: str) -> str:\n",
    "        \"\"\"Use LLM to classify query when keyword matching is inconclusive\"\"\"\n",
    "        try:\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "\n",
    "            # Extract model parameters for tracking\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span for classification\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                response = self.llm.invoke(classification_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "            \n",
    "                if hasattr(response, 'content'):\n",
    "                    result = response.content.strip().upper()\n",
    "                else:\n",
    "                    result = str(response).strip().upper()\n",
    "\n",
    "                # Extract token usage for classification\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                \n",
    "                # If still no tokens found, estimate\n",
    "                if total_tokens == 0:\n",
    "                    estimated_prompt_tokens = len(classification_prompt) // 4\n",
    "                    estimated_completion_tokens = len(result) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"classification_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 1.0 else \"medium\" if model_latency < 3.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(result) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(result),\n",
    "                    \"model.response_quality\": \"high\" if len(result) > 10 else \"medium\" if len(result) > 5 else \"low\",\n",
    "                    \"model.output_response\": f\"Classification Result: {result}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Log classification details for debugging\n",
    "            print(f\"üîç LLM Classification - Model: {model_name}, Tokens: {total_tokens}, Result: {result}\")\n",
    "            \n",
    "            if \"RAG\" in result:\n",
    "                return \"RAG\"\n",
    "            elif \"WEB\" in result or \"SEARCH\" in result:\n",
    "                return \"Web Search\"\n",
    "            else:\n",
    "                # Default to Web Search if unclear\n",
    "                return \"Web Search\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in LLM classification: {e}\")\n",
    "            # Default to Web Search on error\n",
    "            return \"Web Search\"\n",
    "    \n",
    "    def route_query(self, query: str) -> Tuple[str, Dict[str, Any]]:\n",
    "        \"\"\"Route query to appropriate system and return response\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"query_router\",\n",
    "            operation=\"query_routing\",\n",
    "            capabilities=[\"query_classification\", \"routing_decision\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_query_router\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as router_span:\n",
    "            \n",
    "            # Define classification prompt for tracing\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "            \n",
    "            # Classify the query\n",
    "            mode = self.classify_query(query)\n",
    "            \n",
    "            # Calculate routing evaluation metrics\n",
    "            query_lower = query.lower()\n",
    "            rag_keywords = [\"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\", \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\", \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\", \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"]\n",
    "            web_keywords = [\"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\", \"today\", \"yesterday\", \"this week\", \"this month\", \"current\", \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\", \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\", \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"]\n",
    "            \n",
    "            rag_score = sum(1 for keyword in rag_keywords if keyword in query_lower)\n",
    "            web_score = sum(1 for keyword in web_keywords if keyword in query_lower)\n",
    "            confidence_score = abs(rag_score - web_score) / max(rag_score + web_score, 1)\n",
    "            \n",
    "            # Other Details Span - Track routing analysis and decision metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"routing_evaluation_metrics\",\n",
    "                capabilities=[\"routing_analysis\", \"decision_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"routing_evaluation_query\",\n",
    "                    \n",
    "                    # Classification metrics\n",
    "                    \"classification.mode\": mode,\n",
    "                    \"classification.rag_keyword_score\": rag_score,\n",
    "                    \"classification.web_keyword_score\": web_score,\n",
    "                    \"classification.confidence_score\": confidence_score,\n",
    "                    \"classification.confidence_level\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"classification.method\": \"llm_based\" if rag_score == 0 and web_score == 0 else \"keyword_based\",\n",
    "                    \n",
    "                    # Query analysis metrics\n",
    "                    \"query.complexity\": \"complex\" if len(query) > 50 else \"medium\" if len(query) > 20 else \"simple\",\n",
    "                    \"query.intent\": \"noveum_specific\" if \"noveum\" in query_lower else \"general_knowledge\" if web_score > rag_score else \"documentation\",\n",
    "                    \"query.keyword_density\": (rag_score + web_score) / len(query.split()),\n",
    "                    \"query.domain_affinity\": \"noveum\" if rag_score > web_score else \"general\" if web_score > rag_score else \"neutral\",\n",
    "                    \n",
    "                    # Routing decision metrics\n",
    "                    \"routing.decision\": f\"Routed to {mode} based on analysis\",\n",
    "                    \"routing.rationale\": f\"RAG score: {rag_score}, Web score: {web_score}, Confidence: {confidence_score:.2f}\",\n",
    "                    \"routing.expected_performance\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"routing.alternative_mode\": \"Web Search\" if mode == \"RAG\" else \"RAG\",\n",
    "                    \"routing.decision_confidence\": confidence_score,\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.routing_accuracy\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"evaluation.keyword_coverage\": (rag_score + web_score) / len(rag_keywords + web_keywords),\n",
    "                    \"evaluation.query_understanding\": \"clear\" if confidence_score > 0.5 else \"ambiguous\" if confidence_score > 0.2 else \"unclear\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Router-specific metrics\n",
    "                    \"router.classification_strategy\": \"hybrid_keyword_llm\",\n",
    "                    \"router.keyword_matching\": \"used\" if rag_score > 0 or web_score > 0 else \"bypassed\",\n",
    "                    \"router.llm_fallback\": \"used\" if rag_score == 0 and web_score == 0 else \"not_needed\",\n",
    "                    \"router.decision_time\": \"instant\" if rag_score > 0 or web_score > 0 else \"llm_required\",\n",
    "                    \"output_response\": f\"Routing Decision: {mode} (Confidence: {confidence_score:.2f})\"\n",
    "                })\n",
    "\n",
    "            # Set main router span attributes (simplified)\n",
    "            router_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"routing_query\",\n",
    "                \"output_response\": f\"Routed to {mode} for query processing\",\n",
    "                \"router.classification\": mode,\n",
    "                \"router.confidence_score\": confidence_score,\n",
    "                \"router.rag_keyword_score\": rag_score,\n",
    "                \"router.web_keyword_score\": web_score,\n",
    "                \"router.mode\": \"intelligent_routing\"\n",
    "            })\n",
    "            \n",
    "            # Route to appropriate system\n",
    "            if mode == \"RAG\":\n",
    "                print(f\"üß† Routing to RAG system for: '{query}'\")\n",
    "                response = rag_system.generate_rag_response(query)\n",
    "            else:\n",
    "                print(f\"üåê Routing to Web Search for: '{query}'\")\n",
    "                response = web_search_system.generate_web_response(query)\n",
    "            \n",
    "            return mode, response\n",
    "\n",
    "# Initialize query router\n",
    "query_router = NoveumQueryRouter(llm, CONFIG)\n",
    "print(\"‚úÖ Query router initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a865a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Noveum AI Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Executor - Orchestrates the complete agent workflow\n",
    "class NoveumAIAgent:\n",
    "    def __init__(self, scraper, rag_system, web_search_system, query_router, config):\n",
    "        self.scraper = scraper\n",
    "        self.rag_system = rag_system\n",
    "        self.web_search_system = web_search_system\n",
    "        self.query_router = query_router\n",
    "        self.config = config\n",
    "        self.is_initialized = False\n",
    "    \n",
    "    def initialize_system(self, force_scrape: bool = False) -> bool:\n",
    "        \"\"\"Initialize the system by setting up RAG with scraped data\"\"\"\n",
    "        print(\"üöÄ Initializing Noveum AI Agent...\")\n",
    "        \n",
    "        with trace_operation(\"system_initialization\") as init_span:\n",
    "            init_span.set_attributes({\n",
    "                \"system.force_scrape\": force_scrape,\n",
    "                \"system.config\": self.config,\n",
    "                \"input_query\": f\"Initialize system with force_scrape={force_scrape}\",\n",
    "                \"output_response\": \"System initialization: RAG system loaded, vector store ready, agent operational\"\n",
    "            })\n",
    "            \n",
    "            # Check if we need to scrape or if data already exists\n",
    "            if force_scrape or not os.path.exists(self.config[\"noveum_docs_file\"]):\n",
    "                print(\"üì• Scraping Noveum website...\")\n",
    "                \n",
    "                # Scrape the website\n",
    "                scraped_data = self.scraper.scrape_website()\n",
    "                \n",
    "                if not scraped_data:\n",
    "                    print(\"‚ùå Failed to scrape website data\")\n",
    "                    return False\n",
    "                \n",
    "                # Save scraped data\n",
    "                self.scraper.save_to_json(self.config[\"noveum_docs_file\"])\n",
    "                \n",
    "                init_span.add_event(\"website_scraped\", {\n",
    "                    \"input_query\": f\"Scrape website: {self.config['noveum_base_url']}\",\n",
    "                    \"output_response\": f\"Website scraping completed: {len(scraped_data)} pages scraped, {sum(page['content_length'] for page in scraped_data)} total characters extracted for RAG system\",\n",
    "                    \"pages_scraped\": len(scraped_data),\n",
    "                    \"total_content_length\": sum(page[\"content_length\"] for page in scraped_data)\n",
    "                })\n",
    "            else:\n",
    "                print(\"üìÅ Using existing scraped data...\")\n",
    "            \n",
    "            # Load documents and create/load vector store\n",
    "            documents = self.rag_system.load_documents_from_json(self.config[\"noveum_docs_file\"])\n",
    "            \n",
    "            if not documents:\n",
    "                print(\"‚ùå Failed to load documents\")\n",
    "                return False\n",
    "            \n",
    "            # Try to load existing vector store, create if doesn't exist\n",
    "            if not self.rag_system.load_vectorstore():\n",
    "                print(\"üîÑ Creating new vector store...\")\n",
    "                self.rag_system.create_vectorstore(documents)\n",
    "            \n",
    "            self.is_initialized = True\n",
    "            print(\"‚úÖ Noveum AI Agent initialized successfully!\")\n",
    "            \n",
    "            init_span.set_attributes({\n",
    "                \"system.initialized\": True,\n",
    "                \"system.documents_loaded\": len(documents),\n",
    "                \"system.vectorstore_ready\": self.rag_system.vectorstore is not None\n",
    "            })\n",
    "            \n",
    "            return True\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a user query and return response\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            print(\"‚ùå System not initialized. Please run initialize_system() first.\")\n",
    "            return {\n",
    "                \"answer\": \"System not initialized. Please run initialize_system() first.\",\n",
    "                \"mode\": \"Error\",\n",
    "                \"sources\": [],\n",
    "                \"error\": \"System not initialized\"\n",
    "            }\n",
    "        \n",
    "        print(f\"\\nüéØ Processing query: '{query}'\")\n",
    "        \n",
    "        with trace_operation(\"tool-orchestator\") as process_span:\n",
    "            process_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query.length\": len(query)\n",
    "            })\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Route query and get response\n",
    "                mode, response = self.query_router.route_query(query)\n",
    "                \n",
    "                # Add processing metrics\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                response.update({\n",
    "                    \"processing_time\": processing_time,\n",
    "                    \"timestamp\": time.time()\n",
    "                })\n",
    "                \n",
    "                # Add metrics to span\n",
    "                process_span.set_attributes({\n",
    "                    \"processing.mode\": mode,\n",
    "                    \"processing.time_seconds\": processing_time,\n",
    "                    \"processing.response_length\": len(response.get(\"answer\", \"\")),\n",
    "                    \"processing.sources_count\": len(response.get(\"sources\", [])),\n",
    "                    \"output_response\": f\"Final Answer: {response.get('answer', '')[:200]}{'...' if len(response.get('answer', '')) > 200 else ''}\",\n",
    "                    \"final_answer_mode\": mode,\n",
    "                    \"query_processed.input_query\": query,\n",
    "                    \"query_processed.output_response\": f\"Successfully processed query using {mode}, generated {len(response.get('answer', ''))} character response\",\n",
    "                    \"query_processed.mode\": mode,\n",
    "                    \"query_processed.processing_time\": processing_time,\n",
    "                    \"query_processed.response_length\": len(response.get(\"answer\", \"\"))\n",
    "                })\n",
    "                \n",
    "                print(f\"‚úÖ Query processed in {processing_time:.2f}s using {mode}\")\n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error processing query: {str(e)}\"\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                \n",
    "                process_span.add_event(\"query_processing_error\", {\n",
    "                    \"error\": str(e),\n",
    "                    \"input_query\": query,\n",
    "                    \"output_response\": f\"I encountered an error while processing your query: {str(e)}\"\n",
    "                })\n",
    "                \n",
    "                return {\n",
    "                    \"answer\": f\"I encountered an error while processing your query: {str(e)}\",\n",
    "                    \"mode\": \"Error\",\n",
    "                    \"sources\": [],\n",
    "                    \"error\": str(e),\n",
    "                    \"processing_time\": time.time() - start_time\n",
    "                }\n",
    "    \n",
    "    def display_response(self, response: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display the response in a formatted way\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ü§ñ NOVEUM AI AGENT RESPONSE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"üìä Mode: {response.get('mode', 'Unknown')}\")\n",
    "        print(f\"‚è±Ô∏è  Processing Time: {response.get('processing_time', 0):.2f}s\")\n",
    "        print(f\"üìÖ Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(response.get('timestamp', time.time())))}\")\n",
    "        \n",
    "        if response.get('sources'):\n",
    "            print(f\"üìö Sources ({len(response['sources'])}):\")\n",
    "            for i, source in enumerate(response['sources'][:3], 1):  # Show first 3 sources\n",
    "                print(f\"   {i}. {source}\")\n",
    "            if len(response['sources']) > 3:\n",
    "                print(f\"   ... and {len(response['sources']) - 3} more\")\n",
    "        \n",
    "        print(\"\\nüí¨ Answer:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(response.get('answer', 'No answer provided'))\n",
    "        print(\"=\"*80)\n",
    "\n",
    "# Initialize the main agent\n",
    "noveum_agent = NoveumAIAgent(scraper, rag_system, web_search_system, query_router, CONFIG)\n",
    "print(\"‚úÖ Noveum AI Agent initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b30e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Demo functions ready!\n",
      "\n",
      "üöÄ To get started:\n",
      "1. Run: demo_noveum_agent()  # For a full demo\n",
      "2. Run: ask_question('Your question here')  # For a single question\n",
      "3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Usage Examples and Demo\n",
    "def demo_noveum_agent():\n",
    "    \"\"\"Demo function showing how to use the Noveum AI Agent\"\"\"\n",
    "    \n",
    "    print(\"üé¨ NOVEUM AI AGENT DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Initialize the system\n",
    "    print(\"\\n1Ô∏è‚É£ Initializing the system...\")\n",
    "    success = noveum_agent.initialize_system(force_scrape=False)  # Set to True to force re-scraping\n",
    "    \n",
    "    if not success:\n",
    "        print(\"‚ùå Failed to initialize system\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Demo queries - 20 comprehensive test questions\n",
    "    demo_queries = [\n",
    "        # RAG Queries (Noveum-specific)\n",
    "        \"What is Noveum and what does it do?\",  # Basic product info\n",
    "        \"How do I integrate Noveum Trace in my application?\",  # Technical integration\n",
    "        \"What are Noveum's pricing plans?\",  # Pricing information\n",
    "        \"What features does Noveum Trace offer?\",  # Feature overview\n",
    "        \"How do I set up observability with Noveum?\",  # Setup guidance\n",
    "        \"What APIs are available in Noveum platform?\",  # API documentation\n",
    "        \"How does Noveum handle agent tracing?\",  # Technical details\n",
    "        \"What monitoring capabilities does Noveum provide?\",  # Capabilities\n",
    "        \"How do I configure Noveum for my system?\",  # Configuration\n",
    "        \"What are the benefits of using Noveum Trace?\",  # Value proposition\n",
    "        \n",
    "        # Web Search Queries (External/Recent information)\n",
    "        \"What are the latest AI news today?\",  # Recent news\n",
    "        \"What's the weather like today?\",  # Current weather\n",
    "        \"Tell me about recent developments in machine learning\",  # Recent developments\n",
    "        \"What are the current trends in observability tools?\",  # Industry trends\n",
    "        \"What happened in tech news this week?\",  # Weekly tech news\n",
    "        \"What are the latest updates in Python programming?\",  # Recent updates\n",
    "        \"What's the current status of cryptocurrency markets?\",  # Market information\n",
    "        \"What are the newest features in cloud computing?\",  # Recent features\n",
    "        \"What's happening in the software development world today?\",  # Current events\n",
    "        \"What are the latest breakthroughs in artificial intelligence?\"  # Recent breakthroughs\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n2Ô∏è‚É£ Running {len(demo_queries)} demo queries...\")\n",
    "    \n",
    "    for i, query in enumerate(demo_queries, 1):\n",
    "        print(f\"\\n--- Demo Query {i} ---\")\n",
    "        response = noveum_agent.process_query(query)\n",
    "        noveum_agent.display_response(response)\n",
    "        \n",
    "        # Small delay between queries\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"\\nüéâ Demo completed! Check Noveum Trace dashboard for detailed observability data.\")\n",
    "    print(\"üí° You can now use noveum_agent.process_query('your question') for your own queries!\")\n",
    "\n",
    "# Interactive query function\n",
    "def ask_question(question: str):\n",
    "    \"\"\"Convenience function to ask a single question\"\"\"\n",
    "    if not noveum_agent.is_initialized:\n",
    "        print(\"‚ö†Ô∏è  System not initialized. Initializing now...\")\n",
    "        if not noveum_agent.initialize_system():\n",
    "            print(\"‚ùå Failed to initialize system\")\n",
    "            return\n",
    "    \n",
    "    response = noveum_agent.process_query(question)\n",
    "    noveum_agent.display_response(response)\n",
    "    return response\n",
    "\n",
    "print(\"‚úÖ Demo functions ready!\")\n",
    "print(\"\\nüöÄ To get started:\")\n",
    "print(\"1. Run: demo_noveum_agent()  # For a full demo\")\n",
    "print(\"2. Run: ask_question('Your question here')  # For a single question\")\n",
    "print(\"3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f727a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ NOVEUM AI AGENT DEMO\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Initializing the system...\n",
      "üöÄ Initializing Noveum AI Agent...\n",
      "üìÅ Using existing scraped data...\n",
      "‚úÖ Loaded 38 documents from noveum_docs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:26:35 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_system_initialization (ID: 9af2b4b0-0c2f-4d2e-ae99-30df0d2f0fa6) - 1 spans\n",
      "2025-10-22 22:26:35 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_system_initialization (ID: 9af2b4b0-0c2f-4d2e-ae99-30df0d2f0fa6) - 1 spans\n",
      "2025-10-22 22:26:35 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9af2b4b0-0c2f-4d2e-ae99-30df0d2f0fa6\n",
      "2025-10-22 22:26:35 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9af2b4b0-0c2f-4d2e-ae99-30df0d2f0fa6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded existing vector store from noveum_vectorstore\n",
      "‚úÖ Noveum AI Agent initialized successfully!\n",
      "\n",
      "2Ô∏è‚É£ Running 20 demo queries...\n",
      "\n",
      "--- Demo Query 1 ---\n",
      "\n",
      "üéØ Processing query: 'What is Noveum and what does it do?'\n",
      "üß† Routing to RAG system for: 'What is Noveum and what does it do?'\n",
      "üîç Found 5 relevant documents for query: 'What is Noveum and what does it do?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:26:43 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 3ad192e5-bbd4-4236-8144-019d53512769) - 6 spans\n",
      "2025-10-22 22:26:43 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 3ad192e5-bbd4-4236-8144-019d53512769) - 6 spans\n",
      "2025-10-22 22:26:43 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3ad192e5-bbd4-4236-8144-019d53512769\n",
      "2025-10-22 22:26:43 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3ad192e5-bbd4-4236-8144-019d53512769 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What is Noveum and what does it do?'\n",
      "‚úÖ Query processed in 8.68s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 8.68s\n",
      "üìÖ Timestamp: 2025-10-22 22:26:43\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/en/docs/getting-started/overview\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "Noveum.ai is a comprehensive tracing and observability platform specifically designed for AI applications, including LLM-powered chatbots, RAG systems, and multi-agent workflows. It provides the necessary insights to understand, debug, and optimize these systems, addressing the complexities involved in building production AI applications, such as LLM calls, vector searches, and agent reasoning. Noveum.ai enhances visibility into these workflows, making debugging easier and optimization more effective (Source 1, Source 2).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 2 ---\n",
      "\n",
      "üéØ Processing query: 'How do I integrate Noveum Trace in my application?'\n",
      "üß† Routing to RAG system for: 'How do I integrate Noveum Trace in my application?'\n",
      "üîç Found 5 relevant documents for query: 'How do I integrate Noveum Trace in my application?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:26:53 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: bc60c122-f30b-4114-9f78-ee40a024b525) - 6 spans\n",
      "2025-10-22 22:26:53 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: bc60c122-f30b-4114-9f78-ee40a024b525) - 6 spans\n",
      "2025-10-22 22:26:53 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace bc60c122-f30b-4114-9f78-ee40a024b525\n",
      "2025-10-22 22:26:53 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace bc60c122-f30b-4114-9f78-ee40a024b525 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'How do I integrate Noveum Trace in my application?'\n",
      "‚úÖ Query processed in 8.83s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 8.83s\n",
      "üìÖ Timestamp: 2025-10-22 22:26:53\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/sdk-integration\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "To integrate Noveum Trace into your application, you can follow these steps based on the SDK Integration Guide:\n",
      "\n",
      "1. **Create Your Account & Get API Key**:\n",
      "   - Sign up at [noveum.ai](https://noveum.ai).\n",
      "   - Create a project in your dashboard.\n",
      "   - Generate an API key.\n",
      "\n",
      "2. **Choose Your SDK**:\n",
      "   - For Python applications, use the **Python SDK** (`noveum-trace`), which offers decorator-based tracing for LLM calls, agents, and RAG pipelines.\n",
      "   - For TypeScript applications, use the **TypeScript SDK** (`@noveum/trace`), designed for frameworks like Next.js, Express.js, and Hono, with full type safety.\n",
      "\n",
      "3. **Integrate the SDK**:\n",
      "   - Follow the specific integration instructions for your chosen SDK. The SDKs are designed to provide comprehensive tracing and observability with minimal code changes.\n",
      "\n",
      "4. **Capture Metrics**:\n",
      "   - The SDKs automatically capture essential metrics and traces, including performance metrics, cost tracking, request/response data, and metadata.\n",
      "\n",
      "For detailed integration steps, refer to the SDK Integration Guide in the Noveum documentation ([Source 3](https://noveum.ai/docs/getting-started/sdk-integration)).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 3 ---\n",
      "\n",
      "üéØ Processing query: 'What are Noveum's pricing plans?'\n",
      "üß† Routing to RAG system for: 'What are Noveum's pricing plans?'\n",
      "üîç Found 5 relevant documents for query: 'What are Noveum's pricing plans?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:26:58 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 29a862bf-d7aa-4cf9-963c-0a4244343bbe) - 6 spans\n",
      "2025-10-22 22:26:58 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 29a862bf-d7aa-4cf9-963c-0a4244343bbe) - 6 spans\n",
      "2025-10-22 22:26:58 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 29a862bf-d7aa-4cf9-963c-0a4244343bbe\n",
      "2025-10-22 22:26:58 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 29a862bf-d7aa-4cf9-963c-0a4244343bbe successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What are Noveum's pricing plans?'\n",
      "‚úÖ Query processed in 3.49s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 3.49s\n",
      "üìÖ Timestamp: 2025-10-22 22:26:58\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/docs/getting-started/overview\n",
      "   2. https://noveum.ai/en/docs/getting-started/overview\n",
      "   3. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not include specific information about Noveum's pricing plans. It mentions that all users will have access to the Observability suite for free, and early users will receive free evaluation jobs and premium support for the first year (Source 1 and Source 2). However, details on ongoing pricing or additional plans are not available in the documentation. If you have further questions about Noveum, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 4 ---\n",
      "\n",
      "üéØ Processing query: 'What features does Noveum Trace offer?'\n",
      "üß† Routing to RAG system for: 'What features does Noveum Trace offer?'\n",
      "üîç Found 5 relevant documents for query: 'What features does Noveum Trace offer?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:05 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: df0c6344-1a2e-4c53-bb7d-4e43b3bce1b8) - 6 spans\n",
      "2025-10-22 22:27:05 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: df0c6344-1a2e-4c53-bb7d-4e43b3bce1b8) - 6 spans\n",
      "2025-10-22 22:27:05 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace df0c6344-1a2e-4c53-bb7d-4e43b3bce1b8\n",
      "2025-10-22 22:27:05 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace df0c6344-1a2e-4c53-bb7d-4e43b3bce1b8 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What features does Noveum Trace offer?'\n",
      "‚úÖ Query processed in 6.38s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 6.38s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:05\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/en/docs/getting-started/sdk-integration\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "Noveum Trace offers several key features through its Python SDK (`noveum-trace`) and TypeScript SDK (`@noveum/trace`):\n",
      "\n",
      "1. **Decorator-based Tracing**: It provides a simple way to trace LLM calls, agents, and RAG pipelines using decorators.\n",
      "2. **Automatic Instrumentation**: The SDK automatically instruments popular AI frameworks, making it easier to integrate tracing without extensive manual setup.\n",
      "3. **Context Propagation**: It supports context propagation across asynchronous operations, ensuring that trace data remains consistent throughout the execution flow.\n",
      "4. **TypeScript-first Design**: The TypeScript SDK is designed with full type safety and universal compatibility across Node.js, Edge Runtime, and browsers.\n",
      "5. **Framework Integrations**: It includes integrations for popular frameworks like Next.js, Express.js, and Hono.\n",
      "\n",
      "Additionally, the Noveum Platform features a real-time dashboard for analyzing traces and performance, allowing for collaborative insights and monitoring (Sources 1, 2, 3, 4).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 5 ---\n",
      "\n",
      "üéØ Processing query: 'How do I set up observability with Noveum?'\n",
      "üß† Routing to RAG system for: 'How do I set up observability with Noveum?'\n",
      "üîç Found 5 relevant documents for query: 'How do I set up observability with Noveum?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:12 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 93bd37c4-4289-43c9-b34e-19eaaef610c2) - 6 spans\n",
      "2025-10-22 22:27:12 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 93bd37c4-4289-43c9-b34e-19eaaef610c2) - 6 spans\n",
      "2025-10-22 22:27:12 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 93bd37c4-4289-43c9-b34e-19eaaef610c2\n",
      "2025-10-22 22:27:12 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 93bd37c4-4289-43c9-b34e-19eaaef610c2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'How do I set up observability with Noveum?'\n",
      "‚úÖ Query processed in 5.72s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 5.72s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:12\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/en/docs/getting-started/tracing-concepts\n",
      "   3. https://noveum.ai/docs/getting-started/tracing-concepts\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "To set up observability with Noveum, follow these steps:\n",
      "\n",
      "1. **Sign Up**: Go to [noveum.ai](https://noveum.ai) and create an account.\n",
      "2. **Create a Project**: After signing up, create a project to obtain your API key.\n",
      "3. **Install the SDK**: Choose your preferred programming language and install the corresponding SDK.\n",
      "4. **Add Tracing**: Integrate tracing into your AI workflows using the SDK.\n",
      "5. **Explore Insights**: Use the Noveum.ai dashboard to analyze the insights gathered from your traces.\n",
      "\n",
      "For more detailed guidance, you can explore framework-specific integrations and advanced instrumentation techniques in the Noveum documentation (Source 2 and Source 3). Remember, effective observability is about collecting the right data to help you understand, debug, and optimize your AI applications (Source 2).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 6 ---\n",
      "\n",
      "üéØ Processing query: 'What APIs are available in Noveum platform?'\n",
      "üß† Routing to RAG system for: 'What APIs are available in Noveum platform?'\n",
      "üîç Found 5 relevant documents for query: 'What APIs are available in Noveum platform?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:18 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: fee3e6d3-8da1-4ef3-8214-a7d7323d3a49) - 6 spans\n",
      "2025-10-22 22:27:18 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: fee3e6d3-8da1-4ef3-8214-a7d7323d3a49) - 6 spans\n",
      "2025-10-22 22:27:18 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace fee3e6d3-8da1-4ef3-8214-a7d7323d3a49\n",
      "2025-10-22 22:27:18 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace fee3e6d3-8da1-4ef3-8214-a7d7323d3a49 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What APIs are available in Noveum platform?'\n",
      "‚úÖ Query processed in 5.00s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 5.00s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:18\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not specify the APIs available in the Noveum platform. For detailed information about the APIs, I recommend checking the official Noveum documentation or the SDK Integration Guide. If you have any other questions about Noveum, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 7 ---\n",
      "\n",
      "üéØ Processing query: 'How does Noveum handle agent tracing?'\n",
      "üß† Routing to RAG system for: 'How does Noveum handle agent tracing?'\n",
      "üîç Found 5 relevant documents for query: 'How does Noveum handle agent tracing?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:23 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 3bbd0b36-c30f-4126-b62a-dd0fae1c701d) - 6 spans\n",
      "2025-10-22 22:27:23 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 3bbd0b36-c30f-4126-b62a-dd0fae1c701d) - 6 spans\n",
      "2025-10-22 22:27:23 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3bbd0b36-c30f-4126-b62a-dd0fae1c701d\n",
      "2025-10-22 22:27:23 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3bbd0b36-c30f-4126-b62a-dd0fae1c701d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'How does Noveum handle agent tracing?'\n",
      "‚úÖ Query processed in 4.48s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 4.48s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:23\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/docs/advanced/multi-agent-tracing\n",
      "   3. https://noveum.ai/en/docs/advanced/multi-agent-tracing\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "Noveum.ai handles agent tracing through its specialized Multi-Agent Tracing capabilities, which are designed to observe complex workflows and inter-agent communications within multi-agent systems. These systems often involve multiple agents that coordinate, communicate, and collaborate to achieve shared goals, presenting unique observability challenges. Noveum.ai provides comprehensive tracing to help users understand and optimize these intricate workflows, ensuring better visibility into agent interactions and performance (Source 2 and Source 3). \n",
      "\n",
      "For more detailed insights or specific use cases, you may want to explore the Noveum documentation further.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 8 ---\n",
      "\n",
      "üéØ Processing query: 'What monitoring capabilities does Noveum provide?'\n",
      "üß† Routing to RAG system for: 'What monitoring capabilities does Noveum provide?'\n",
      "üîç Found 5 relevant documents for query: 'What monitoring capabilities does Noveum provide?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:31 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: fb0d31fc-2465-4ecd-973c-4cd443d9befa) - 6 spans\n",
      "2025-10-22 22:27:31 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: fb0d31fc-2465-4ecd-973c-4cd443d9befa) - 6 spans\n",
      "2025-10-22 22:27:31 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace fb0d31fc-2465-4ecd-973c-4cd443d9befa\n",
      "2025-10-22 22:27:31 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace fb0d31fc-2465-4ecd-973c-4cd443d9befa successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What monitoring capabilities does Noveum provide?'\n",
      "‚úÖ Query processed in 6.97s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 6.97s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:31\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en\n",
      "   2. https://noveum.ai/\n",
      "   3. https://noveum.ai\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "Noveum provides comprehensive monitoring capabilities for AI applications, including the ability to monitor, trace, and optimize AI agents across various frameworks such as LangChain, CrewAI, AutoGen, and custom implementations. The platform features a unified dashboard that allows users to monitor everything in their AI ecosystem, capturing every trace and span from simple LLM calls to complex multi-agent interactions. This is facilitated by lightweight SDKs that ensure no detail is missed, enabling users to evaluate and improve their AI agents effectively (Sources 1, 2, 4).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 9 ---\n",
      "\n",
      "üéØ Processing query: 'How do I configure Noveum for my system?'\n",
      "üß† Routing to RAG system for: 'How do I configure Noveum for my system?'\n",
      "üîç Found 5 relevant documents for query: 'How do I configure Noveum for my system?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:37 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 1ae0d6c4-d1fb-4239-b536-3333187d44aa) - 6 spans\n",
      "2025-10-22 22:27:37 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 1ae0d6c4-d1fb-4239-b536-3333187d44aa) - 6 spans\n",
      "2025-10-22 22:27:37 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 1ae0d6c4-d1fb-4239-b536-3333187d44aa\n",
      "2025-10-22 22:27:37 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 1ae0d6c4-d1fb-4239-b536-3333187d44aa successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'How do I configure Noveum for my system?'\n",
      "‚úÖ Query processed in 4.69s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 4.69s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:37\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "To configure Noveum for your system, you can refer to the SDK Integration Guide available in the Noveum documentation. This guide will help you trace your AI applications with minimal code changes. The SDKs provided for Python and TypeScript are designed to facilitate this integration. \n",
      "\n",
      "For detailed steps and specific configurations, please check the relevant sections in the documentation. If you need further assistance, you can also reach out to the Noveum community via Discord or email support at [email protected] (Sources: Source 1, Source 5).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 10 ---\n",
      "\n",
      "üéØ Processing query: 'What are the benefits of using Noveum Trace?'\n",
      "üß† Routing to RAG system for: 'What are the benefits of using Noveum Trace?'\n",
      "üîç Found 5 relevant documents for query: 'What are the benefits of using Noveum Trace?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:46 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 823b7927-10bb-49ef-a94e-1b914c298bfb) - 6 spans\n",
      "2025-10-22 22:27:46 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 823b7927-10bb-49ef-a94e-1b914c298bfb) - 6 spans\n",
      "2025-10-22 22:27:46 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 823b7927-10bb-49ef-a94e-1b914c298bfb\n",
      "2025-10-22 22:27:46 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 823b7927-10bb-49ef-a94e-1b914c298bfb successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What are the benefits of using Noveum Trace?'\n",
      "‚úÖ Query processed in 7.97s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 7.97s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:46\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/docs/platform/dashboard\n",
      "   2. https://noveum.ai/en/docs\n",
      "   3. https://noveum.ai/docs\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "Using Noveum Trace offers several benefits, including:\n",
      "\n",
      "1. **Real-Time Monitoring**: The Noveum platform provides a real-time dashboard for analyzing traces and performance, with live updates as new traces arrive and real-time status monitoring of your trace ingestion pipeline (Source 1).\n",
      "\n",
      "2. **Advanced Analysis**: Users can perform comparative analysis across multiple traces, allowing for performance comparisons and insights into system health through live metrics (Source 1).\n",
      "\n",
      "3. **Cost Analysis and Optimization**: Noveum Trace includes features for cost analysis and optimization recommendations, helping users manage and reduce expenses associated with AI operations (Source 4).\n",
      "\n",
      "4. **Collaboration Features**: The platform supports team collaboration by enabling shared insights and alerts, facilitating better communication and teamwork (Source 4).\n",
      "\n",
      "5. **Comprehensive Tracing**: With the Python and TypeScript SDKs, Noveum Trace offers decorator-based tracing for LLM calls, agents, and RAG pipelines, along with automatic instrumentation for popular AI frameworks (Source 2).\n",
      "\n",
      "6. **Detailed Metrics**: It provides detailed metrics on model calls, token usage, prompt engineering effectiveness, and response quality, which are crucial for optimizing AI applications (Source 4).\n",
      "\n",
      "Overall, Noveum Trace enhances the ability to monitor, analyze, and optimize AI applications effectively.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo Query 11 ---\n",
      "\n",
      "üéØ Processing query: 'What are the latest AI news today?'\n",
      "üåê Routing to Web Search for: 'What are the latest AI news today?'\n",
      "üîç Found 1 web search results for: 'What are the latest AI news today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:50 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: e4f3cc20-c137-4905-80fe-2d29b03c2231) - 6 spans\n",
      "2025-10-22 22:27:50 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: e4f3cc20-c137-4905-80fe-2d29b03c2231) - 6 spans\n",
      "2025-10-22 22:27:50 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace e4f3cc20-c137-4905-80fe-2d29b03c2231\n",
      "2025-10-22 22:27:50 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace e4f3cc20-c137-4905-80fe-2d29b03c2231 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 3.48s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 3.48s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:50\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+AI+news+today?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information about the latest AI news today. They primarily focus on general news coverage from India and around the world, including politics, business, and entertainment, but do not mention any recent developments or updates in artificial intelligence.\n",
      "\n",
      "For the latest AI news, I recommend checking dedicated technology news websites or platforms that specialize in AI developments, as they would provide more relevant and up-to-date information.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 12 ---\n",
      "\n",
      "üéØ Processing query: 'What's the weather like today?'\n",
      "üåê Routing to Web Search for: 'What's the weather like today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 web search results for: 'What's the weather like today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:27:56 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: b1b13e60-5b32-44a0-9769-197a944989d0) - 6 spans\n",
      "2025-10-22 22:27:56 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: b1b13e60-5b32-44a0-9769-197a944989d0) - 6 spans\n",
      "2025-10-22 22:27:56 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b1b13e60-5b32-44a0-9769-197a944989d0\n",
      "2025-10-22 22:27:56 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b1b13e60-5b32-44a0-9769-197a944989d0 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 4.93s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 4.93s\n",
      "üìÖ Timestamp: 2025-10-22 22:27:56\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+the+weather+like+today?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The web search results do not provide specific information about today's weather. To find out the current weather conditions, I recommend checking a reliable weather website or app for detailed updates, including temperature, wind, and precipitation forecasts.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo Query 13 ---\n",
      "\n",
      "üéØ Processing query: 'Tell me about recent developments in machine learning'\n",
      "üåê Routing to Web Search for: 'Tell me about recent developments in machine learning'\n",
      "üîç Found 1 web search results for: 'Tell me about recent developments in machine learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:03 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: c5a64d08-d00f-46cf-ab3c-d8d473c10eca) - 6 spans\n",
      "2025-10-22 22:28:03 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: c5a64d08-d00f-46cf-ab3c-d8d473c10eca) - 6 spans\n",
      "2025-10-22 22:28:03 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace c5a64d08-d00f-46cf-ab3c-d8d473c10eca\n",
      "2025-10-22 22:28:03 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace c5a64d08-d00f-46cf-ab3c-d8d473c10eca successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 5.97s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 5.97s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:03\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=Tell+me+about+recent+developments+in+machine+learning\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The web search results did not provide specific information about recent developments in machine learning. Therefore, I cannot summarize any recent advancements based on the provided data.\n",
      "\n",
      "However, if you're interested in general trends in machine learning, I can mention that recent developments often include advancements in deep learning architectures, improvements in natural language processing (NLP) models, and increased applications of machine learning in various industries such as healthcare, finance, and autonomous systems. For the latest updates, I recommend checking reputable tech news sources or academic journals focused on artificial intelligence and machine learning.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 14 ---\n",
      "\n",
      "üéØ Processing query: 'What are the current trends in observability tools?'\n",
      "üß† Routing to RAG system for: 'What are the current trends in observability tools?'\n",
      "üîç Found 5 relevant documents for query: 'What are the current trends in observability tools?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:10 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 45efae74-ee25-4004-a509-6e0ff628a0cd) - 6 spans\n",
      "2025-10-22 22:28:10 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 45efae74-ee25-4004-a509-6e0ff628a0cd) - 6 spans\n",
      "2025-10-22 22:28:10 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 45efae74-ee25-4004-a509-6e0ff628a0cd\n",
      "2025-10-22 22:28:10 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 45efae74-ee25-4004-a509-6e0ff628a0cd successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What are the current trends in observability tools?'\n",
      "‚úÖ Query processed in 5.15s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 5.15s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:10\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/blog/from-logs-to-intelligent-choices-inside-noveum-ais-evaluation-process\n",
      "   2. https://noveum.ai/docs/getting-started/tracing-concepts\n",
      "   3. https://noveum.ai/en/docs/getting-started/tracing-concepts\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not explicitly outline current trends in observability tools. However, it highlights the unique challenges faced by AI applications that traditional monitoring tools cannot adequately address. For instance, Noveum.ai emphasizes the importance of comprehensive tracing and collecting the right data to understand, debug, and optimize AI systems, rather than just gathering all possible data (Source 2 and Source 4).\n",
      "\n",
      "Additionally, the context mentions advanced practices such as comprehensive pipeline tracing, quality monitoring, and A/B testing for RAG components, which suggest a trend towards more specialized and tailored observability solutions for AI applications (Source 5).\n",
      "\n",
      "If you have specific questions about Noveum.ai's observability platform or its features, feel free to ask!\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo Query 15 ---\n",
      "\n",
      "üéØ Processing query: 'What happened in tech news this week?'\n",
      "üåê Routing to Web Search for: 'What happened in tech news this week?'\n",
      "üîç Found 1 web search results for: 'What happened in tech news this week?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:14 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: e30e9ba6-ffd1-4eb9-b7ae-6d19e04343d6) - 6 spans\n",
      "2025-10-22 22:28:14 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: e30e9ba6-ffd1-4eb9-b7ae-6d19e04343d6) - 6 spans\n",
      "2025-10-22 22:28:14 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace e30e9ba6-ffd1-4eb9-b7ae-6d19e04343d6\n",
      "2025-10-22 22:28:14 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace e30e9ba6-ffd1-4eb9-b7ae-6d19e04343d6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 3.22s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 3.22s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:14\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+happened+in+tech+news+this+week?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The web search results do not provide specific information about recent events in tech news for this week. They primarily discuss the grammatical usage of the word \"happened\" and its variations, such as \"what happened\" and \"what's happened.\" \n",
      "\n",
      "To find out what happened in tech news this week, I recommend checking reliable tech news websites or platforms that aggregate current events in technology. If you have specific topics or companies in mind, I can help guide you on where to look for that information.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 16 ---\n",
      "\n",
      "üéØ Processing query: 'What are the latest updates in Python programming?'\n",
      "üåê Routing to Web Search for: 'What are the latest updates in Python programming?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 web search results for: 'What are the latest updates in Python programming?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:18 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 51f4534f-23e4-4be7-8d6e-e93391d6e0e2) - 6 spans\n",
      "2025-10-22 22:28:18 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 51f4534f-23e4-4be7-8d6e-e93391d6e0e2) - 6 spans\n",
      "2025-10-22 22:28:18 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 51f4534f-23e4-4be7-8d6e-e93391d6e0e2\n",
      "2025-10-22 22:28:18 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 51f4534f-23e4-4be7-8d6e-e93391d6e0e2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 3.62s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 3.62s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:18\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+updates+in+Python+programming?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information about the latest updates in Python programming. They primarily focus on general news coverage and updates from India and around the world, without addressing programming or Python specifically.\n",
      "\n",
      "For the latest updates in Python programming, I recommend checking official sources such as the Python Software Foundation's website or popular programming news platforms like Real Python or Python Weekly. These sources typically provide information on new releases, features, and enhancements in the Python language.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 17 ---\n",
      "\n",
      "üéØ Processing query: 'What's the current status of cryptocurrency markets?'\n",
      "üåê Routing to Web Search for: 'What's the current status of cryptocurrency markets?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 web search results for: 'What's the current status of cryptocurrency markets?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:25 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 3f7b6a62-8888-4a5d-b12c-37a3829aea49) - 6 spans\n",
      "2025-10-22 22:28:25 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 3f7b6a62-8888-4a5d-b12c-37a3829aea49) - 6 spans\n",
      "2025-10-22 22:28:25 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3f7b6a62-8888-4a5d-b12c-37a3829aea49\n",
      "2025-10-22 22:28:25 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3f7b6a62-8888-4a5d-b12c-37a3829aea49 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 5.65s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 5.65s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:25\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+the+current+status+of+cryptocurrency+markets?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information regarding the current status of cryptocurrency markets. To get the latest updates on cryptocurrency prices, trends, and market analysis, I recommend checking financial news websites, cryptocurrency exchanges, or market tracking platforms like CoinMarketCap or CoinGecko. If you have any other questions or need further assistance, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 18 ---\n",
      "\n",
      "üéØ Processing query: 'What are the newest features in cloud computing?'\n",
      "üß† Routing to RAG system for: 'What are the newest features in cloud computing?'\n",
      "üîç Found 5 relevant documents for query: 'What are the newest features in cloud computing?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:31 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 343764b8-7ac9-4549-93cf-8abc11ceba6f) - 6 spans\n",
      "2025-10-22 22:28:31 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 343764b8-7ac9-4549-93cf-8abc11ceba6f) - 6 spans\n",
      "2025-10-22 22:28:31 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 343764b8-7ac9-4549-93cf-8abc11ceba6f\n",
      "2025-10-22 22:28:31 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 343764b8-7ac9-4549-93cf-8abc11ceba6f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 5 relevant documents for query: 'What are the newest features in cloud computing?'\n",
      "‚úÖ Query processed in 5.25s using RAG\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: RAG\n",
      "‚è±Ô∏è  Processing Time: 5.25s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:31\n",
      "üìö Sources (5):\n",
      "   1. https://noveum.ai/en/changelog\n",
      "   2. https://noveum.ai/en/changelog\n",
      "   3. https://noveum.ai/docs/platform/dashboard\n",
      "   ... and 2 more\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not specifically mention any new features in cloud computing as a general topic. However, it does highlight several recent enhancements related to the Noveum.ai platform, which may involve cloud computing aspects. These include:\n",
      "\n",
      "1. **Enhanced Dashboard Analytics**: Real-time request tracking, latency monitoring, and cost analysis (Source 1).\n",
      "2. **Improved Logs Interface**: Better search functionality and enhanced debugging capabilities (Source 1).\n",
      "3. **Advanced Metrics Collection**: A comprehensive telemetry system with custom metrics (Source 1).\n",
      "4. **Major Platform Evolution**: The launch of the NovaEval Framework for AI model evaluation, which includes production-grade deployment on Docker and Kubernetes (Source 4).\n",
      "\n",
      "If you have specific questions about Noveum.ai or its features, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 19 ---\n",
      "\n",
      "üéØ Processing query: 'What's happening in the software development world today?'\n",
      "üåê Routing to Web Search for: 'What's happening in the software development world today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 1 web search results for: 'What's happening in the software development world today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:41 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: ec7c6cae-9bbd-47f4-a8ae-2d6d9b5011ba) - 6 spans\n",
      "2025-10-22 22:28:41 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: ec7c6cae-9bbd-47f4-a8ae-2d6d9b5011ba) - 6 spans\n",
      "2025-10-22 22:28:41 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ec7c6cae-9bbd-47f4-a8ae-2d6d9b5011ba\n",
      "2025-10-22 22:28:41 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ec7c6cae-9bbd-47f4-a8ae-2d6d9b5011ba successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 8.28s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 8.28s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:41\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+happening+in+the+software+development+world+today?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The web search did not yield any specific results regarding current events in the software development world. Therefore, I cannot provide detailed information on the latest trends, technologies, or news in this field.\n",
      "\n",
      "However, generally speaking, the software development landscape is often influenced by several ongoing trends, such as:\n",
      "\n",
      "1. **Increased Adoption of AI and Machine Learning**: Many companies are integrating AI into their software solutions to enhance functionality and user experience.\n",
      "\n",
      "2. **Remote Work and Collaboration Tools**: The shift to remote work has led to a surge in the development and use of collaboration tools and platforms.\n",
      "\n",
      "3. **DevOps and Continuous Integration/Continuous Deployment (CI/CD)**: There is a growing emphasis on DevOps practices to improve collaboration between development and operations teams, leading to faster and more reliable software delivery.\n",
      "\n",
      "4. **Focus on Cybersecurity**: With the rise in cyber threats, there is an increasing focus on building secure software and implementing robust security practices throughout the development lifecycle.\n",
      "\n",
      "5. **Low-Code and No-Code Development**: These platforms are gaining popularity as they allow users to create applications with minimal coding, making software development more accessible.\n",
      "\n",
      "For the most accurate and up-to-date information, I recommend checking reputable tech news websites or software development blogs.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/work/NovaEval/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo Query 20 ---\n",
      "\n",
      "üéØ Processing query: 'What are the latest breakthroughs in artificial intelligence?'\n",
      "üåê Routing to Web Search for: 'What are the latest breakthroughs in artificial intelligence?'\n",
      "üîç Found 1 web search results for: 'What are the latest breakthroughs in artificial intelligence?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:28:44 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 6fe93abf-1413-49e8-8464-58558e25ab7b) - 6 spans\n",
      "2025-10-22 22:28:44 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 6fe93abf-1413-49e8-8464-58558e25ab7b) - 6 spans\n",
      "2025-10-22 22:28:44 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 6fe93abf-1413-49e8-8464-58558e25ab7b\n",
      "2025-10-22 22:28:44 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 6fe93abf-1413-49e8-8464-58558e25ab7b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Query processed in 2.68s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ü§ñ NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "üìä Mode: Web Search\n",
      "‚è±Ô∏è  Processing Time: 2.68s\n",
      "üìÖ Timestamp: 2025-10-22 22:28:44\n",
      "üìö Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+breakthroughs+in+artificial+intelligence?\n",
      "\n",
      "üí¨ Answer:\n",
      "----------------------------------------\n",
      "The web search did not yield specific results regarding the latest breakthroughs in artificial intelligence. However, I can provide a general overview based on knowledge up to October 2023.\n",
      "\n",
      "Recent breakthroughs in artificial intelligence include advancements in natural language processing (NLP), particularly with models like GPT-4, which have improved understanding and generation of human-like text. Additionally, there have been significant developments in computer vision, enabling AI systems to better interpret and analyze visual data.\n",
      "\n",
      "Another notable area of progress is in reinforcement learning, where AI systems are increasingly capable of learning complex tasks through trial and error, leading to applications in robotics and game playing. Furthermore, AI ethics and safety have gained attention, with researchers focusing on creating more transparent and fair AI systems.\n",
      "\n",
      "For the most current and specific breakthroughs, I recommend checking reputable technology news sources or academic journals that focus on AI research.\n",
      "================================================================================\n",
      "\n",
      "üéâ Demo completed! Check Noveum Trace dashboard for detailed observability data.\n",
      "üí° You can now use noveum_agent.process_query('your question') for your own queries!\n"
     ]
    }
   ],
   "source": [
    "demo_noveum_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b29876",
   "metadata": {},
   "source": [
    "## Downloading the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1f2b8",
   "metadata": {},
   "source": [
    "## üìã Complete End-to-End Workflow Overview\n",
    "\n",
    "This notebook demonstrates a **complete end-to-end workflow** for AI agent evaluation:\n",
    "\n",
    "### üîÑ Workflow Steps:\n",
    "\n",
    "1. **ü§ñ Agent Creation & Demo** - Build and test the Noveum AI agent with RAG + Web Search\n",
    "2. **üìä Trace Collection** - Download traces from Noveum platform \n",
    "3. **üîÑ Data Processing** - Combine, filter, and map trace data\n",
    "4. **üìà Dataset Management** - Create dataset and upload items to Noveum\n",
    "5. **üìä Score Upload** - Upload all evaluation metrics to the platform\n",
    "\n",
    "### üéØ What You'll Learn:\n",
    "\n",
    "- How to build a sophisticated AI agent with dual knowledge sources\n",
    "- Complete observability and tracing implementation\n",
    "- End-to-end evaluation pipeline from traces to scores\n",
    "- Noveum platform integration for dataset and score management\n",
    "\n",
    "### üìä Expected Results:\n",
    "\n",
    "- **50 traces** with **279 spans** collected\n",
    "- **12 conversation items** uploaded to dataset\n",
    "- **5 evaluation metrics** successfully uploaded\n",
    "- Complete observability pipeline operational\n",
    "\n",
    "Let's start! üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f918640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 50 traces for project: noveum-ai-agent-rag-websearch\n",
      "Cleaning existing traces directory: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces\n",
      "Created traces directory: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces\n",
      "Will fetch in 1 batch(es) of up to 100 traces each\n",
      "\n",
      "--- Batch 1/1 ---\n",
      "Fetching traces: size=50, from=0\n",
      "Successfully fetched 50 traces\n",
      "Saved batch 1 to: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/traces_batch_001.json\n",
      "Batch 1 complete: 50 traces\n",
      "Total fetched so far: 50/50\n",
      "Reached target of 50 traces\n",
      "\n",
      "=== Summary ===\n",
      "Total traces fetched: 50\n",
      "Batches created: 1\n",
      "Traces directory: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces\n",
      "Created files: traces_batch_001.json\n"
     ]
    }
   ],
   "source": [
    "!python noveum_customer_support_bt/traces/fetch_traces_api.py 50\n",
    "\n",
    "#. This script fetches traces for our project and saves them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641efa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing traces from: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces\n",
      "Found 1 trace files: ['traces_batch_001.json']\n",
      "Processing traces_batch_001.json...\n",
      "Combined 290 spans total\n",
      "Saved combined spans to: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/dataset.json\n",
      "\n",
      "Sample of first span keys: ['span_id', 'trace_id', 'parent_span_id', 'name', 'start_time', 'end_time', 'duration_ms', 'status', 'status_message', 'attributes', 'events', 'links', 'trace_trace_id', 'trace_name', 'project', 'environment', 'trace_status', 'trace_status_message', 'trace_start_time', 'trace_end_time', 'trace_duration_ms', 'span_count', 'error_count', 'sdk', 'trace_attributes', 'metadata', 'created_at', 'updated_at']\n",
      "Total spans: 290\n",
      "\n",
      "Span types distribution:\n",
      "  agent.llm-rag: 26\n",
      "  agent.llm_model_execution: 48\n",
      "  agent.query_routing: 48\n",
      "  agent.rag_evaluation_metrics: 26\n",
      "  agent.routing_evaluation_metrics: 48\n",
      "  agent.web_search_evaluation_metrics: 22\n",
      "  agent.web_search_generation: 22\n",
      "  system_initialization: 2\n",
      "  tool-orchestator: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!python NovaEval/noveum_customer_support_bt/traces/combine_spans_api_compat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bddd552",
   "metadata": {},
   "source": [
    "## Data Filteration and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3dfb8588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./traces/traces/dataset.json...\n",
      "Original dataset: 290 records\n",
      "Filtering spans...\n",
      "After filtering: 290 records\n",
      "Converting tool output format...\n",
      "Writing ./traces/traces/dataset_filtered.json...\n",
      "Filtering complete! Output: ./traces/traces/dataset_filtered.json\n",
      "\n",
      "Success! Created ./traces/traces/dataset_filtered.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_filter.py ./traces/traces/dataset.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7484b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File ./traces/dataset_filtered.json not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_map.py ./traces/dataset_filtered.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd53eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered.json...\n",
      "Input dataset: 290 records\n",
      "Mapping spans...\n",
      "Writing /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered_mapped.json...\n",
      "Mapping complete! Output: /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered_mapped.json\n",
      "\n",
      "Success! Created /Users/mramanindia/work/NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered_mapped.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    }
   ],
   "source": [
    "!python preprocess_map.py NovaEval/noveum_customer_support_bt/traces/traces/dataset_filtered.json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008fd0e1",
   "metadata": {},
   "source": [
    "## Running eval on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "430d60b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:source:1: no such file or directory: .venv/bin/activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:cd:1: no such file or directory: noveum_customer_support_bt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=52016) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  WARNING: Please update the dataset slug in your .env file after creating the dataset!\n",
      "   The API will return a slug that you should set as NOVEUM_DATASET_SLUG in your .env file.\n",
      "\n",
      "Creating dataset at: https://noveum.ai/api/v1/datasets\n",
      "Organization: magic-api\n",
      "Dataset name: customersupportagentdemo_new\n",
      "Dataset type: agent\n",
      "Description: Customer Support Agent Evaluation Dataset\n",
      "Visibility: org\n",
      "Environment: \n",
      "Error creating dataset: 409 Client Error: Conflict for url: https://noveum.ai/api/v1/datasets\n",
      "Response status: 409\n",
      "Response text: DATASET_SLUG_EXISTS\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup\n",
    "!cd /Users/mramanindia/work/NovaEval\n",
    "!source .venv/bin/activate\n",
    "!cd noveum_customer_support_bt\n",
    "\n",
    "# 2. Create Dataset\n",
    "!python create_dataset.py --dataset-type agent --description \"Customer Support Agent Evaluation Dataset\" --pretty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7feb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset version at: https://noveum.ai/api/v1/datasets/customersupportagentdemo-new/versions?organizationSlug=magic-api\n",
      "Organization: magic-api\n",
      "Dataset: customersupportagentdemo-new\n",
      "Version: 0.0.2\n",
      "Successfully created dataset version\n",
      "Response status: 201\n",
      "\n",
      "Response saved to: dataset_version_response.json\n",
      "\n",
      "Response data:\n",
      "{\n",
      "  \"success\": true,\n",
      "  \"version\": \"0.0.2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 3. Create Version\n",
    "!python create_dataset_version.py --pretty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d36f1da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:42 - noveum_trace.transport.batch_processor - INFO - üîÑ Batch processor background thread started (batch_size=100, timeout=5.0s)\n",
      "2025-10-22 22:59:42 - noveum_trace.transport.batch_processor - INFO - Batch processor started with batch_size=100\n",
      "2025-10-22 22:59:42 - noveum_trace.transport.http_transport - INFO - HTTP transport initialized for endpoint: https://api.noveum.ai/api\n",
      "2025-10-22 22:59:42 - noveum_trace.core.client - INFO - Noveum Trace client initialized\n",
      "2025-10-22 22:59:42,946 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "‚úÖ list_dataset_files function defined!\n",
      "‚úÖ load_and_analyze_dataset function defined!\n",
      "‚úÖ parse_tools_from_prompt function defined!\n",
      "‚úÖ parse_params function defined!\n",
      "‚úÖ identify_span_type function defined!\n",
      "‚úÖ map_span_to_agent_data function defined!\n",
      "‚úÖ convert_spans_to_agent_dataset function defined!\n",
      "‚úÖ analyze_dataset_statistics function defined!\n",
      "‚úÖ setup_gemini_model function defined!\n",
      "‚úÖ setup_agent_evaluator function defined!\n",
      "‚úÖ run_evaluation function defined!\n",
      "‚úÖ analyze_agent_behavior_patterns function defined!\n",
      "‚úÖ export_processed_dataset function defined!\n",
      "‚úÖ setup_logging function defined!\n",
      "‚úÖ validate_environment function defined!\n",
      "‚úÖ print_demo_summary function defined!\n",
      "‚úÖ run_complete_agent_evaluation function defined!\n",
      "Processing agent.llm_model_execution_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.llm_model_execution_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 20 spans from split_datasets/agent.llm_model_execution_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.llm_model_execution: 20\n",
      "‚úÖ Dataset loaded: 20 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "agent_task not found\n",
      "agent_response is not available  ce8556f4-bbeb-46fc-8bfd-dfaedb61cb70\n",
      "agent_task not found\n",
      "agent_response is not available  cc3073ec-c970-4821-8335-8d0fc8f37930\n",
      "agent_task not found\n",
      "agent_response is not available  c24fae6d-6314-4342-8214-7e9905ae83db\n",
      "agent_task not found\n",
      "agent_response is not available  93879d8f-77c7-4fd4-881b-be500e2dcbde\n",
      "agent_task not found\n",
      "agent_response is not available  f92643c0-44a3-4fae-9d29-45321342d12f\n",
      "agent_task not found\n",
      "agent_response is not available  44f379aa-10fe-4a51-847c-5288444d7843\n",
      "agent_task not found\n",
      "agent_response is not available  e8e79f2a-2ed0-4981-943c-adcf6f7d2b15\n",
      "agent_task not found\n",
      "agent_response is not available  e6d0eb41-5f64-44c5-8a42-a80c336de03e\n",
      "agent_task not found\n",
      "agent_response is not available  c545cb62-5a51-4f2e-b020-b3f1d1dfe217\n",
      "agent_task not found\n",
      "agent_response is not available  c2f21e4d-a5e6-4134-aeaf-96e2f566cf96\n",
      "agent_task not found\n",
      "agent_response is not available  39d99d2b-518f-439c-8758-7a01b970fd9e\n",
      "agent_task not found\n",
      "agent_response is not available  9e5ade74-3815-4dad-8abe-d4281d7e62da\n",
      "agent_task not found\n",
      "agent_response is not available  4f38a85b-0721-47a5-8a51-d0808e460f96\n",
      "agent_task not found\n",
      "agent_response is not available  f4c03a8d-b90d-4c1a-a259-826d09e3e57a\n",
      "agent_task not found\n",
      "agent_response is not available  48fb40ba-a39f-4e13-9d94-18794c7e5e2b\n",
      "agent_task not found\n",
      "agent_response is not available  d4d544a0-f052-4889-82eb-4346f2e447a7\n",
      "agent_task not found\n",
      "agent_response is not available  304f9e3d-9063-4661-9777-618efc49f5c1\n",
      "agent_task not found\n",
      "agent_response is not available  e0b4ccfb-18e7-4d71-b2dd-5b807eb27513\n",
      "agent_task not found\n",
      "agent_response is not available  f1425131-f8a2-43f7-aa17-d009f745ed06\n",
      "agent_task not found\n",
      "agent_response is not available  f41e836c-1a82-46e0-9d51-011713874e94\n",
      "\n",
      "‚úÖ Successfully converted 20 spans to AgentData\n",
      "üìä AgentDataset created with 20 records\n",
      "‚úÖ AgentDataset created: 20 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 20}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 0 sample records...\n",
      "2025-10-22 22:59:42 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:43 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 22:59:43 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "‚ùå Results file not found\n",
      "‚ùå Evaluation failed\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.llm_model_execution_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.llm_model_execution_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.llm_model_execution_dataset.json\n",
      "  - Spans loaded: 20\n",
      "  - Dataset size: 20\n",
      "  - Evaluation completed: False\n",
      "  - Export successful: True\n",
      "  - Errors encountered: 1\n",
      "Completed agent.llm_model_execution_dataset.json\n",
      "\n",
      "Processing agent.query_routing_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.query_routing_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 20 spans from split_datasets/agent.query_routing_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.query_routing: 20\n",
      "‚úÖ Dataset loaded: 20 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "\n",
      "‚úÖ Successfully converted 20 spans to AgentData\n",
      "üìä AgentDataset created with 20 records\n",
      "‚úÖ AgentDataset created: 20 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 20}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "  - other: 20\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 22:59:43 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 20 sample records...\n",
      "2025-10-22 22:59:43 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:43 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:44 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 62c88c1e-760c-437e-a9d7-84a84e258789) - 1 spans\n",
      "2025-10-22 22:59:44 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 62c88c1e-760c-437e-a9d7-84a84e258789) - 1 spans\n",
      "2025-10-22 22:59:44 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 62c88c1e-760c-437e-a9d7-84a84e258789\n",
      "2025-10-22 22:59:44 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 62c88c1e-760c-437e-a9d7-84a84e258789 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:44 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:46 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: cf8d91be-c525-4e98-b2ab-b6dead66b872) - 1 spans\n",
      "2025-10-22 22:59:46 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: cf8d91be-c525-4e98-b2ab-b6dead66b872) - 1 spans\n",
      "2025-10-22 22:59:46 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace cf8d91be-c525-4e98-b2ab-b6dead66b872\n",
      "2025-10-22 22:59:46 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace cf8d91be-c525-4e98-b2ab-b6dead66b872 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:46 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:47 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 087e523c-cf91-49e6-8a3f-63d7e6ea817a) - 1 spans\n",
      "2025-10-22 22:59:47 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 087e523c-cf91-49e6-8a3f-63d7e6ea817a) - 1 spans\n",
      "2025-10-22 22:59:47 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 087e523c-cf91-49e6-8a3f-63d7e6ea817a\n",
      "2025-10-22 22:59:47 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 087e523c-cf91-49e6-8a3f-63d7e6ea817a successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:47 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 1 samples\n",
      "2025-10-22 22:59:47 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 1it [00:04,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:47 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:48 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.1s >= 5.0s)\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f5d0b1e3-779c-4804-8cb6-c37743638b63) - 1 spans\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f5d0b1e3-779c-4804-8cb6-c37743638b63) - 1 spans\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f5d0b1e3-779c-4804-8cb6-c37743638b63\n",
      "2025-10-22 22:59:48 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f5d0b1e3-779c-4804-8cb6-c37743638b63 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:48 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:49 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:49 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 22:59:49 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 22:59:50 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9c192a1f-994d-4dba-a03d-79b70c731c6f) - 1 spans\n",
      "2025-10-22 22:59:50 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9c192a1f-994d-4dba-a03d-79b70c731c6f) - 1 spans\n",
      "2025-10-22 22:59:50 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9c192a1f-994d-4dba-a03d-79b70c731c6f\n",
      "2025-10-22 22:59:50 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9c192a1f-994d-4dba-a03d-79b70c731c6f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:50 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:52 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4d902ae0-f8b9-4d47-b1d8-cfcc59d71ef9) - 1 spans\n",
      "2025-10-22 22:59:52 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4d902ae0-f8b9-4d47-b1d8-cfcc59d71ef9) - 1 spans\n",
      "2025-10-22 22:59:52 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4d902ae0-f8b9-4d47-b1d8-cfcc59d71ef9\n",
      "2025-10-22 22:59:52 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4d902ae0-f8b9-4d47-b1d8-cfcc59d71ef9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:52 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 2 samples\n",
      "2025-10-22 22:59:52 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 2it [00:09,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:52 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:53 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 22:59:53 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 22:59:53 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:53 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:53 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 22:59:53 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 22:59:55 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: d6f4e5b6-7b0c-4cc5-a6ab-0d7f6ee82997) - 1 spans\n",
      "2025-10-22 22:59:55 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: d6f4e5b6-7b0c-4cc5-a6ab-0d7f6ee82997) - 1 spans\n",
      "2025-10-22 22:59:55 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace d6f4e5b6-7b0c-4cc5-a6ab-0d7f6ee82997\n",
      "2025-10-22 22:59:55 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace d6f4e5b6-7b0c-4cc5-a6ab-0d7f6ee82997 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:55 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:58 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 1791b898-a25e-406e-9946-13403e6ea2a5) - 1 spans\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 1791b898-a25e-406e-9946-13403e6ea2a5) - 1 spans\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 1791b898-a25e-406e-9946-13403e6ea2a5\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 1791b898-a25e-406e-9946-13403e6ea2a5 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:58 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:58 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.1s >= 5.0s)\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 2 traces via send_callback\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 2 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 2 traces\n",
      "2025-10-22 22:59:58 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 2 traces via callback\n",
      "2025-10-22 22:59:59 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 93cd53ab-4aee-474b-80a1-b2e056179d42) - 1 spans\n",
      "2025-10-22 22:59:59 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 93cd53ab-4aee-474b-80a1-b2e056179d42) - 1 spans\n",
      "2025-10-22 22:59:59 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 93cd53ab-4aee-474b-80a1-b2e056179d42\n",
      "2025-10-22 22:59:59 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 93cd53ab-4aee-474b-80a1-b2e056179d42 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:59 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 3 samples\n",
      "2025-10-22 22:59:59 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 3it [00:16,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 22:59:59 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:01 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: bdd95aaf-99e9-4926-ae57-f3846a34dfe2) - 1 spans\n",
      "2025-10-22 23:00:01 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: bdd95aaf-99e9-4926-ae57-f3846a34dfe2) - 1 spans\n",
      "2025-10-22 23:00:01 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace bdd95aaf-99e9-4926-ae57-f3846a34dfe2\n",
      "2025-10-22 23:00:01 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace bdd95aaf-99e9-4926-ae57-f3846a34dfe2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:01 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:03 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.2s >= 5.0s)\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 2 traces via send_callback\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 2 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 14a0cc75-5abe-4057-8b8e-474c095520bd) - 1 spans\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 14a0cc75-5abe-4057-8b8e-474c095520bd) - 1 spans\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 14a0cc75-5abe-4057-8b8e-474c095520bd\n",
      "2025-10-22 23:00:03 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 14a0cc75-5abe-4057-8b8e-474c095520bd successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:03 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:04 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:04 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 2 traces\n",
      "2025-10-22 23:00:04 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 2 traces via callback\n",
      "2025-10-22 23:00:05 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3cdcd252-7600-4247-8557-f67f1a66beae) - 1 spans\n",
      "2025-10-22 23:00:05 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3cdcd252-7600-4247-8557-f67f1a66beae) - 1 spans\n",
      "2025-10-22 23:00:05 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3cdcd252-7600-4247-8557-f67f1a66beae\n",
      "2025-10-22 23:00:05 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3cdcd252-7600-4247-8557-f67f1a66beae successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:05 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 4 samples\n",
      "2025-10-22 23:00:05 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 4it [00:21,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:05 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:06 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 57555bab-ecd2-4006-a353-7d27bef7df0b) - 1 spans\n",
      "2025-10-22 23:00:06 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 57555bab-ecd2-4006-a353-7d27bef7df0b) - 1 spans\n",
      "2025-10-22 23:00:06 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 57555bab-ecd2-4006-a353-7d27bef7df0b\n",
      "2025-10-22 23:00:06 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 57555bab-ecd2-4006-a353-7d27bef7df0b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:06 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:07 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 6b673f69-57ca-406b-8795-a74e96080081) - 1 spans\n",
      "2025-10-22 23:00:07 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 6b673f69-57ca-406b-8795-a74e96080081) - 1 spans\n",
      "2025-10-22 23:00:07 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 6b673f69-57ca-406b-8795-a74e96080081\n",
      "2025-10-22 23:00:07 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 6b673f69-57ca-406b-8795-a74e96080081 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:07 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:08 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.0s >= 5.0s)\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 47efa03a-15f4-4818-b062-db186df9847c) - 1 spans\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 47efa03a-15f4-4818-b062-db186df9847c) - 1 spans\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 47efa03a-15f4-4818-b062-db186df9847c\n",
      "2025-10-22 23:00:08 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 47efa03a-15f4-4818-b062-db186df9847c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:08 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 5 samples\n",
      "2025-10-22 23:00:08 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 5it [00:25,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:08 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:09 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:09 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:09 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:10 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a1e9ac36-8c30-4784-9f33-93ed2497ee97) - 1 spans\n",
      "2025-10-22 23:00:10 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a1e9ac36-8c30-4784-9f33-93ed2497ee97) - 1 spans\n",
      "2025-10-22 23:00:10 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a1e9ac36-8c30-4784-9f33-93ed2497ee97\n",
      "2025-10-22 23:00:10 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a1e9ac36-8c30-4784-9f33-93ed2497ee97 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:10 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:11 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 62a690ab-2806-4619-92df-eec54d03b859) - 1 spans\n",
      "2025-10-22 23:00:11 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 62a690ab-2806-4619-92df-eec54d03b859) - 1 spans\n",
      "2025-10-22 23:00:11 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 62a690ab-2806-4619-92df-eec54d03b859\n",
      "2025-10-22 23:00:11 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 62a690ab-2806-4619-92df-eec54d03b859 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:11 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:12 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 239c63de-f804-41f5-98af-463f42dd4089) - 1 spans\n",
      "2025-10-22 23:00:12 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 239c63de-f804-41f5-98af-463f42dd4089) - 1 spans\n",
      "2025-10-22 23:00:12 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 239c63de-f804-41f5-98af-463f42dd4089\n",
      "2025-10-22 23:00:12 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 239c63de-f804-41f5-98af-463f42dd4089 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:12 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 6 samples\n",
      "2025-10-22 23:00:12 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 6it [00:29,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:12 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:13 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4b6d4dfb-7c55-4296-9ad6-0490385e162d) - 1 spans\n",
      "2025-10-22 23:00:13 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4b6d4dfb-7c55-4296-9ad6-0490385e162d) - 1 spans\n",
      "2025-10-22 23:00:13 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4b6d4dfb-7c55-4296-9ad6-0490385e162d\n",
      "2025-10-22 23:00:13 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4b6d4dfb-7c55-4296-9ad6-0490385e162d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:13 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:14 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 5 traces via send_callback\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 5 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 5 traces\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 5 traces via callback\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: b6ec3f3c-f9ec-4714-b99e-034d4fa7655b) - 1 spans\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: b6ec3f3c-f9ec-4714-b99e-034d4fa7655b) - 1 spans\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b6ec3f3c-f9ec-4714-b99e-034d4fa7655b\n",
      "2025-10-22 23:00:14 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b6ec3f3c-f9ec-4714-b99e-034d4fa7655b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:14 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:16 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ed49c38e-e2d4-4cb2-8049-ec501c7407d7) - 1 spans\n",
      "2025-10-22 23:00:16 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ed49c38e-e2d4-4cb2-8049-ec501c7407d7) - 1 spans\n",
      "2025-10-22 23:00:16 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ed49c38e-e2d4-4cb2-8049-ec501c7407d7\n",
      "2025-10-22 23:00:16 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ed49c38e-e2d4-4cb2-8049-ec501c7407d7 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:16 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 7 samples\n",
      "2025-10-22 23:00:16 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 7it [00:33,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:16 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:17 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 1df4cc5a-2027-401e-8a59-c0bc394f0463) - 1 spans\n",
      "2025-10-22 23:00:17 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 1df4cc5a-2027-401e-8a59-c0bc394f0463) - 1 spans\n",
      "2025-10-22 23:00:17 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 1df4cc5a-2027-401e-8a59-c0bc394f0463\n",
      "2025-10-22 23:00:17 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 1df4cc5a-2027-401e-8a59-c0bc394f0463 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:17 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:18 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 75755b07-45c9-4ad8-a59e-f6b04685a2be) - 1 spans\n",
      "2025-10-22 23:00:18 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 75755b07-45c9-4ad8-a59e-f6b04685a2be) - 1 spans\n",
      "2025-10-22 23:00:18 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 75755b07-45c9-4ad8-a59e-f6b04685a2be\n",
      "2025-10-22 23:00:18 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 75755b07-45c9-4ad8-a59e-f6b04685a2be successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:18 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:19 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:00:19 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:19 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:19 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:19 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:19 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:20 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: dea54b30-9b78-45a1-861c-acef72c97a3f) - 1 spans\n",
      "2025-10-22 23:00:20 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: dea54b30-9b78-45a1-861c-acef72c97a3f) - 1 spans\n",
      "2025-10-22 23:00:20 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace dea54b30-9b78-45a1-861c-acef72c97a3f\n",
      "2025-10-22 23:00:20 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace dea54b30-9b78-45a1-861c-acef72c97a3f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:20 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 8 samples\n",
      "2025-10-22 23:00:20 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 8it [00:37,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:20 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:21 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9cb16557-f687-4b6d-aa25-798f27e9615c) - 1 spans\n",
      "2025-10-22 23:00:21 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9cb16557-f687-4b6d-aa25-798f27e9615c) - 1 spans\n",
      "2025-10-22 23:00:21 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9cb16557-f687-4b6d-aa25-798f27e9615c\n",
      "2025-10-22 23:00:21 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9cb16557-f687-4b6d-aa25-798f27e9615c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:21 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:22 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 39999cf9-16cd-4b1f-8167-39953b328da6) - 1 spans\n",
      "2025-10-22 23:00:22 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 39999cf9-16cd-4b1f-8167-39953b328da6) - 1 spans\n",
      "2025-10-22 23:00:22 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 39999cf9-16cd-4b1f-8167-39953b328da6\n",
      "2025-10-22 23:00:22 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 39999cf9-16cd-4b1f-8167-39953b328da6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:22 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:24 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.1s >= 5.0s)\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 0829f590-d837-4dee-9e65-feee419011b2) - 1 spans\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 0829f590-d837-4dee-9e65-feee419011b2) - 1 spans\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 0829f590-d837-4dee-9e65-feee419011b2\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 0829f590-d837-4dee-9e65-feee419011b2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:24 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 9 samples\n",
      "2025-10-22 23:00:24 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 9it [00:41,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:24 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:24 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:00:24 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:00:26 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4e2bb2ea-fcec-476a-8505-3f15ad8243ca) - 1 spans\n",
      "2025-10-22 23:00:26 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4e2bb2ea-fcec-476a-8505-3f15ad8243ca) - 1 spans\n",
      "2025-10-22 23:00:26 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4e2bb2ea-fcec-476a-8505-3f15ad8243ca\n",
      "2025-10-22 23:00:26 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4e2bb2ea-fcec-476a-8505-3f15ad8243ca successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:26 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:28 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a091f50f-c6f6-4e99-a812-c427266b63f3) - 1 spans\n",
      "2025-10-22 23:00:28 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a091f50f-c6f6-4e99-a812-c427266b63f3) - 1 spans\n",
      "2025-10-22 23:00:28 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a091f50f-c6f6-4e99-a812-c427266b63f3\n",
      "2025-10-22 23:00:28 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a091f50f-c6f6-4e99-a812-c427266b63f3 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:28 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:29 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:00:29 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:00:29 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 236d1ec0-daf8-46f7-be50-ea50e4a5e1c6) - 1 spans\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 236d1ec0-daf8-46f7-be50-ea50e4a5e1c6) - 1 spans\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 236d1ec0-daf8-46f7-be50-ea50e4a5e1c6\n",
      "2025-10-22 23:00:30 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 236d1ec0-daf8-46f7-be50-ea50e4a5e1c6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:30 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 10 samples\n",
      "2025-10-22 23:00:30 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 10it [00:47,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:30 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:31 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 609077f6-7021-4b16-83e5-d3ed68573359) - 1 spans\n",
      "2025-10-22 23:00:31 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 609077f6-7021-4b16-83e5-d3ed68573359) - 1 spans\n",
      "2025-10-22 23:00:31 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 609077f6-7021-4b16-83e5-d3ed68573359\n",
      "2025-10-22 23:00:31 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 609077f6-7021-4b16-83e5-d3ed68573359 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:31 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:32 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: c2bcfc15-818d-4d23-91ef-c38392c4ce9a) - 1 spans\n",
      "2025-10-22 23:00:32 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: c2bcfc15-818d-4d23-91ef-c38392c4ce9a) - 1 spans\n",
      "2025-10-22 23:00:32 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace c2bcfc15-818d-4d23-91ef-c38392c4ce9a\n",
      "2025-10-22 23:00:32 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace c2bcfc15-818d-4d23-91ef-c38392c4ce9a successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:32 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:34 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 027b030d-d0d7-49f7-a9e8-8933f7829573) - 1 spans\n",
      "2025-10-22 23:00:34 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 027b030d-d0d7-49f7-a9e8-8933f7829573) - 1 spans\n",
      "2025-10-22 23:00:34 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 027b030d-d0d7-49f7-a9e8-8933f7829573\n",
      "2025-10-22 23:00:34 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 027b030d-d0d7-49f7-a9e8-8933f7829573 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:34 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 11 samples\n",
      "2025-10-22 23:00:34 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 11it [00:51,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:34 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:35 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.2s >= 5.0s)\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3b7a2d72-a669-4745-939e-e3eba5fb166b) - 1 spans\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3b7a2d72-a669-4745-939e-e3eba5fb166b) - 1 spans\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3b7a2d72-a669-4745-939e-e3eba5fb166b\n",
      "2025-10-22 23:00:35 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3b7a2d72-a669-4745-939e-e3eba5fb166b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:35 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:36 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3155450e-76b4-4a55-b15b-5c369a6cea5c) - 1 spans\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3155450e-76b4-4a55-b15b-5c369a6cea5c) - 1 spans\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3155450e-76b4-4a55-b15b-5c369a6cea5c\n",
      "2025-10-22 23:00:36 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3155450e-76b4-4a55-b15b-5c369a6cea5c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:36 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:38 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 21337429-011a-4aba-a4e5-83ac5be321ce) - 1 spans\n",
      "2025-10-22 23:00:38 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 21337429-011a-4aba-a4e5-83ac5be321ce) - 1 spans\n",
      "2025-10-22 23:00:38 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 21337429-011a-4aba-a4e5-83ac5be321ce\n",
      "2025-10-22 23:00:38 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 21337429-011a-4aba-a4e5-83ac5be321ce successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:38 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 12 samples\n",
      "2025-10-22 23:00:38 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 12it [00:55,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:38 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:40 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4ebfd611-8645-4781-a3fa-adc5413e7ef9) - 1 spans\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4ebfd611-8645-4781-a3fa-adc5413e7ef9) - 1 spans\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4ebfd611-8645-4781-a3fa-adc5413e7ef9\n",
      "2025-10-22 23:00:40 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4ebfd611-8645-4781-a3fa-adc5413e7ef9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:40 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:41 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 622d34b2-775e-4533-9b86-f3a269f7a87d) - 1 spans\n",
      "2025-10-22 23:00:41 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 622d34b2-775e-4533-9b86-f3a269f7a87d) - 1 spans\n",
      "2025-10-22 23:00:41 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 622d34b2-775e-4533-9b86-f3a269f7a87d\n",
      "2025-10-22 23:00:41 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 622d34b2-775e-4533-9b86-f3a269f7a87d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:41 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:43 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 094c79f8-e0c9-4ce7-b493-3ead460412da) - 1 spans\n",
      "2025-10-22 23:00:43 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 094c79f8-e0c9-4ce7-b493-3ead460412da) - 1 spans\n",
      "2025-10-22 23:00:43 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 094c79f8-e0c9-4ce7-b493-3ead460412da\n",
      "2025-10-22 23:00:43 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 094c79f8-e0c9-4ce7-b493-3ead460412da successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:43 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 13 samples\n",
      "2025-10-22 23:00:43 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 13it [01:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:43 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:43 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:43 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:00:43 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ba787a5a-c805-4920-bcb6-54f73a11e9be) - 1 spans\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ba787a5a-c805-4920-bcb6-54f73a11e9be) - 1 spans\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ba787a5a-c805-4920-bcb6-54f73a11e9be\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ba787a5a-c805-4920-bcb6-54f73a11e9be successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:45 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:45 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:45 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:46 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f7978f02-3999-4b3e-adc7-86d57c952fff) - 1 spans\n",
      "2025-10-22 23:00:46 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f7978f02-3999-4b3e-adc7-86d57c952fff) - 1 spans\n",
      "2025-10-22 23:00:46 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f7978f02-3999-4b3e-adc7-86d57c952fff\n",
      "2025-10-22 23:00:46 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f7978f02-3999-4b3e-adc7-86d57c952fff successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:46 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:47 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f7c102f2-ae59-4acf-8a11-c8763070bc2d) - 1 spans\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f7c102f2-ae59-4acf-8a11-c8763070bc2d) - 1 spans\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f7c102f2-ae59-4acf-8a11-c8763070bc2d\n",
      "2025-10-22 23:00:47 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f7c102f2-ae59-4acf-8a11-c8763070bc2d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:47 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 14 samples\n",
      "2025-10-22 23:00:47 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 14it [01:04,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:47 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:48 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 499bdbdf-4ddd-4197-a8e4-8fa056cf2c81) - 1 spans\n",
      "2025-10-22 23:00:48 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 499bdbdf-4ddd-4197-a8e4-8fa056cf2c81) - 1 spans\n",
      "2025-10-22 23:00:48 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 499bdbdf-4ddd-4197-a8e4-8fa056cf2c81\n",
      "2025-10-22 23:00:48 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 499bdbdf-4ddd-4197-a8e4-8fa056cf2c81 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:48 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:50 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9941d150-0874-4f64-8348-a5e8a777128e) - 1 spans\n",
      "2025-10-22 23:00:50 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9941d150-0874-4f64-8348-a5e8a777128e) - 1 spans\n",
      "2025-10-22 23:00:50 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9941d150-0874-4f64-8348-a5e8a777128e\n",
      "2025-10-22 23:00:50 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9941d150-0874-4f64-8348-a5e8a777128e successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:50 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:51 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.2s >= 5.0s)\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: b4820be8-ae51-49bc-97d5-6aaf3f26ccbf) - 1 spans\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: b4820be8-ae51-49bc-97d5-6aaf3f26ccbf) - 1 spans\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b4820be8-ae51-49bc-97d5-6aaf3f26ccbf\n",
      "2025-10-22 23:00:51 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b4820be8-ae51-49bc-97d5-6aaf3f26ccbf successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:51 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 15 samples\n",
      "2025-10-22 23:00:51 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 15it [01:08,  4.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:51 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:52 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 58a8930f-83c2-4717-9f71-5a34660d8fa2) - 1 spans\n",
      "2025-10-22 23:00:52 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 58a8930f-83c2-4717-9f71-5a34660d8fa2) - 1 spans\n",
      "2025-10-22 23:00:52 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 58a8930f-83c2-4717-9f71-5a34660d8fa2\n",
      "2025-10-22 23:00:52 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 58a8930f-83c2-4717-9f71-5a34660d8fa2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:52 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:52 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:52 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:52 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:53 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9572f06a-e0ba-4e67-81eb-eaad1774cc15) - 1 spans\n",
      "2025-10-22 23:00:53 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9572f06a-e0ba-4e67-81eb-eaad1774cc15) - 1 spans\n",
      "2025-10-22 23:00:53 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9572f06a-e0ba-4e67-81eb-eaad1774cc15\n",
      "2025-10-22 23:00:53 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9572f06a-e0ba-4e67-81eb-eaad1774cc15 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:53 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:54 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 11aa6f5b-1e71-440f-b4d7-cfa0b1a3ae56) - 1 spans\n",
      "2025-10-22 23:00:54 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 11aa6f5b-1e71-440f-b4d7-cfa0b1a3ae56) - 1 spans\n",
      "2025-10-22 23:00:54 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 11aa6f5b-1e71-440f-b4d7-cfa0b1a3ae56\n",
      "2025-10-22 23:00:54 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 11aa6f5b-1e71-440f-b4d7-cfa0b1a3ae56 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:54 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 16 samples\n",
      "2025-10-22 23:00:54 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 16it [01:11,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:54 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:56 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 1700f8dd-b141-4677-9778-db8440931e33) - 1 spans\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 1700f8dd-b141-4677-9778-db8440931e33) - 1 spans\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 1700f8dd-b141-4677-9778-db8440931e33\n",
      "2025-10-22 23:00:56 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 1700f8dd-b141-4677-9778-db8440931e33 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:56 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:57 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:00:57 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:00:57 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:00:58 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4ba7a1c6-56f2-40bb-bb89-bbcd9bf864b9) - 1 spans\n",
      "2025-10-22 23:00:58 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4ba7a1c6-56f2-40bb-bb89-bbcd9bf864b9) - 1 spans\n",
      "2025-10-22 23:00:58 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4ba7a1c6-56f2-40bb-bb89-bbcd9bf864b9\n",
      "2025-10-22 23:00:58 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4ba7a1c6-56f2-40bb-bb89-bbcd9bf864b9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:58 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:59 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: c25eaffa-a215-4fb8-af0d-0d0fcf0acde9) - 1 spans\n",
      "2025-10-22 23:00:59 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: c25eaffa-a215-4fb8-af0d-0d0fcf0acde9) - 1 spans\n",
      "2025-10-22 23:00:59 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace c25eaffa-a215-4fb8-af0d-0d0fcf0acde9\n",
      "2025-10-22 23:00:59 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace c25eaffa-a215-4fb8-af0d-0d0fcf0acde9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:59 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 17 samples\n",
      "2025-10-22 23:00:59 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 17it [01:16,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:00:59 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:00 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: b925a4e7-7af5-4039-a7ab-0fdb05e03c71) - 1 spans\n",
      "2025-10-22 23:01:00 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: b925a4e7-7af5-4039-a7ab-0fdb05e03c71) - 1 spans\n",
      "2025-10-22 23:01:00 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b925a4e7-7af5-4039-a7ab-0fdb05e03c71\n",
      "2025-10-22 23:01:00 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b925a4e7-7af5-4039-a7ab-0fdb05e03c71 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:00 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:01 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.0s >= 5.0s)\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9639d4eb-e562-4372-a019-e6eb2f867d0f) - 1 spans\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9639d4eb-e562-4372-a019-e6eb2f867d0f) - 1 spans\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9639d4eb-e562-4372-a019-e6eb2f867d0f\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9639d4eb-e562-4372-a019-e6eb2f867d0f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:01 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:01 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:01:01 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:01:03 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 02b5f22f-eb99-4514-9a0d-fb74709ade16) - 1 spans\n",
      "2025-10-22 23:01:03 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 02b5f22f-eb99-4514-9a0d-fb74709ade16) - 1 spans\n",
      "2025-10-22 23:01:03 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 02b5f22f-eb99-4514-9a0d-fb74709ade16\n",
      "2025-10-22 23:01:03 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 02b5f22f-eb99-4514-9a0d-fb74709ade16 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:03 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 18 samples\n",
      "2025-10-22 23:01:03 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 18it [01:20,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:03 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:04 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ed8a64df-f92b-4a38-b236-02cd5720da91) - 1 spans\n",
      "2025-10-22 23:01:04 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ed8a64df-f92b-4a38-b236-02cd5720da91) - 1 spans\n",
      "2025-10-22 23:01:04 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ed8a64df-f92b-4a38-b236-02cd5720da91\n",
      "2025-10-22 23:01:04 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ed8a64df-f92b-4a38-b236-02cd5720da91 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:04 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:06 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 65462cbf-b85d-40b9-b50d-a71850336ebe) - 1 spans\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 65462cbf-b85d-40b9-b50d-a71850336ebe) - 1 spans\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 65462cbf-b85d-40b9-b50d-a71850336ebe\n",
      "2025-10-22 23:01:06 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 65462cbf-b85d-40b9-b50d-a71850336ebe successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:06 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:07 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:07 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:01:07 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:01:08 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a174d9f5-fa2d-4c6d-a674-341e8382a11d) - 1 spans\n",
      "2025-10-22 23:01:08 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a174d9f5-fa2d-4c6d-a674-341e8382a11d) - 1 spans\n",
      "2025-10-22 23:01:08 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a174d9f5-fa2d-4c6d-a674-341e8382a11d\n",
      "2025-10-22 23:01:08 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a174d9f5-fa2d-4c6d-a674-341e8382a11d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:08 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 19 samples\n",
      "2025-10-22 23:01:08 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 19it [01:25,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:08 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:09 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 672a16dd-589f-4d48-a8e4-c9e6bb5d871b) - 1 spans\n",
      "2025-10-22 23:01:09 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 672a16dd-589f-4d48-a8e4-c9e6bb5d871b) - 1 spans\n",
      "2025-10-22 23:01:09 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 672a16dd-589f-4d48-a8e4-c9e6bb5d871b\n",
      "2025-10-22 23:01:09 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 672a16dd-589f-4d48-a8e4-c9e6bb5d871b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:09 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:11 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 89085ca6-0aa1-44f9-9d93-804b9725c2c0) - 1 spans\n",
      "2025-10-22 23:01:11 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 89085ca6-0aa1-44f9-9d93-804b9725c2c0) - 1 spans\n",
      "2025-10-22 23:01:11 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 89085ca6-0aa1-44f9-9d93-804b9725c2c0\n",
      "2025-10-22 23:01:11 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 89085ca6-0aa1-44f9-9d93-804b9725c2c0 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:11 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: b7a046e6-46d4-41f7-a47b-35dae73bb923) - 1 spans\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: b7a046e6-46d4-41f7-a47b-35dae73bb923) - 1 spans\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b7a046e6-46d4-41f7-a47b-35dae73bb923\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b7a046e6-46d4-41f7-a47b-35dae73bb923 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 20 samples\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.query_routing_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 20it [01:29,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Reloaded 20 results from CSV\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "\n",
      "üìä Results Summary:\n",
      "  - task_progression: 1.27\n",
      "  - context_relevancy: 7.36\n",
      "  - role_adherence: 5.45\n",
      "  - tool_relevancy: 0.00\n",
      "  - parameter_correctness: 0.00\n",
      "\n",
      "üîç Individual Scores:\n",
      "\n",
      "  Record 1 (Task: eda4fe22-9a2b-4b73-856b-f4f3309bf719):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 2 (Task: 0ffffba1-8a37-443c-8866-d53ffbfa7718):\n",
      "    - task_progression: 2.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 3 (Task: f1f37bd7-0851-4659-b493-b80d3800d920):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 4 (Task: 43cdf081-4f01-49cd-b566-dbd1619e6cd2):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 5 (Task: 9a1983f4-09da-4b53-80e6-38de6878e0e7):\n",
      "    - task_progression: 2.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 6 (Task: 5d2517e1-220a-429d-9d59-f701bda25eed):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 1.0\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 7 (Task: 52aacb67-c361-4445-9b72-c157f79f47d6):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 8 (Task: a81ca3a8-80aa-4c39-876e-8d40ea7a0aef):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 9 (Task: 230aad27-f3dd-4968-a45a-3c2f07ac28ed):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 10 (Task: 83c7dcce-3d89-4da1-8b3f-d419885d4cbc):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 11 (Task: 2218f641-604c-491a-9710-b51a9941b982):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 12 (Task: 255fd49c-84b4-4b18-887e-6308a412d535):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 13 (Task: dc511122-c0b6-415c-9a49-c7b45132dd87):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 14 (Task: 04bebf38-a343-4563-80db-0154bef8d927):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 15 (Task: 5e043630-6493-42b5-beb8-79faa19bfa37):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 16 (Task: 7da9814d-a2e8-4c4e-b750-68b26bd5fd22):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 17 (Task: 16143f74-2831-4753-b33d-ce4b645093c5):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 18 (Task: fc64e6cc-6739-4256-ac4a-7b80c3028233):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 19 (Task: b7945c49-f584-4c70-972d-536a805d8a31):\n",
      "    - task_progression: 1.0\n",
      "    - context_relevancy: 7.5\n",
      "    - role_adherence: 1.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 20 (Task: f5c40ecf-36c0-45ba-9cc9-dc0329b0324b):\n",
      "    - task_progression: 2.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "‚úÖ Evaluation completed successfully!\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.query_routing_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.query_routing_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.query_routing_dataset.json\n",
      "  - Spans loaded: 20\n",
      "  - Dataset size: 20\n",
      "  - Evaluation completed: True\n",
      "  - Export successful: True\n",
      "  - Results saved to: ./demo_results/agent.query_routing_dataset/\n",
      "Completed agent.query_routing_dataset.json\n",
      "\n",
      "Processing tool-orchestator_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/tool-orchestator_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 20 spans from split_datasets/tool-orchestator_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - tool-orchestator: 20\n",
      "‚úÖ Dataset loaded: 20 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "returning unknown type for span\n",
      "{'span_id': 'b6b7c1c0-3b7b-4e19-805d-a16beb7ea871', 'trace_id': 'eda4fe22-9a2b-4b73-856b-f4f3309bf719', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:46.384000000', 'end_time': '2025-10-09 08:26:48.685000000', 'duration_ms': 2301.412, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the latest breakthroughs in artificial intelligence?', 'query.length': 61, 'processing.mode': 'Web Search', 'processing.time_seconds': 2.301326274871826, 'processing.response_length': 423, 'processing.sources_count': 1, 'output_response': 'Final Answer: The provided web search results do not contain specific information about the latest breakthroughs in artificial intelligence. To find the most recent advancements in AI, I recommend checking reputabl...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': 'What are the latest breakthroughs in artificial intelligence?', 'query_processed.output_response': 'Successfully processed query using Web Search, generated 423 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 2.301326274871826, 'query_processed.response_length': 423}, 'events': [], 'links': [], 'trace_trace_id': 'eda4fe22-9a2b-4b73-856b-f4f3309bf719', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:46.384000000', 'trace_end_time': '2025-10-09 08:26:48.685000000', 'trace_duration_ms': 2301.488, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:49.422000000', 'updated_at': '2025-10-09 08:26:49.422000000'}\n",
      "Spans with unknown type: 1\n",
      "returning unknown type for span\n",
      "{'span_id': '3045d971-b7ff-46cc-be11-6db7d65dfefd', 'trace_id': '0ffffba1-8a37-443c-8866-d53ffbfa7718', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:41.850000000', 'end_time': '2025-10-09 08:26:45.377000000', 'duration_ms': 3527.75, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': \"What's happening in the software development world today?\", 'query.length': 57, 'processing.mode': 'Web Search', 'processing.time_seconds': 3.527592897415161, 'processing.response_length': 795, 'processing.sources_count': 1, 'output_response': \"Final Answer: The web search did not yield any specific results regarding current events in the software development world. Therefore, I cannot provide detailed information on what's happening today in that field.\\n...\", 'final_answer_mode': 'Web Search', 'query_processed.input_query': \"What's happening in the software development world today?\", 'query_processed.output_response': 'Successfully processed query using Web Search, generated 795 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 3.527592897415161, 'query_processed.response_length': 795}, 'events': [], 'links': [], 'trace_trace_id': '0ffffba1-8a37-443c-8866-d53ffbfa7718', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:41.850000000', 'trace_end_time': '2025-10-09 08:26:45.377000000', 'trace_duration_ms': 3527.831, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:49.422000000', 'updated_at': '2025-10-09 08:26:49.422000000'}\n",
      "Spans with unknown type: 2\n",
      "returning unknown type for span\n",
      "{'span_id': '42d4cb1f-17ec-433a-8087-90292c2fa9d9', 'trace_id': 'f1f37bd7-0851-4659-b493-b80d3800d920', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:35.915000000', 'end_time': '2025-10-09 08:26:40.841000000', 'duration_ms': 4926.2519999999995, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the newest features in cloud computing?', 'query.length': 48, 'processing.mode': 'RAG', 'processing.time_seconds': 4.926196813583374, 'processing.response_length': 883, 'processing.sources_count': 5, 'output_response': 'Final Answer: The provided context does not specifically mention any new features in cloud computing as a general topic. However, it does highlight several recent enhancements and features related to the Noveum.ai ...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What are the newest features in cloud computing?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 883 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 4.926196813583374, 'query_processed.response_length': 883}, 'events': [], 'links': [], 'trace_trace_id': 'f1f37bd7-0851-4659-b493-b80d3800d920', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:35.915000000', 'trace_end_time': '2025-10-09 08:26:40.841000000', 'trace_duration_ms': 4926.342, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:44.053000000', 'updated_at': '2025-10-09 08:26:44.053000000'}\n",
      "Spans with unknown type: 3\n",
      "returning unknown type for span\n",
      "{'span_id': 'e22b809d-5320-40b7-b78a-e3e125538a6b', 'trace_id': '43cdf081-4f01-49cd-b566-dbd1619e6cd2', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:32.239000000', 'end_time': '2025-10-09 08:26:34.906000000', 'duration_ms': 2667.1330000000003, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': \"What's the current status of cryptocurrency markets?\", 'query.length': 52, 'processing.mode': 'Web Search', 'processing.time_seconds': 2.6669082641601562, 'processing.response_length': 371, 'processing.sources_count': 1, 'output_response': 'Final Answer: The web search results did not provide any specific information regarding the current status of cryptocurrency markets. Therefore, I cannot provide an accurate update on market conditions, trends, or ...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': \"What's the current status of cryptocurrency markets?\", 'query_processed.output_response': 'Successfully processed query using Web Search, generated 371 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 2.6669082641601562, 'query_processed.response_length': 371}, 'events': [], 'links': [], 'trace_trace_id': '43cdf081-4f01-49cd-b566-dbd1619e6cd2', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:32.237000000', 'trace_end_time': '2025-10-09 08:26:34.906000000', 'trace_duration_ms': 2668.841, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:38.618000000', 'updated_at': '2025-10-09 08:26:38.618000000'}\n",
      "Spans with unknown type: 4\n",
      "returning unknown type for span\n",
      "{'span_id': '813a4450-1cf8-4d43-8493-eabfa200919b', 'trace_id': '9a1983f4-09da-4b53-80e6-38de6878e0e7', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:27.992000000', 'end_time': '2025-10-09 08:26:31.231000000', 'duration_ms': 3239.601, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the latest updates in Python programming?', 'query.length': 50, 'processing.mode': 'Web Search', 'processing.time_seconds': 3.2394051551818848, 'processing.response_length': 583, 'processing.sources_count': 1, 'output_response': 'Final Answer: The web search results do not provide specific information about the latest updates in Python programming. They focus primarily on news related to China, including geopolitics, economy, and lifestyle,...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': 'What are the latest updates in Python programming?', 'query_processed.output_response': 'Successfully processed query using Web Search, generated 583 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 3.2394051551818848, 'query_processed.response_length': 583}, 'events': [], 'links': [], 'trace_trace_id': '9a1983f4-09da-4b53-80e6-38de6878e0e7', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:27.992000000', 'trace_end_time': '2025-10-09 08:26:31.231000000', 'trace_duration_ms': 3239.706, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:33.463000000', 'updated_at': '2025-10-09 08:26:33.463000000'}\n",
      "Spans with unknown type: 5\n",
      "returning unknown type for span\n",
      "{'span_id': '6102352a-833e-493d-adbb-887e2af17918', 'trace_id': '5d2517e1-220a-429d-9d59-f701bda25eed', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:23.210000000', 'end_time': '2025-10-09 08:26:26.985000000', 'duration_ms': 3775.0409999999997, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What happened in tech news this week?', 'query.length': 37, 'processing.mode': 'Web Search', 'processing.time_seconds': 3.774940013885498, 'processing.response_length': 501, 'processing.sources_count': 1, 'output_response': 'Final Answer: The web search results do not provide specific information about recent events in tech news for this week. They primarily discuss the grammatical usage of the phrase \"what happened\" and its variations...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': 'What happened in tech news this week?', 'query_processed.output_response': 'Successfully processed query using Web Search, generated 501 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 3.774940013885498, 'query_processed.response_length': 501}, 'events': [], 'links': [], 'trace_trace_id': '5d2517e1-220a-429d-9d59-f701bda25eed', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:23.210000000', 'trace_end_time': '2025-10-09 08:26:26.985000000', 'trace_duration_ms': 3775.124, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:28.174000000', 'updated_at': '2025-10-09 08:26:28.174000000'}\n",
      "Spans with unknown type: 6\n",
      "returning unknown type for span\n",
      "{'span_id': '2926418a-fe09-4df0-bf19-a527bc24a478', 'trace_id': '52aacb67-c361-4445-9b72-c157f79f47d6', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:16.544000000', 'end_time': '2025-10-09 08:26:22.201000000', 'duration_ms': 5656.852, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the current trends in observability tools?', 'query.length': 51, 'processing.mode': 'RAG', 'processing.time_seconds': 5.656759023666382, 'processing.response_length': 1074, 'processing.sources_count': 5, 'output_response': 'Final Answer: The provided context does not explicitly outline current trends in observability tools. However, it highlights some key aspects of observability that are particularly relevant to AI applications. \\n\\n1....', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What are the current trends in observability tools?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 1074 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 5.656759023666382, 'query_processed.response_length': 1074}, 'events': [], 'links': [], 'trace_trace_id': '52aacb67-c361-4445-9b72-c157f79f47d6', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:16.544000000', 'trace_end_time': '2025-10-09 08:26:22.201000000', 'trace_duration_ms': 5657.012, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:22.904000000', 'updated_at': '2025-10-09 08:26:22.904000000'}\n",
      "Spans with unknown type: 7\n",
      "returning unknown type for span\n",
      "{'span_id': 'afe85a1d-13c8-4476-8154-52d58ba83d52', 'trace_id': 'a81ca3a8-80aa-4c39-876e-8d40ea7a0aef', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:08.903000000', 'end_time': '2025-10-09 08:26:15.537000000', 'duration_ms': 6633.559, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'Tell me about recent developments in machine learning', 'query.length': 53, 'processing.mode': 'Web Search', 'processing.time_seconds': 6.63348126411438, 'processing.response_length': 1639, 'processing.sources_count': 1, 'output_response': 'Final Answer: The provided web search results do not contain specific information about recent developments in machine learning. Therefore, I cannot provide a detailed answer based on those results.\\n\\nHowever, I can...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': 'Tell me about recent developments in machine learning', 'query_processed.output_response': 'Successfully processed query using Web Search, generated 1639 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 6.63348126411438, 'query_processed.response_length': 1639}, 'events': [], 'links': [], 'trace_trace_id': 'a81ca3a8-80aa-4c39-876e-8d40ea7a0aef', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:08.903000000', 'trace_end_time': '2025-10-09 08:26:15.537000000', 'trace_duration_ms': 6633.662, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:16.227000000', 'updated_at': '2025-10-09 08:26:16.227000000'}\n",
      "Spans with unknown type: 8\n",
      "returning unknown type for span\n",
      "{'span_id': 'db8da393-6d72-421e-87dc-96f56b6576e5', 'trace_id': '230aad27-f3dd-4968-a45a-3c2f07ac28ed', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:26:02.424000000', 'end_time': '2025-10-09 08:26:07.894000000', 'duration_ms': 5470.179, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': \"What's the weather like today?\", 'query.length': 30, 'processing.mode': 'Web Search', 'processing.time_seconds': 5.469927072525024, 'processing.response_length': 376, 'processing.sources_count': 1, 'output_response': \"Final Answer: The provided web search results do not contain specific information about today's weather in any particular location. They mention weather forecasts for various places, including France and Singapore,...\", 'final_answer_mode': 'Web Search', 'query_processed.input_query': \"What's the weather like today?\", 'query_processed.output_response': 'Successfully processed query using Web Search, generated 376 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 5.469927072525024, 'query_processed.response_length': 376}, 'events': [], 'links': [], 'trace_trace_id': '230aad27-f3dd-4968-a45a-3c2f07ac28ed', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:26:02.424000000', 'trace_end_time': '2025-10-09 08:26:07.894000000', 'trace_duration_ms': 5470.232, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:08.586000000', 'updated_at': '2025-10-09 08:26:08.586000000'}\n",
      "Spans with unknown type: 9\n",
      "returning unknown type for span\n",
      "{'span_id': 'a290202d-1b3f-431f-8728-fcb937380f8c', 'trace_id': '83c7dcce-3d89-4da1-8b3f-d419885d4cbc', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:56.886000000', 'end_time': '2025-10-09 08:26:01.416000000', 'duration_ms': 4530.039000000001, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the latest AI news today?', 'query.length': 34, 'processing.mode': 'Web Search', 'processing.time_seconds': 4.529800176620483, 'processing.response_length': 1003, 'processing.sources_count': 1, 'output_response': 'Final Answer: The latest news in artificial intelligence includes several key updates:\\n\\n1. **AI Spending Concerns**: Jeff Bezos has expressed concerns that the current level of investment in AI resembles an \"indust...', 'final_answer_mode': 'Web Search', 'query_processed.input_query': 'What are the latest AI news today?', 'query_processed.output_response': 'Successfully processed query using Web Search, generated 1003 character response', 'query_processed.mode': 'Web Search', 'query_processed.processing_time': 4.529800176620483, 'query_processed.response_length': 1003}, 'events': [], 'links': [], 'trace_trace_id': '83c7dcce-3d89-4da1-8b3f-d419885d4cbc', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:56.886000000', 'trace_end_time': '2025-10-09 08:26:01.416000000', 'trace_duration_ms': 4530.08, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:26:02.122000000', 'updated_at': '2025-10-09 08:26:02.122000000'}\n",
      "Spans with unknown type: 10\n",
      "returning unknown type for span\n",
      "{'span_id': '5fbaef83-95fc-4bed-9695-9d69c37c35e4', 'trace_id': '2218f641-604c-491a-9710-b51a9941b982', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:48.107000000', 'end_time': '2025-10-09 08:25:55.878000000', 'duration_ms': 7770.846, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What are the benefits of using Noveum Trace?', 'query.length': 44, 'processing.mode': 'RAG', 'processing.time_seconds': 7.770798206329346, 'processing.response_length': 1460, 'processing.sources_count': 5, 'output_response': 'Final Answer: Using Noveum Trace offers several benefits, including:\\n\\n1. **Real-Time Monitoring**: The Noveum platform provides a real-time dashboard for analyzing traces and performance, with live updates as new t...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What are the benefits of using Noveum Trace?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 1460 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 7.770798206329346, 'query_processed.response_length': 1460}, 'events': [], 'links': [], 'trace_trace_id': '2218f641-604c-491a-9710-b51a9941b982', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:48.107000000', 'trace_end_time': '2025-10-09 08:25:55.878000000', 'trace_duration_ms': 7770.953, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:56.565000000', 'updated_at': '2025-10-09 08:25:56.565000000'}\n",
      "Spans with unknown type: 11\n",
      "returning unknown type for span\n",
      "{'span_id': 'b3ac3924-928b-4d48-a2a7-aa749802fef9', 'trace_id': '255fd49c-84b4-4b18-887e-6308a412d535', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:43.830000000', 'end_time': '2025-10-09 08:25:47.099000000', 'duration_ms': 3268.8160000000003, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'How do I configure Noveum for my system?', 'query.length': 40, 'processing.mode': 'RAG', 'processing.time_seconds': 3.268723249435425, 'processing.response_length': 613, 'processing.sources_count': 5, 'output_response': 'Final Answer: To configure Noveum for your system, you can refer to the SDK Integration Guide available in the Noveum documentation. This guide will help you trace your AI applications with minimal code changes. Th...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'How do I configure Noveum for my system?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 613 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 3.268723249435425, 'query_processed.response_length': 613}, 'events': [], 'links': [], 'trace_trace_id': '255fd49c-84b4-4b18-887e-6308a412d535', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:43.830000000', 'trace_end_time': '2025-10-09 08:25:47.099000000', 'trace_duration_ms': 3268.862, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:50.304000000', 'updated_at': '2025-10-09 08:25:50.304000000'}\n",
      "Spans with unknown type: 12\n",
      "returning unknown type for span\n",
      "{'span_id': 'b8055ffc-ee7d-46ad-b6a0-84e80f9399e2', 'trace_id': 'dc511122-c0b6-415c-9a49-c7b45132dd87', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:38.322000000', 'end_time': '2025-10-09 08:25:42.822000000', 'duration_ms': 4500.335, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What monitoring capabilities does Noveum provide?', 'query.length': 49, 'processing.mode': 'RAG', 'processing.time_seconds': 4.5002899169921875, 'processing.response_length': 839, 'processing.sources_count': 5, 'output_response': 'Final Answer: Noveum provides comprehensive monitoring capabilities for AI applications, including the ability to monitor, trace, and optimize AI agents across various frameworks such as LangChain, CrewAI, AutoGen,...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What monitoring capabilities does Noveum provide?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 839 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 4.5002899169921875, 'query_processed.response_length': 839}, 'events': [], 'links': [], 'trace_trace_id': 'dc511122-c0b6-415c-9a49-c7b45132dd87', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:38.322000000', 'trace_end_time': '2025-10-09 08:25:42.822000000', 'trace_duration_ms': 4500.425, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:45.028000000', 'updated_at': '2025-10-09 08:25:45.028000000'}\n",
      "Spans with unknown type: 13\n",
      "returning unknown type for span\n",
      "{'span_id': '532b9e1f-5c4f-4b41-98bb-e9a1510f0f1c', 'trace_id': '04bebf38-a343-4563-80db-0154bef8d927', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:33.693000000', 'end_time': '2025-10-09 08:25:37.313000000', 'duration_ms': 3619.5789999999997, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'How does Noveum handle agent tracing?', 'query.length': 37, 'processing.mode': 'RAG', 'processing.time_seconds': 3.6195271015167236, 'processing.response_length': 691, 'processing.sources_count': 5, 'output_response': 'Final Answer: Noveum.ai handles agent tracing through its specialized Multi-Agent Tracing capabilities, which are designed to observe complex workflows and inter-agent communications within multi-agent systems. The...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'How does Noveum handle agent tracing?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 691 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 3.6195271015167236, 'query_processed.response_length': 691}, 'events': [], 'links': [], 'trace_trace_id': '04bebf38-a343-4563-80db-0154bef8d927', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:33.693000000', 'trace_end_time': '2025-10-09 08:25:37.313000000', 'trace_duration_ms': 3619.672, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:40.339000000', 'updated_at': '2025-10-09 08:25:40.339000000'}\n",
      "Spans with unknown type: 14\n",
      "returning unknown type for span\n",
      "{'span_id': '14064e3f-f9c9-4bb7-b8cb-1ad52938b075', 'trace_id': '5e043630-6493-42b5-beb8-79faa19bfa37', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:29.901000000', 'end_time': '2025-10-09 08:25:32.685000000', 'duration_ms': 2783.257, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What APIs are available in Noveum platform?', 'query.length': 43, 'processing.mode': 'RAG', 'processing.time_seconds': 2.783203125, 'processing.response_length': 270, 'processing.sources_count': 5, 'output_response': 'Final Answer: The provided context does not specify the APIs available in the Noveum platform. For detailed information about the APIs, I recommend checking the official Noveum documentation or the SDK Integration ...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What APIs are available in Noveum platform?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 270 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 2.783203125, 'query_processed.response_length': 270}, 'events': [], 'links': [], 'trace_trace_id': '5e043630-6493-42b5-beb8-79faa19bfa37', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:29.901000000', 'trace_end_time': '2025-10-09 08:25:32.685000000', 'trace_duration_ms': 2783.326, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:34.918000000', 'updated_at': '2025-10-09 08:25:34.918000000'}\n",
      "Spans with unknown type: 15\n",
      "returning unknown type for span\n",
      "{'span_id': 'a74fe8a9-2654-4b9d-ba87-dc2f86b6466d', 'trace_id': '7da9814d-a2e8-4c4e-b750-68b26bd5fd22', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:20.586000000', 'end_time': '2025-10-09 08:25:28.897000000', 'duration_ms': 8310.113, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'How do I set up observability with Noveum?', 'query.length': 42, 'processing.mode': 'RAG', 'processing.time_seconds': 8.31006908416748, 'processing.response_length': 951, 'processing.sources_count': 5, 'output_response': 'Final Answer: To set up observability with Noveum, follow these steps:\\n\\n1. **Sign Up**: Go to [noveum.ai](https://noveum.ai) and create an account.\\n2. **Create a Project**: Once signed in, create a new project to o...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'How do I set up observability with Noveum?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 951 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 8.31006908416748, 'query_processed.response_length': 951}, 'events': [], 'links': [], 'trace_trace_id': '7da9814d-a2e8-4c4e-b750-68b26bd5fd22', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:20.586000000', 'trace_end_time': '2025-10-09 08:25:28.897000000', 'trace_duration_ms': 8310.205, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:29.588000000', 'updated_at': '2025-10-09 08:25:29.588000000'}\n",
      "Spans with unknown type: 16\n",
      "returning unknown type for span\n",
      "{'span_id': 'c700d0f4-f1f8-4339-aa42-a3060ae2ae11', 'trace_id': '16143f74-2831-4753-b33d-ce4b645093c5', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:12.442000000', 'end_time': '2025-10-09 08:25:19.579000000', 'duration_ms': 7137.314, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What features does Noveum Trace offer?', 'query.length': 38, 'processing.mode': 'RAG', 'processing.time_seconds': 7.1372880935668945, 'processing.response_length': 1014, 'processing.sources_count': 5, 'output_response': 'Final Answer: Noveum Trace offers several key features through its Python SDK (`noveum-trace`) and TypeScript SDK (`@noveum/trace`):\\n\\n1. **Decorator-based Tracing**: It provides a simple way to trace LLM calls, age...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What features does Noveum Trace offer?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 1014 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 7.1372880935668945, 'query_processed.response_length': 1014}, 'events': [], 'links': [], 'trace_trace_id': '16143f74-2831-4753-b33d-ce4b645093c5', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:12.442000000', 'trace_end_time': '2025-10-09 08:25:19.579000000', 'trace_duration_ms': 7137.402, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:20.290000000', 'updated_at': '2025-10-09 08:25:20.290000000'}\n",
      "Spans with unknown type: 17\n",
      "returning unknown type for span\n",
      "{'span_id': 'f7f5981f-d840-4265-8970-d319b876366d', 'trace_id': 'fc64e6cc-6739-4256-ac4a-7b80c3028233', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:25:07.932000000', 'end_time': '2025-10-09 08:25:11.438000000', 'duration_ms': 3506.0159999999996, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': \"What are Noveum's pricing plans?\", 'query.length': 32, 'processing.mode': 'RAG', 'processing.time_seconds': 3.5059969425201416, 'processing.response_length': 399, 'processing.sources_count': 5, 'output_response': \"Final Answer: The provided context does not include specific information about Noveum's pricing plans. However, it mentions that all users will have access to the Observability suite for free, and early users will ...\", 'final_answer_mode': 'RAG', 'query_processed.input_query': \"What are Noveum's pricing plans?\", 'query_processed.output_response': 'Successfully processed query using RAG, generated 399 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 3.5059969425201416, 'query_processed.response_length': 399}, 'events': [], 'links': [], 'trace_trace_id': 'fc64e6cc-6739-4256-ac4a-7b80c3028233', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:25:07.932000000', 'trace_end_time': '2025-10-09 08:25:11.438000000', 'trace_duration_ms': 3506.0989999999997, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:12.651000000', 'updated_at': '2025-10-09 08:25:12.651000000'}\n",
      "Spans with unknown type: 18\n",
      "returning unknown type for span\n",
      "{'span_id': '0c7bbe2b-18af-4fdb-a5bf-4a91daa3bf50', 'trace_id': 'b7945c49-f584-4c70-972d-536a805d8a31', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:24:58.518000000', 'end_time': '2025-10-09 08:25:06.920000000', 'duration_ms': 8402.378, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'How do I integrate Noveum Trace in my application?', 'query.length': 50, 'processing.mode': 'RAG', 'processing.time_seconds': 8.402259826660156, 'processing.response_length': 1151, 'processing.sources_count': 5, 'output_response': 'Final Answer: To integrate Noveum Trace into your application, you can use either the Python SDK (`noveum-trace`) or the TypeScript SDK (`@noveum/trace`). Here‚Äôs a quick start guide based on the provided documentat...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'How do I integrate Noveum Trace in my application?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 1151 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 8.402259826660156, 'query_processed.response_length': 1151}, 'events': [], 'links': [], 'trace_trace_id': 'b7945c49-f584-4c70-972d-536a805d8a31', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:24:58.518000000', 'trace_end_time': '2025-10-09 08:25:06.920000000', 'trace_duration_ms': 8402.516, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:25:07.620000000', 'updated_at': '2025-10-09 08:25:07.620000000'}\n",
      "Spans with unknown type: 19\n",
      "returning unknown type for span\n",
      "{'span_id': 'dc869742-6797-4016-8061-37530fc7d433', 'trace_id': 'f5c40ecf-36c0-45ba-9cc9-dc0329b0324b', 'parent_span_id': '', 'name': 'tool-orchestator', 'start_time': '2025-10-09 08:24:54.009000000', 'end_time': '2025-10-09 08:24:57.511000000', 'duration_ms': 3502.0229999999997, 'status': 'ok', 'status_message': '', 'attributes': {'input_query': 'What is Noveum and what does it do?', 'query.length': 35, 'processing.mode': 'RAG', 'processing.time_seconds': 3.5019419193267822, 'processing.response_length': 611, 'processing.sources_count': 5, 'output_response': 'Final Answer: Noveum.ai is a comprehensive tracing and observability platform specifically designed for AI applications, including those powered by large language models (LLMs), retrieval-augmented generation (RAG)...', 'final_answer_mode': 'RAG', 'query_processed.input_query': 'What is Noveum and what does it do?', 'query_processed.output_response': 'Successfully processed query using RAG, generated 611 character response', 'query_processed.mode': 'RAG', 'query_processed.processing_time': 3.5019419193267822, 'query_processed.response_length': 611}, 'events': [], 'links': [], 'trace_trace_id': 'f5c40ecf-36c0-45ba-9cc9-dc0329b0324b', 'trace_name': 'auto_trace_tool-orchestator', 'project': 'noveum-ai-agent-rag-websearch', 'environment': 'development', 'trace_status': 'ok', 'trace_status_message': '', 'trace_start_time': '2025-10-09 08:24:54.009000000', 'trace_end_time': '2025-10-09 08:24:57.511000000', 'trace_duration_ms': 3502.062, 'span_count': 6, 'error_count': 0, 'sdk': {'name': 'noveum-trace-python', 'version': '0.3.8'}, 'trace_attributes': {'noveum.project': 'noveum-ai-agent-rag-websearch', 'noveum.environment': 'development', 'noveum.sdk.version': '0.3.8', 'noveum.sampling.decision': 'record'}, 'metadata': {'user_id': None, 'session_id': None, 'request_id': None, 'tags': {}, 'custom_attributes': {}}, 'created_at': '2025-10-09 08:24:59.716000000', 'updated_at': '2025-10-09 08:24:59.716000000'}\n",
      "Spans with unknown type: 20\n",
      "\n",
      "‚úÖ Successfully converted 20 spans to AgentData\n",
      "üìä AgentDataset created with 20 records\n",
      "‚úÖ AgentDataset created: 20 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'unknown': 20}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:01:12 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 0 sample records...\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "‚ùå Results file not found\n",
      "‚ùå Evaluation failed\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/tool-orchestator_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/tool-orchestator_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/tool-orchestator_dataset.json\n",
      "  - Spans loaded: 20\n",
      "  - Dataset size: 20\n",
      "  - Evaluation completed: False\n",
      "  - Export successful: True\n",
      "  - Errors encountered: 1\n",
      "Completed tool-orchestator_dataset.json\n",
      "\n",
      "Processing agent.web_search_generation_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.web_search_generation_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 8 spans from split_datasets/agent.web_search_generation_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.web_search_generation: 8\n",
      "‚úÖ Dataset loaded: 8 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "agent_task not found\n",
      "agent_response is not available  2aca614b-b016-4d56-abe2-43a144dc681d\n",
      "agent_task not found\n",
      "agent_response is not available  03e3ae4d-0107-401d-8ca0-05fc0f28fb24\n",
      "agent_task not found\n",
      "agent_response is not available  dfdb9aaf-9925-4a5c-a0c6-2cb00f70d4d3\n",
      "agent_task not found\n",
      "agent_response is not available  eefcfdfc-6433-459e-a134-e2647b8418e4\n",
      "agent_task not found\n",
      "agent_response is not available  c57b4b54-b9b0-4a4c-b5cd-57a4cfe5301b\n",
      "agent_task not found\n",
      "agent_response is not available  a062bef6-d973-489b-91df-5d40a2aef077\n",
      "agent_task not found\n",
      "agent_response is not available  41f82a95-620d-440c-84e6-36d6d1b9e079\n",
      "agent_task not found\n",
      "agent_response is not available  63f2a0d5-9016-4483-8ec0-e6aa6b27689f\n",
      "\n",
      "‚úÖ Successfully converted 8 spans to AgentData\n",
      "üìä AgentDataset created with 8 records\n",
      "‚úÖ AgentDataset created: 8 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 8}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:01:12 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 0 sample records...\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "‚ùå Results file not found\n",
      "‚ùå Evaluation failed\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.web_search_generation_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.web_search_generation_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.web_search_generation_dataset.json\n",
      "  - Spans loaded: 8\n",
      "  - Dataset size: 8\n",
      "  - Evaluation completed: False\n",
      "  - Export successful: True\n",
      "  - Errors encountered: 1\n",
      "Completed agent.web_search_generation_dataset.json\n",
      "\n",
      "Processing agent.rag_evaluation_metrics_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.rag_evaluation_metrics_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 12 spans from split_datasets/agent.rag_evaluation_metrics_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.rag_evaluation_metrics: 12\n",
      "‚úÖ Dataset loaded: 12 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "\n",
      "‚úÖ Successfully converted 12 spans to AgentData\n",
      "üìä AgentDataset created with 12 records\n",
      "‚úÖ AgentDataset created: 12 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 12}\n",
      "Records with responses: 12\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 12\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "  - other: 12\n",
      "\n",
      "üìù Response Statistics:\n",
      "  - Average response length: 215.0 characters\n",
      "  - Min response length: 215\n",
      "  - Max response length: 215\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:01:12 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 12 sample records...\n",
      "2025-10-22 23:01:12 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:12 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:01:12 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:01:13 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: eb775ca5-3cc0-47f9-b26b-0e3e770dadd5) - 1 spans\n",
      "2025-10-22 23:01:13 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: eb775ca5-3cc0-47f9-b26b-0e3e770dadd5) - 1 spans\n",
      "2025-10-22 23:01:13 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace eb775ca5-3cc0-47f9-b26b-0e3e770dadd5\n",
      "2025-10-22 23:01:13 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace eb775ca5-3cc0-47f9-b26b-0e3e770dadd5 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:13 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:16 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: cce316e9-4f3f-4d2b-bdba-b2856b9c4181) - 1 spans\n",
      "2025-10-22 23:01:16 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: cce316e9-4f3f-4d2b-bdba-b2856b9c4181) - 1 spans\n",
      "2025-10-22 23:01:16 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace cce316e9-4f3f-4d2b-bdba-b2856b9c4181\n",
      "2025-10-22 23:01:16 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace cce316e9-4f3f-4d2b-bdba-b2856b9c4181 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:16 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:17 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:01:17 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:01:17 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:17 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:17 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:01:17 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:01:18 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ef7447dd-1534-4496-9aff-02d51839cd0c) - 1 spans\n",
      "2025-10-22 23:01:18 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ef7447dd-1534-4496-9aff-02d51839cd0c) - 1 spans\n",
      "2025-10-22 23:01:18 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ef7447dd-1534-4496-9aff-02d51839cd0c\n",
      "2025-10-22 23:01:18 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ef7447dd-1534-4496-9aff-02d51839cd0c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:18 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 1 samples\n",
      "2025-10-22 23:01:18 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 1it [00:06,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:18 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:20 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: d32ecc4b-d331-4e62-9ef2-ec61e6fc52bf) - 1 spans\n",
      "2025-10-22 23:01:20 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: d32ecc4b-d331-4e62-9ef2-ec61e6fc52bf) - 1 spans\n",
      "2025-10-22 23:01:20 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace d32ecc4b-d331-4e62-9ef2-ec61e6fc52bf\n",
      "2025-10-22 23:01:20 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace d32ecc4b-d331-4e62-9ef2-ec61e6fc52bf successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:20 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:22 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 37646e1d-3bea-43ae-af16-71bf5ba46b9c) - 1 spans\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 37646e1d-3bea-43ae-af16-71bf5ba46b9c) - 1 spans\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 37646e1d-3bea-43ae-af16-71bf5ba46b9c\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 37646e1d-3bea-43ae-af16-71bf5ba46b9c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:22 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:22 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.2s >= 5.0s)\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:01:22 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:01:23 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 309e9e0e-8ee6-46e4-86c2-60922d034adb) - 1 spans\n",
      "2025-10-22 23:01:23 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 309e9e0e-8ee6-46e4-86c2-60922d034adb) - 1 spans\n",
      "2025-10-22 23:01:23 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 309e9e0e-8ee6-46e4-86c2-60922d034adb\n",
      "2025-10-22 23:01:23 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 309e9e0e-8ee6-46e4-86c2-60922d034adb successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:23 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 2 samples\n",
      "2025-10-22 23:01:23 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 2it [00:10,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:23 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:24 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 7876eb8f-cae3-442a-b676-588d0e06a56b) - 1 spans\n",
      "2025-10-22 23:01:24 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 7876eb8f-cae3-442a-b676-588d0e06a56b) - 1 spans\n",
      "2025-10-22 23:01:24 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 7876eb8f-cae3-442a-b676-588d0e06a56b\n",
      "2025-10-22 23:01:24 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 7876eb8f-cae3-442a-b676-588d0e06a56b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:24 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:26 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a1a2f4ae-eaf9-4742-94d2-b2b650faf225) - 1 spans\n",
      "2025-10-22 23:01:26 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a1a2f4ae-eaf9-4742-94d2-b2b650faf225) - 1 spans\n",
      "2025-10-22 23:01:26 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a1a2f4ae-eaf9-4742-94d2-b2b650faf225\n",
      "2025-10-22 23:01:26 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a1a2f4ae-eaf9-4742-94d2-b2b650faf225 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:26 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:27 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.1s >= 5.0s)\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 7fd55fac-bb86-4db1-9e20-e5ce69a772fb) - 1 spans\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 7fd55fac-bb86-4db1-9e20-e5ce69a772fb) - 1 spans\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 7fd55fac-bb86-4db1-9e20-e5ce69a772fb\n",
      "2025-10-22 23:01:27 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 7fd55fac-bb86-4db1-9e20-e5ce69a772fb successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:27 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 3 samples\n",
      "2025-10-22 23:01:27 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 3it [00:15,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:27 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:28 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3e3b5c0c-04e1-4bf5-8ea2-c70387c8e327) - 1 spans\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3e3b5c0c-04e1-4bf5-8ea2-c70387c8e327) - 1 spans\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3e3b5c0c-04e1-4bf5-8ea2-c70387c8e327\n",
      "2025-10-22 23:01:28 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3e3b5c0c-04e1-4bf5-8ea2-c70387c8e327 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:28 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:30 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3e9b223d-42c3-4f70-8541-e8b7c27201fc) - 1 spans\n",
      "2025-10-22 23:01:30 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3e9b223d-42c3-4f70-8541-e8b7c27201fc) - 1 spans\n",
      "2025-10-22 23:01:30 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3e9b223d-42c3-4f70-8541-e8b7c27201fc\n",
      "2025-10-22 23:01:30 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3e9b223d-42c3-4f70-8541-e8b7c27201fc successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:30 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:31 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f822ee4c-33fa-4a46-8a1c-a9fd7a749983) - 1 spans\n",
      "2025-10-22 23:01:31 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f822ee4c-33fa-4a46-8a1c-a9fd7a749983) - 1 spans\n",
      "2025-10-22 23:01:31 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f822ee4c-33fa-4a46-8a1c-a9fd7a749983\n",
      "2025-10-22 23:01:31 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f822ee4c-33fa-4a46-8a1c-a9fd7a749983 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:31 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 4 samples\n",
      "2025-10-22 23:01:31 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 4it [00:18,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:31 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:32 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: b9ec0566-acc2-4c49-8fa4-fa58362b7056) - 1 spans\n",
      "2025-10-22 23:01:32 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: b9ec0566-acc2-4c49-8fa4-fa58362b7056) - 1 spans\n",
      "2025-10-22 23:01:32 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace b9ec0566-acc2-4c49-8fa4-fa58362b7056\n",
      "2025-10-22 23:01:32 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace b9ec0566-acc2-4c49-8fa4-fa58362b7056 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:32 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:32 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:01:32 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 5 traces via send_callback\n",
      "2025-10-22 23:01:32 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 5 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:33 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:33 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 5 traces\n",
      "2025-10-22 23:01:33 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 5 traces via callback\n",
      "2025-10-22 23:01:34 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4a7712cd-d5db-43d4-b9f9-3bf2854fd36d) - 1 spans\n",
      "2025-10-22 23:01:34 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4a7712cd-d5db-43d4-b9f9-3bf2854fd36d) - 1 spans\n",
      "2025-10-22 23:01:34 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4a7712cd-d5db-43d4-b9f9-3bf2854fd36d\n",
      "2025-10-22 23:01:34 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4a7712cd-d5db-43d4-b9f9-3bf2854fd36d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:34 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:35 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: d3a4f8d6-9ac8-4312-982f-ed0ba66a9792) - 1 spans\n",
      "2025-10-22 23:01:35 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: d3a4f8d6-9ac8-4312-982f-ed0ba66a9792) - 1 spans\n",
      "2025-10-22 23:01:35 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace d3a4f8d6-9ac8-4312-982f-ed0ba66a9792\n",
      "2025-10-22 23:01:35 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace d3a4f8d6-9ac8-4312-982f-ed0ba66a9792 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:35 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 5 samples\n",
      "2025-10-22 23:01:35 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 5it [00:22,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:35 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:36 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 089525d7-5531-478e-b4f3-fec4d1ac533d) - 1 spans\n",
      "2025-10-22 23:01:36 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 089525d7-5531-478e-b4f3-fec4d1ac533d) - 1 spans\n",
      "2025-10-22 23:01:36 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 089525d7-5531-478e-b4f3-fec4d1ac533d\n",
      "2025-10-22 23:01:36 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 089525d7-5531-478e-b4f3-fec4d1ac533d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:36 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:37 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 2214e8fb-a31c-4111-8735-0c6c8057a66c) - 1 spans\n",
      "2025-10-22 23:01:37 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 2214e8fb-a31c-4111-8735-0c6c8057a66c) - 1 spans\n",
      "2025-10-22 23:01:37 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 2214e8fb-a31c-4111-8735-0c6c8057a66c\n",
      "2025-10-22 23:01:37 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 2214e8fb-a31c-4111-8735-0c6c8057a66c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:37 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:38 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.3s >= 5.0s)\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4d917e77-4f61-46e5-8aed-f705e23cf42b) - 1 spans\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4d917e77-4f61-46e5-8aed-f705e23cf42b) - 1 spans\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4d917e77-4f61-46e5-8aed-f705e23cf42b\n",
      "2025-10-22 23:01:38 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4d917e77-4f61-46e5-8aed-f705e23cf42b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:38 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 6 samples\n",
      "2025-10-22 23:01:38 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 6it [00:26,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:38 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:40 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f08a5cf5-f699-499a-bf6f-7c5ab49bee74) - 1 spans\n",
      "2025-10-22 23:01:40 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f08a5cf5-f699-499a-bf6f-7c5ab49bee74) - 1 spans\n",
      "2025-10-22 23:01:40 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f08a5cf5-f699-499a-bf6f-7c5ab49bee74\n",
      "2025-10-22 23:01:40 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f08a5cf5-f699-499a-bf6f-7c5ab49bee74 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:40 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:41 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 22fad5c7-5c05-46dc-be41-410da97ae840) - 1 spans\n",
      "2025-10-22 23:01:41 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 22fad5c7-5c05-46dc-be41-410da97ae840) - 1 spans\n",
      "2025-10-22 23:01:41 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 22fad5c7-5c05-46dc-be41-410da97ae840\n",
      "2025-10-22 23:01:41 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 22fad5c7-5c05-46dc-be41-410da97ae840 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:41 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:42 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 81742ed5-9524-4203-aaf6-837045f5d1ce) - 1 spans\n",
      "2025-10-22 23:01:42 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 81742ed5-9524-4203-aaf6-837045f5d1ce) - 1 spans\n",
      "2025-10-22 23:01:42 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 81742ed5-9524-4203-aaf6-837045f5d1ce\n",
      "2025-10-22 23:01:42 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 81742ed5-9524-4203-aaf6-837045f5d1ce successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:42 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 7 samples\n",
      "2025-10-22 23:01:42 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 7it [00:30,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:42 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:43 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 8dd29a67-8d57-4f95-b0bd-9c1fa22f55da) - 1 spans\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 8dd29a67-8d57-4f95-b0bd-9c1fa22f55da) - 1 spans\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 8dd29a67-8d57-4f95-b0bd-9c1fa22f55da\n",
      "2025-10-22 23:01:43 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 8dd29a67-8d57-4f95-b0bd-9c1fa22f55da successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:43 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:44 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:44 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:01:44 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:01:45 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ae9c03e4-9a18-4c40-a616-34ba6df7216e) - 1 spans\n",
      "2025-10-22 23:01:45 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ae9c03e4-9a18-4c40-a616-34ba6df7216e) - 1 spans\n",
      "2025-10-22 23:01:45 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ae9c03e4-9a18-4c40-a616-34ba6df7216e\n",
      "2025-10-22 23:01:45 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ae9c03e4-9a18-4c40-a616-34ba6df7216e successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:45 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:46 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: aefaba52-0c8a-428c-af02-72f1145c5c99) - 1 spans\n",
      "2025-10-22 23:01:46 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: aefaba52-0c8a-428c-af02-72f1145c5c99) - 1 spans\n",
      "2025-10-22 23:01:46 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace aefaba52-0c8a-428c-af02-72f1145c5c99\n",
      "2025-10-22 23:01:46 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace aefaba52-0c8a-428c-af02-72f1145c5c99 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:46 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 8 samples\n",
      "2025-10-22 23:01:46 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 8it [00:34,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:46 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:47 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 6d0b6d2c-d570-40cb-8d9d-c0a1187d7ec5) - 1 spans\n",
      "2025-10-22 23:01:47 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 6d0b6d2c-d570-40cb-8d9d-c0a1187d7ec5) - 1 spans\n",
      "2025-10-22 23:01:47 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 6d0b6d2c-d570-40cb-8d9d-c0a1187d7ec5\n",
      "2025-10-22 23:01:47 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 6d0b6d2c-d570-40cb-8d9d-c0a1187d7ec5 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:47 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:49 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: af1cb192-c53d-4c68-bcf1-63ae80a319ab) - 1 spans\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: af1cb192-c53d-4c68-bcf1-63ae80a319ab) - 1 spans\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace af1cb192-c53d-4c68-bcf1-63ae80a319ab\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace af1cb192-c53d-4c68-bcf1-63ae80a319ab successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:49 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:49 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:01:49 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:01:50 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 6dc7d782-6f29-481b-9738-d22d793c9d53) - 1 spans\n",
      "2025-10-22 23:01:50 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 6dc7d782-6f29-481b-9738-d22d793c9d53) - 1 spans\n",
      "2025-10-22 23:01:50 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 6dc7d782-6f29-481b-9738-d22d793c9d53\n",
      "2025-10-22 23:01:50 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 6dc7d782-6f29-481b-9738-d22d793c9d53 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:50 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 9 samples\n",
      "2025-10-22 23:01:50 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 9it [00:38,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:50 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:51 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 79ae16c8-3b0e-4e3c-bc10-9eae81586163) - 1 spans\n",
      "2025-10-22 23:01:51 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 79ae16c8-3b0e-4e3c-bc10-9eae81586163) - 1 spans\n",
      "2025-10-22 23:01:51 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 79ae16c8-3b0e-4e3c-bc10-9eae81586163\n",
      "2025-10-22 23:01:51 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 79ae16c8-3b0e-4e3c-bc10-9eae81586163 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:51 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:52 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: e69630b6-5e34-4ae7-9195-929d04ef31a5) - 1 spans\n",
      "2025-10-22 23:01:52 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: e69630b6-5e34-4ae7-9195-929d04ef31a5) - 1 spans\n",
      "2025-10-22 23:01:52 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace e69630b6-5e34-4ae7-9195-929d04ef31a5\n",
      "2025-10-22 23:01:52 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace e69630b6-5e34-4ae7-9195-929d04ef31a5 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:52 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:53 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: ef939d49-86d5-4ab4-b8a3-918e10f86639) - 1 spans\n",
      "2025-10-22 23:01:53 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: ef939d49-86d5-4ab4-b8a3-918e10f86639) - 1 spans\n",
      "2025-10-22 23:01:53 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace ef939d49-86d5-4ab4-b8a3-918e10f86639\n",
      "2025-10-22 23:01:53 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace ef939d49-86d5-4ab4-b8a3-918e10f86639 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:53 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 10 samples\n",
      "2025-10-22 23:01:53 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 10it [00:41,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:53 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:54 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:01:54 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 5 traces via send_callback\n",
      "2025-10-22 23:01:54 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 5 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:54 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:01:54 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 5 traces\n",
      "2025-10-22 23:01:54 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 5 traces via callback\n",
      "2025-10-22 23:01:57 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 926cf84f-fcb5-4e44-b36b-dfa5f9c28c55) - 1 spans\n",
      "2025-10-22 23:01:57 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 926cf84f-fcb5-4e44-b36b-dfa5f9c28c55) - 1 spans\n",
      "2025-10-22 23:01:57 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 926cf84f-fcb5-4e44-b36b-dfa5f9c28c55\n",
      "2025-10-22 23:01:57 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 926cf84f-fcb5-4e44-b36b-dfa5f9c28c55 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:57 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:58 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 5bb8255c-0f41-4735-a818-52f6115b7de1) - 1 spans\n",
      "2025-10-22 23:01:58 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 5bb8255c-0f41-4735-a818-52f6115b7de1) - 1 spans\n",
      "2025-10-22 23:01:58 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 5bb8255c-0f41-4735-a818-52f6115b7de1\n",
      "2025-10-22 23:01:58 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 5bb8255c-0f41-4735-a818-52f6115b7de1 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:58 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:01:59 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
      "2025-10-22 23:01:59 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 2 traces via send_callback\n",
      "2025-10-22 23:01:59 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 2 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 96472f81-b98d-4453-97e8-b0000f4ac7b6) - 1 spans\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 96472f81-b98d-4453-97e8-b0000f4ac7b6) - 1 spans\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 2 traces\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 96472f81-b98d-4453-97e8-b0000f4ac7b6\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 96472f81-b98d-4453-97e8-b0000f4ac7b6 successfully queued for export\n",
      "2025-10-22 23:02:00 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 2 traces via callback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:00 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 11 samples\n",
      "2025-10-22 23:02:00 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 11it [00:47,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:00 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:02 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 3ec56361-a2aa-45bd-ad9e-12139cd5b25b) - 1 spans\n",
      "2025-10-22 23:02:02 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 3ec56361-a2aa-45bd-ad9e-12139cd5b25b) - 1 spans\n",
      "2025-10-22 23:02:02 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 3ec56361-a2aa-45bd-ad9e-12139cd5b25b\n",
      "2025-10-22 23:02:02 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 3ec56361-a2aa-45bd-ad9e-12139cd5b25b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:02 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:03 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: bd7c6734-9502-43af-9227-7e3256eac18c) - 1 spans\n",
      "2025-10-22 23:02:03 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: bd7c6734-9502-43af-9227-7e3256eac18c) - 1 spans\n",
      "2025-10-22 23:02:03 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace bd7c6734-9502-43af-9227-7e3256eac18c\n",
      "2025-10-22 23:02:03 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace bd7c6734-9502-43af-9227-7e3256eac18c successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:03 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 8c77b5d2-4e09-4e86-89db-9c4432c6a8f9) - 1 spans\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 8c77b5d2-4e09-4e86-89db-9c4432c6a8f9) - 1 spans\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 8c77b5d2-4e09-4e86-89db-9c4432c6a8f9\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 8c77b5d2-4e09-4e86-89db-9c4432c6a8f9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 12 samples\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.rag_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 12it [00:52,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Reloaded 12 results from CSV\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "\n",
      "üìä Results Summary:\n",
      "  - task_progression: 4.27\n",
      "  - context_relevancy: 7.90\n",
      "  - role_adherence: 9.08\n",
      "  - tool_relevancy: 0.00\n",
      "  - parameter_correctness: 0.00\n",
      "\n",
      "üîç Individual Scores:\n",
      "\n",
      "  Record 1 (Task: f1f37bd7-0851-4659-b493-b80d3800d920):\n",
      "    - task_progression: 3.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 2 (Task: 52aacb67-c361-4445-9b72-c157f79f47d6):\n",
      "    - task_progression: 2.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 3 (Task: 2218f641-604c-491a-9710-b51a9941b982):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 7.9\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 4 (Task: 255fd49c-84b4-4b18-887e-6308a412d535):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 5 (Task: dc511122-c0b6-415c-9a49-c7b45132dd87):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 8.1\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 6 (Task: 04bebf38-a343-4563-80db-0154bef8d927):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 7 (Task: 5e043630-6493-42b5-beb8-79faa19bfa37):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 8 (Task: 7da9814d-a2e8-4c4e-b750-68b26bd5fd22):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 9 (Task: 16143f74-2831-4753-b33d-ce4b645093c5):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 8.1\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 10 (Task: fc64e6cc-6739-4256-ac4a-7b80c3028233):\n",
      "    - task_progression: 4.1\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 11 (Task: b7945c49-f584-4c70-972d-536a805d8a31):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 8.0\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 12 (Task: f5c40ecf-36c0-45ba-9cc9-dc0329b0324b):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 8.1\n",
      "    - role_adherence: 10.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "‚úÖ Evaluation completed successfully!\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.rag_evaluation_metrics_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.rag_evaluation_metrics_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.rag_evaluation_metrics_dataset.json\n",
      "  - Spans loaded: 12\n",
      "  - Dataset size: 12\n",
      "  - Evaluation completed: True\n",
      "  - Export successful: True\n",
      "  - Results saved to: ./demo_results/agent.rag_evaluation_metrics_dataset/\n",
      "Completed agent.rag_evaluation_metrics_dataset.json\n",
      "\n",
      "Processing agent.routing_evaluation_metrics_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.routing_evaluation_metrics_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 20 spans from split_datasets/agent.routing_evaluation_metrics_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.routing_evaluation_metrics: 20\n",
      "‚úÖ Dataset loaded: 20 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "agent_task not found\n",
      "agent_response is not available  95dac0c3-83fd-459c-af4e-c6a1734fd874\n",
      "agent_task not found\n",
      "agent_response is not available  516060a3-0f58-46ba-8a6a-4b502a376492\n",
      "agent_task not found\n",
      "agent_response is not available  8f8d2dc4-150f-4e43-aad3-96da4d06f586\n",
      "agent_task not found\n",
      "agent_response is not available  cf0a915c-668b-412e-9c14-69119d059dc2\n",
      "agent_task not found\n",
      "agent_response is not available  f75b51b8-4882-4170-bc08-2adcab250f50\n",
      "agent_task not found\n",
      "agent_response is not available  4180abcf-924c-45ac-8dfa-17c0bc603eff\n",
      "agent_task not found\n",
      "agent_response is not available  8b0022cc-91dd-4065-91ed-b77217f92bd7\n",
      "agent_task not found\n",
      "agent_response is not available  780df186-fe5a-4742-b937-2a142ad528c6\n",
      "agent_task not found\n",
      "agent_response is not available  f80ae3e8-b4dd-42c6-b17b-de7805cedbb9\n",
      "agent_task not found\n",
      "agent_response is not available  209259cf-411d-4b97-8f7b-40b2530eec81\n",
      "agent_task not found\n",
      "agent_response is not available  c3f3bd32-9954-443f-93e5-52aa6cf412a0\n",
      "agent_task not found\n",
      "agent_response is not available  940ce621-0015-45ed-adc6-c4caa2a95e81\n",
      "agent_task not found\n",
      "agent_response is not available  ea28f049-6bc9-48b4-8386-279abe087ca8\n",
      "agent_task not found\n",
      "agent_response is not available  01a03da5-64df-41e3-b9c9-556e12a8edd7\n",
      "agent_task not found\n",
      "agent_response is not available  8d9c632b-b2e8-496d-b1b0-a89e780ef810\n",
      "agent_task not found\n",
      "agent_response is not available  72dfbba4-0672-4adc-a1bf-308157d831e6\n",
      "agent_task not found\n",
      "agent_response is not available  92c81ee2-728d-4ea6-bc52-b81295d2aea2\n",
      "agent_task not found\n",
      "agent_response is not available  807627b0-41d9-478f-8a8b-26540d70af68\n",
      "agent_task not found\n",
      "agent_response is not available  bf860672-af22-44c1-b13b-0eabe8f72503\n",
      "agent_task not found\n",
      "agent_response is not available  5fa714f1-eeb9-4617-bc7e-67062e6d1eab\n",
      "\n",
      "‚úÖ Successfully converted 20 spans to AgentData\n",
      "üìä AgentDataset created with 20 records\n",
      "‚úÖ AgentDataset created: 20 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 20}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:02:05 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 0 sample records...\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "‚ùå Results file not found\n",
      "‚ùå Evaluation failed\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.routing_evaluation_metrics_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.routing_evaluation_metrics_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.routing_evaluation_metrics_dataset.json\n",
      "  - Spans loaded: 20\n",
      "  - Dataset size: 20\n",
      "  - Evaluation completed: False\n",
      "  - Export successful: True\n",
      "  - Errors encountered: 1\n",
      "Completed agent.routing_evaluation_metrics_dataset.json\n",
      "\n",
      "Processing agent.llm-rag_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.llm-rag_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 12 spans from split_datasets/agent.llm-rag_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.llm-rag: 12\n",
      "‚úÖ Dataset loaded: 12 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "agent_task not found\n",
      "agent_response is not available  ea4d61c5-b8dd-4677-b21b-2b17170e2163\n",
      "agent_task not found\n",
      "agent_response is not available  7505f97a-cbc0-42fe-8a72-95387d723daa\n",
      "agent_task not found\n",
      "agent_response is not available  8a6e18a1-babc-4166-926f-188f344d514e\n",
      "agent_task not found\n",
      "agent_response is not available  5bec4165-6596-43ac-930b-acfcde1cc02a\n",
      "agent_task not found\n",
      "agent_response is not available  f9f79a07-4eda-41b8-9634-d4460114caad\n",
      "agent_task not found\n",
      "agent_response is not available  edc52a5d-8450-4d0f-ad14-958ec4d147f4\n",
      "agent_task not found\n",
      "agent_response is not available  6c362c73-e063-4813-8180-d26b6a52b798\n",
      "agent_task not found\n",
      "agent_response is not available  1393d065-a9a4-4475-808f-2d00b3c68939\n",
      "agent_task not found\n",
      "agent_response is not available  f419377a-fc24-4abf-8a1c-03857824e374\n",
      "agent_task not found\n",
      "agent_response is not available  0e58e31f-a8ab-4aee-8fc2-abcae1e21d9d\n",
      "agent_task not found\n",
      "agent_response is not available  48155aad-6204-4a52-8624-8fa5d6fe407f\n",
      "agent_task not found\n",
      "agent_response is not available  57ded2eb-0f3f-474e-8704-5ad9974ab4bb\n",
      "\n",
      "‚úÖ Successfully converted 12 spans to AgentData\n",
      "üìä AgentDataset created with 12 records\n",
      "‚úÖ AgentDataset created: 12 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 12}\n",
      "Records with responses: 0\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 0\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:02:05 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n",
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 0 sample records...\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "‚ùå Results file not found\n",
      "‚ùå Evaluation failed\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.llm-rag_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.llm-rag_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.llm-rag_dataset.json\n",
      "  - Spans loaded: 12\n",
      "  - Dataset size: 12\n",
      "  - Evaluation completed: False\n",
      "  - Export successful: True\n",
      "  - Errors encountered: 1\n",
      "Completed agent.llm-rag_dataset.json\n",
      "\n",
      "Processing agent.web_search_evaluation_metrics_dataset.json...\n",
      "üöÄ Starting Complete Agent Evaluation Pipeline\n",
      "üìÅ Processing file: split_datasets/agent.web_search_evaluation_metrics_dataset.json\n",
      "============================================================\n",
      "\n",
      "üìã Step 1: Environment Setup\n",
      "‚úÖ Logging configured at INFO level\n",
      "üîç Environment validation:\n",
      "  ‚úÖ gemini_api_key: True\n",
      "  ‚úÖ pandas_available: True\n",
      "  ‚úÖ novaeval_available: True\n",
      "‚úÖ Environment ready for evaluation!\n",
      "\n",
      "üìã Step 2: Loading Dataset\n",
      "üìä Loaded 8 spans from split_datasets/agent.web_search_evaluation_metrics_dataset.json\n",
      "\n",
      "üîç Available span types:\n",
      "  - agent.web_search_evaluation_metrics: 8\n",
      "‚úÖ Dataset loaded: 8 spans\n",
      "\n",
      "üìã Step 3: Converting to AgentDataset Format\n",
      "üîÑ Converting spans to AgentData objects...\n",
      "\n",
      "‚úÖ Successfully converted 8 spans to AgentData\n",
      "üìä AgentDataset created with 8 records\n",
      "‚úÖ AgentDataset created: 8 records\n",
      "\n",
      "üìã Step 4: Dataset Analysis\n",
      "üìà Dataset Statistics:\n",
      "\n",
      "Agent Types: {'agent': 8}\n",
      "Records with responses: 8\n",
      "Records with tool calls: 0\n",
      "Records with retrieval: 8\n",
      "Tool usage: {}\n",
      "üîç Dataset Analysis:\n",
      "\n",
      "=== Agent Behavior Patterns ===\n",
      "\n",
      "üìà Tool Usage:\n",
      "\n",
      "üìã Task Types:\n",
      "  - other: 8\n",
      "\n",
      "üìù Response Statistics:\n",
      "  - Average response length: 222.0 characters\n",
      "  - Min response length: 222\n",
      "  - Max response length: 222\n",
      "\n",
      "üìã Step 5: Setting up Evaluation\n",
      "‚úÖ GEMINI_API_KEY found in environment\n",
      "2025-10-22 23:02:05 - INFO - novaeval.models.base - Noveum tracing initialized successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini model initialized\n",
      "‚úÖ Initialized 5 scoring functions:\n",
      "  - task_progression_scorer\n",
      "  - context_relevancy_scorer\n",
      "  - role_adherence_scorer\n",
      "  - tool_relevancy_scorer\n",
      "  - parameter_correctness_scorer\n",
      "\n",
      "‚úÖ AgentEvaluator created with Gemini model and scoring functions\n",
      "‚úÖ Evaluation components ready!\n",
      "\n",
      "üìã Step 6: Running Evaluation\n",
      "üéØ Evaluating 25 samples...\n",
      "üöÄ Running evaluation on sample data...\n",
      "\n",
      "üìä Evaluating 8 sample records...\n",
      "2025-10-22 23:02:05 - INFO - novaeval.evaluators.agent_evaluator - Starting agent evaluation process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:05 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:02:05 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:02:07 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: e7588539-fcf8-44a3-9f31-efe82ba97700) - 1 spans\n",
      "2025-10-22 23:02:07 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: e7588539-fcf8-44a3-9f31-efe82ba97700) - 1 spans\n",
      "2025-10-22 23:02:07 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace e7588539-fcf8-44a3-9f31-efe82ba97700\n",
      "2025-10-22 23:02:07 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace e7588539-fcf8-44a3-9f31-efe82ba97700 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:07 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:08 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a47d3d33-371b-4045-9fb1-378424928ada) - 1 spans\n",
      "2025-10-22 23:02:08 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a47d3d33-371b-4045-9fb1-378424928ada) - 1 spans\n",
      "2025-10-22 23:02:08 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a47d3d33-371b-4045-9fb1-378424928ada\n",
      "2025-10-22 23:02:08 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a47d3d33-371b-4045-9fb1-378424928ada successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:08 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:09 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 69314585-f591-4d20-ba7c-81dcd5fa7aee) - 1 spans\n",
      "2025-10-22 23:02:09 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 69314585-f591-4d20-ba7c-81dcd5fa7aee) - 1 spans\n",
      "2025-10-22 23:02:09 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 69314585-f591-4d20-ba7c-81dcd5fa7aee\n",
      "2025-10-22 23:02:09 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 69314585-f591-4d20-ba7c-81dcd5fa7aee successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:09 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 1 samples\n",
      "2025-10-22 23:02:09 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 1it [00:04,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:09 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:10 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: a05b5d92-06f6-4fec-9673-f33c267ef809) - 1 spans\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: a05b5d92-06f6-4fec-9673-f33c267ef809) - 1 spans\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace a05b5d92-06f6-4fec-9673-f33c267ef809\n",
      "2025-10-22 23:02:10 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace a05b5d92-06f6-4fec-9673-f33c267ef809 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:10 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:11 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:11 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:02:11 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:02:12 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 032c73be-2c3f-4980-9cdf-762de61c437e) - 1 spans\n",
      "2025-10-22 23:02:12 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 032c73be-2c3f-4980-9cdf-762de61c437e) - 1 spans\n",
      "2025-10-22 23:02:12 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 032c73be-2c3f-4980-9cdf-762de61c437e\n",
      "2025-10-22 23:02:12 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 032c73be-2c3f-4980-9cdf-762de61c437e successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:12 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:13 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4ccea784-7905-4081-b536-1a6fade9180f) - 1 spans\n",
      "2025-10-22 23:02:13 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4ccea784-7905-4081-b536-1a6fade9180f) - 1 spans\n",
      "2025-10-22 23:02:13 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4ccea784-7905-4081-b536-1a6fade9180f\n",
      "2025-10-22 23:02:13 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4ccea784-7905-4081-b536-1a6fade9180f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:13 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 2 samples\n",
      "2025-10-22 23:02:13 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 2it [00:07,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:13 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:14 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 4a768f59-41a4-4da7-b4fb-1530bd85f1bc) - 1 spans\n",
      "2025-10-22 23:02:14 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 4a768f59-41a4-4da7-b4fb-1530bd85f1bc) - 1 spans\n",
      "2025-10-22 23:02:14 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 4a768f59-41a4-4da7-b4fb-1530bd85f1bc\n",
      "2025-10-22 23:02:14 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 4a768f59-41a4-4da7-b4fb-1530bd85f1bc successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:14 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:15 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 490c1659-4aca-401f-bf9d-34891b18717a) - 1 spans\n",
      "2025-10-22 23:02:15 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 490c1659-4aca-401f-bf9d-34891b18717a) - 1 spans\n",
      "2025-10-22 23:02:15 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 490c1659-4aca-401f-bf9d-34891b18717a\n",
      "2025-10-22 23:02:15 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 490c1659-4aca-401f-bf9d-34891b18717a successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:15 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:16 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
      "2025-10-22 23:02:16 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 5 traces via send_callback\n",
      "2025-10-22 23:02:16 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 5 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:16 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:16 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 5 traces\n",
      "2025-10-22 23:02:16 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 5 traces via callback\n",
      "2025-10-22 23:02:17 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: c83bf958-6430-47bc-9407-5933e25f4892) - 1 spans\n",
      "2025-10-22 23:02:17 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: c83bf958-6430-47bc-9407-5933e25f4892) - 1 spans\n",
      "2025-10-22 23:02:17 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace c83bf958-6430-47bc-9407-5933e25f4892\n",
      "2025-10-22 23:02:17 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace c83bf958-6430-47bc-9407-5933e25f4892 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:17 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 3 samples\n",
      "2025-10-22 23:02:17 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 3it [00:11,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:17 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:18 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: eacc2b6e-8d42-4c12-82df-b0298723c50e) - 1 spans\n",
      "2025-10-22 23:02:18 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: eacc2b6e-8d42-4c12-82df-b0298723c50e) - 1 spans\n",
      "2025-10-22 23:02:18 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace eacc2b6e-8d42-4c12-82df-b0298723c50e\n",
      "2025-10-22 23:02:18 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace eacc2b6e-8d42-4c12-82df-b0298723c50e successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:18 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:19 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 1f3f745f-2735-4197-b27d-0e54cd4fdd9b) - 1 spans\n",
      "2025-10-22 23:02:19 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 1f3f745f-2735-4197-b27d-0e54cd4fdd9b) - 1 spans\n",
      "2025-10-22 23:02:19 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 1f3f745f-2735-4197-b27d-0e54cd4fdd9b\n",
      "2025-10-22 23:02:19 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 1f3f745f-2735-4197-b27d-0e54cd4fdd9b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:19 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:20 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 04df8130-9aa6-4c7c-b184-df6b8d827620) - 1 spans\n",
      "2025-10-22 23:02:20 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 04df8130-9aa6-4c7c-b184-df6b8d827620) - 1 spans\n",
      "2025-10-22 23:02:21 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 04df8130-9aa6-4c7c-b184-df6b8d827620\n",
      "2025-10-22 23:02:21 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 04df8130-9aa6-4c7c-b184-df6b8d827620 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:21 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 4 samples\n",
      "2025-10-22 23:02:21 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 4it [00:15,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:21 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:21 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.2s >= 5.0s)\n",
      "2025-10-22 23:02:21 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:02:21 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 25522bcf-a4e6-4f72-b6b1-be6e12c6b628) - 1 spans\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 25522bcf-a4e6-4f72-b6b1-be6e12c6b628) - 1 spans\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 25522bcf-a4e6-4f72-b6b1-be6e12c6b628\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:02:22 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 25522bcf-a4e6-4f72-b6b1-be6e12c6b628 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:22 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:23 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 8d0257b7-8b4a-43d2-b3f8-c331f9442e9a) - 1 spans\n",
      "2025-10-22 23:02:23 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 8d0257b7-8b4a-43d2-b3f8-c331f9442e9a) - 1 spans\n",
      "2025-10-22 23:02:23 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 8d0257b7-8b4a-43d2-b3f8-c331f9442e9a\n",
      "2025-10-22 23:02:23 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 8d0257b7-8b4a-43d2-b3f8-c331f9442e9a successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:23 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:26 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: df6eff5c-8fa9-4c0a-9f8b-4fb5eb71694a) - 1 spans\n",
      "2025-10-22 23:02:26 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: df6eff5c-8fa9-4c0a-9f8b-4fb5eb71694a) - 1 spans\n",
      "2025-10-22 23:02:26 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace df6eff5c-8fa9-4c0a-9f8b-4fb5eb71694a\n",
      "2025-10-22 23:02:26 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace df6eff5c-8fa9-4c0a-9f8b-4fb5eb71694a successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:26 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 5 samples\n",
      "2025-10-22 23:02:26 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 5it [00:21,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:26 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:27 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.9s >= 5.0s)\n",
      "2025-10-22 23:02:27 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 3 traces via send_callback\n",
      "2025-10-22 23:02:27 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 3 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:27 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:27 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 3 traces\n",
      "2025-10-22 23:02:27 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 3 traces via callback\n",
      "2025-10-22 23:02:28 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 9fca5686-3b49-4bba-961f-452fba26f5e6) - 1 spans\n",
      "2025-10-22 23:02:28 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 9fca5686-3b49-4bba-961f-452fba26f5e6) - 1 spans\n",
      "2025-10-22 23:02:28 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 9fca5686-3b49-4bba-961f-452fba26f5e6\n",
      "2025-10-22 23:02:28 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 9fca5686-3b49-4bba-961f-452fba26f5e6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:28 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:29 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: d7502a23-efaa-437e-ab40-138c0a1c3cc9) - 1 spans\n",
      "2025-10-22 23:02:29 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: d7502a23-efaa-437e-ab40-138c0a1c3cc9) - 1 spans\n",
      "2025-10-22 23:02:29 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace d7502a23-efaa-437e-ab40-138c0a1c3cc9\n",
      "2025-10-22 23:02:29 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace d7502a23-efaa-437e-ab40-138c0a1c3cc9 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:29 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:30 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 539d7f80-b556-441a-b288-08da522ef2ed) - 1 spans\n",
      "2025-10-22 23:02:30 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 539d7f80-b556-441a-b288-08da522ef2ed) - 1 spans\n",
      "2025-10-22 23:02:30 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 539d7f80-b556-441a-b288-08da522ef2ed\n",
      "2025-10-22 23:02:30 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 539d7f80-b556-441a-b288-08da522ef2ed successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:30 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 6 samples\n",
      "2025-10-22 23:02:30 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 6it [00:25,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:30 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:31 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f4853141-1b6b-493e-94c2-ebd82a327a63) - 1 spans\n",
      "2025-10-22 23:02:31 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f4853141-1b6b-493e-94c2-ebd82a327a63) - 1 spans\n",
      "2025-10-22 23:02:31 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f4853141-1b6b-493e-94c2-ebd82a327a63\n",
      "2025-10-22 23:02:31 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f4853141-1b6b-493e-94c2-ebd82a327a63 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:31 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:32 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.5s >= 5.0s)\n",
      "2025-10-22 23:02:32 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:02:32 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: dc0ec2ed-2ab0-4e6f-9005-08c47f6be881) - 1 spans\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: dc0ec2ed-2ab0-4e6f-9005-08c47f6be881) - 1 spans\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace dc0ec2ed-2ab0-4e6f-9005-08c47f6be881\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace dc0ec2ed-2ab0-4e6f-9005-08c47f6be881 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:33 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:33 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:02:33 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:02:34 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 6be3cc26-2f44-4534-8c17-af00776df15d) - 1 spans\n",
      "2025-10-22 23:02:34 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 6be3cc26-2f44-4534-8c17-af00776df15d) - 1 spans\n",
      "2025-10-22 23:02:34 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 6be3cc26-2f44-4534-8c17-af00776df15d\n",
      "2025-10-22 23:02:34 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 6be3cc26-2f44-4534-8c17-af00776df15d successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:34 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 7 samples\n",
      "2025-10-22 23:02:34 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 7it [00:28,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:34 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:36 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: d900cab2-2ff3-4c05-b0c0-7d5ed8303c40) - 1 spans\n",
      "2025-10-22 23:02:36 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: d900cab2-2ff3-4c05-b0c0-7d5ed8303c40) - 1 spans\n",
      "2025-10-22 23:02:36 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace d900cab2-2ff3-4c05-b0c0-7d5ed8303c40\n",
      "2025-10-22 23:02:36 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace d900cab2-2ff3-4c05-b0c0-7d5ed8303c40 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:36 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:37 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: 2337a5e3-f182-40a2-8172-7b973fd6f67f) - 1 spans\n",
      "2025-10-22 23:02:37 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: 2337a5e3-f182-40a2-8172-7b973fd6f67f) - 1 spans\n",
      "2025-10-22 23:02:37 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace 2337a5e3-f182-40a2-8172-7b973fd6f67f\n",
      "2025-10-22 23:02:37 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace 2337a5e3-f182-40a2-8172-7b973fd6f67f successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:37 - INFO - google_genai.models - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:38 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.4s >= 5.0s)\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 4 traces via send_callback\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 4 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 4 traces\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 4 traces via callback\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.http_transport - INFO - üì§ EXPORTING TRACE: auto_trace_generate (ID: f49c469d-893d-4a5a-8cf0-b5112321d143) - 1 spans\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.batch_processor - INFO - üì• ADDING TRACE TO QUEUE: auto_trace_generate (ID: f49c469d-893d-4a5a-8cf0-b5112321d143) - 1 spans\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully queued trace f49c469d-893d-4a5a-8cf0-b5112321d143\n",
      "2025-10-22 23:02:38 - noveum_trace.transport.http_transport - INFO - ‚úÖ Trace f49c469d-893d-4a5a-8cf0-b5112321d143 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:38 - INFO - novaeval.evaluators.agent_evaluator - Saving intermediate results after 8 samples\n",
      "2025-10-22 23:02:38 - INFO - novaeval.evaluators.agent_evaluator - Intermediate results saved to demo_results/agent.web_search_evaluation_metrics_dataset/agent_evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating samples: 8it [00:33,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:38 - INFO - novaeval.evaluators.agent_evaluator - Saving final results\n",
      "2025-10-22 23:02:38 - INFO - novaeval.evaluators.agent_evaluator - Reloaded 8 results from CSV\n",
      "2025-10-22 23:02:38 - INFO - novaeval.evaluators.agent_evaluator - Agent evaluation completed\n",
      "\n",
      "‚úÖ Evaluation completed!\n",
      "\n",
      "üìä Results Summary:\n",
      "  - task_progression: 3.75\n",
      "  - context_relevancy: 7.84\n",
      "  - role_adherence: 8.97\n",
      "  - tool_relevancy: 0.00\n",
      "  - parameter_correctness: 0.00\n",
      "\n",
      "üîç Individual Scores:\n",
      "\n",
      "  Record 1 (Task: eda4fe22-9a2b-4b73-856b-f4f3309bf719):\n",
      "    - task_progression: 4.2\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 2 (Task: 0ffffba1-8a37-443c-8866-d53ffbfa7718):\n",
      "    - task_progression: 3.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 3 (Task: 43cdf081-4f01-49cd-b566-dbd1619e6cd2):\n",
      "    - task_progression: 4.2\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 4 (Task: 9a1983f4-09da-4b53-80e6-38de6878e0e7):\n",
      "    - task_progression: 2.5\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 5 (Task: 5d2517e1-220a-429d-9d59-f701bda25eed):\n",
      "    - task_progression: 2.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 6 (Task: a81ca3a8-80aa-4c39-876e-8d40ea7a0aef):\n",
      "    - task_progression: 3.8\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 7 (Task: 230aad27-f3dd-4968-a45a-3c2f07ac28ed):\n",
      "    - task_progression: 4.2\n",
      "    - context_relevancy: 7.8\n",
      "    - role_adherence: 9.0\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "\n",
      "  Record 8 (Task: 83c7dcce-3d89-4da1-8b3f-d419885d4cbc):\n",
      "    - task_progression: 4.5\n",
      "    - context_relevancy: 8.1\n",
      "    - role_adherence: 8.8\n",
      "    - tool_relevancy: 0.0\n",
      "    - parameter_correctness: 0.0\n",
      "‚úÖ Evaluation completed successfully!\n",
      "\n",
      "üìã Step 7: Exporting Dataset\n",
      "üíæ Exporting processed dataset...\n",
      "‚úÖ Exported to ./processed_datasets/agent.web_search_evaluation_metrics_dataset_processed_dataset.json\n",
      "‚úÖ Exported to ./processed_datasets/agent.web_search_evaluation_metrics_dataset_processed_dataset.csv\n",
      "‚úÖ Export completed successfully!\n",
      "\n",
      "============================================================\n",
      "üéâ EVALUATION PIPELINE COMPLETED!\n",
      "üìä Final Results:\n",
      "  - File processed: split_datasets/agent.web_search_evaluation_metrics_dataset.json\n",
      "  - Spans loaded: 8\n",
      "  - Dataset size: 8\n",
      "  - Evaluation completed: True\n",
      "  - Export successful: True\n",
      "  - Results saved to: ./demo_results/agent.web_search_evaluation_metrics_dataset/\n",
      "Completed agent.web_search_evaluation_metrics_dataset.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 23:02:43 - noveum_trace.transport.batch_processor - INFO - ‚è∞ TIMEOUT TRIGGER: Sending batch due to timeout (5.1s >= 5.0s)\n",
      "2025-10-22 23:02:43 - noveum_trace.transport.batch_processor - INFO - üì§ SENDING BATCH: 1 traces via send_callback\n",
      "2025-10-22 23:02:43 - noveum_trace.transport.http_transport - INFO - üöÄ SENDING BATCH: 1 traces to https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:44 - noveum_trace.transport.http_transport - INFO - üì° HTTP RESPONSE: Status 200 from https://api.noveum.ai/api/v1/traces\n",
      "2025-10-22 23:02:44 - noveum_trace.transport.http_transport - INFO - ‚úÖ Successfully sent batch of 1 traces\n",
      "2025-10-22 23:02:44 - noveum_trace.transport.batch_processor - INFO - ‚úÖ Successfully sent batch of 1 traces via callback\n"
     ]
    }
   ],
   "source": [
    "from demo_utils import run_complete_agent_evaluation\n",
    "import os\n",
    "\n",
    "# Process all JSON files in split_datasets directory\n",
    "for file in os.listdir('split_datasets'):\n",
    "    if file.endswith('.json'):\n",
    "        print(f'Processing {file}...')\n",
    "        run_complete_agent_evaluation(\n",
    "            f'split_datasets/{file}', \n",
    "            sample_size=25, \n",
    "            evaluation_name=file.replace('.json', ''),\n",
    "            output_dir='./demo_results'\n",
    "        )\n",
    "        print(f'Completed {file}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f5ca2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created api_data.json with 20 items\n",
      "Sample items:\n",
      "  {'item_key': 'eda4fe22-9a2b-4b73-856b-f4f3309bf719', 'item_id': 'item_1'}\n",
      "  {'item_key': '0ffffba1-8a37-443c-8866-d53ffbfa7718', 'item_id': 'item_2'}\n",
      "  {'item_key': 'f1f37bd7-0851-4659-b493-b80d3800d920', 'item_id': 'item_3'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('demo_results/agent.query_routing_dataset/agent_evaluation_results.csv')\n",
    "\n",
    "# Create API data structure with all task_ids\n",
    "api_data = {\n",
    "    'items': [\n",
    "        {\n",
    "            'item_key': str(row['task_id']),\n",
    "            'item_id': f'item_{i+1}'  # Generate unique item IDs\n",
    "        }\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('api_data.json', 'w') as f:\n",
    "    json.dump(api_data, f, indent=2)\n",
    "\n",
    "print('Created api_data.json with', len(api_data['items']), 'items')\n",
    "print('Sample items:')\n",
    "for item in api_data['items'][:3]:\n",
    "    print(f'  {item}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06289a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables\n",
      "Loading API data from api_data.json...\n",
      "Loaded 20 item mappings\n",
      "Reading CSV from demo_results/agent.query_routing_dataset/agent_evaluation_results.csv...\n",
      "Read 20 rows from CSV\n",
      "Created 20 results for upload\n",
      "\n",
      "Uploading 20 results in 1 batches...\n",
      "‚úó Batch 1/1 failed: 201\n",
      "  Response: {\"success\":true,\"created\":20,\"failed\":0,\"results\":[{\"result_id\":\"c92dbfca-8820-45d4-be82-a970e7e45b14\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_1\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent's response should provide information about the latest breakthroughs in AI. Without seeing the actual response, it's impossible to confirm alignment with role and task. However, the premise indicates that the content should be factually correct and presented in an informative manner, suggesting an appropriate tone for the given role.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"0075462f-01a1-45b4-8113-007ae6fcde5d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_10\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's direct relevance is confirmed, matching the specified task. The alignment with the designated role is evident, and the tone and content are appropriate. There's a slight lack of demonstrating deeper understanding, which slightly reduces the score, but overall, it's well-executed and helpful.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"12ce4442-7cff-4e80-ba5b-7c9caa1cf2b0\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_11\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's direct relevance to the task is good, and it generally aligns with the agent's role. The tone and content are appropriate. However, without seeing the actual response, a slightly higher score is withheld as it's impossible to confirm the response's comprehensive understanding and perfect alignment with the task's requirements.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"f084daf2-094b-4a0d-98ee-8b67fcba5eec\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_12\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response appears helpful and relevant to the assigned task of configuring Noveum. It's aligned with the agent's role and expertise. The tone and content are appropriate. However, without the actual response, a definitive assessment of its quality and level of detail is impossible; hence, a slightly lower score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"ccdd6d5e-d882-4ea1-b957-5a99a62fbaab\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_13\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's relevance is good given the prompt, and the response is appropriate for the agent's designated role. The content's tone is also aligned with the task, and the response demonstrates good understanding of the task requirements. Further details could enhance the response.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"f530766b-4b3d-4186-a175-e9220af2bf74\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_14\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's relevance to the assigned task is clear, and it aligns well with the agent's role. The tone and content are appropriate. There's a solid understanding of the task requirements. The response is helpful. It could gain a higher score if it gives an answer.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"5cb29b73-a4f1-48b7-b215-f300fb850b51\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_15\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's relevance to the assigned task is clear, and it aligns well with the agent's specified role. The content and tone are suitable for the role. Demonstrating a more extensive understanding of available APIs in Noveum would improve the score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"df6a1c18-72cd-4ecf-a796-2970e989358b\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_16\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The response should directly address setting up observability with Noveum, which is highly relevant to the provided task. The response is likely aligned with the agent's role and expertise. Improvement could include a more helpful response, leading to a higher score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"eb68976c-4108-4800-af06-83e31f0ce74c\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_17\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's direct relevance is strong, fitting the task and agent role well. The content is suitable. While it efficiently addresses the query, there's room to further showcase the agent's expertise and provide a more comprehensive overview of Noveum Trace's features. A more elaborate answer could have improved the score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"5d535892-430c-4920-8a08-3a93431b032e\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_18\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's relevance to the assigned task is clear and aligns well with the agent's role. The tone and content are appropriate. However, without the actual response, it's impossible to gauge the depth of understanding or how helpful it is in completing the task, so the score is slightly adjusted.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"55439906-553e-4155-87d2-848d453689e2\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_19\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response would likely be directly relevant to the task if there was an actual response to evaluate. The prompt itself is designed to elicit a response about integrating Noveum Trace, aligning with the agent's expected role. Without a response, evaluating tone, content, and task understanding is impossible, but the prompt itself is well-suited.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"eb624892-309d-4359-bfa2-251303cc7351\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_2\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's direct relevance and its alignment with the agent's role are satisfactory. The tone and content are appropriate, showing understanding of the task. However, achieving a higher score requires a more detailed and insightful response on current trends, implying a need for better task completion progression.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"41801712-7f2a-40be-9d29-f614143c0989\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_20\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The response is relevant to the task of defining Noveum. It's well-aligned with the agent's role of providing information. The tone is appropriate. Demonstrating a slightly more detailed understanding of Noveum's function or purpose would elevate the score further, though the foundational elements of task completion are present.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"f507b5b0-399c-4eb6-befa-af29ff56a48d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_3\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The response should list the newest features in cloud computing based on the agent's task. It should be aligned with the agent's role as well as the expertise. The tone and content are appropriate for the role. Demonstrating a deeper understanding of the task requirements would be key to increase the score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"ff03a298-77c5-4785-8bd1-d5a19038e745\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_4\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent's response should provide real-time or recent information regarding the current status of the cryptocurrency markets. Given the task of providing market updates, the agent's response needs to be relevant and aligned with the role of an information provider. The score reflects a solid starting point but can improve through richer details.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"95f84560-319e-4a2c-ad3c-f0631a1bae56\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_5\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's direct relevance and role alignment is good. The tone and content are appropriate. However, the score could be higher if the response also demonstrated a helpful level of task understanding by providing specific examples or sources for the latest Python programming updates to aid task completion.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"3e2efda3-20a2-4f71-a6f8-430f50a454a6\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_6\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response, which is completely irrelevant and inappropriate. It fails to address the task of summarizing tech news and demonstrates no understanding of the requirements. Therefore, the score is significantly low, reflecting the complete lack of a meaningful answer.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"99f927fb-447b-4eaa-8413-76932289cc37\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_7\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent's response should provide a list of current trends in observability tools. This shows a good understanding of the task. The information should be factual and relevant. Its appropriateness hinges on the quality of the response, specifically the trends mentioned and their relevance in current times. A detailed response will increase the score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"a0c16e26-c4d0-4765-afe0-c9a007fd1481\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_8\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.5,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The response is relevant to the task of describing recent developments in machine learning, fitting the agent's role. The tone and content are appropriate. However, the depth of the response could be increased to demonstrate a stronger understanding of the current state of the field to get a better score.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"},{\"result_id\":\"696c0bee-158d-4134-8785-19503ec01da3\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_9\",\"scorer_id\":\"context_relevancy_scorer\",\"score\":7.8,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent response's relevance is good given the weather query. It's appropriately aligned with the role, providing information about the weather. The tone is suitable, indicating task understanding. To improve, it could offer a bit more detail, but overall it is a helpful start.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:06.219000000\",\"updated_at\":\"2025-10-22 18:01:06.219000000\",\"scorer_name\":\"Context Relevancy Scorer\"}]}\n",
      "\n",
      "Upload complete!\n"
     ]
    }
   ],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col context_relevancy --reasoning-col context_relevancy_reasoning --api-data api_data.json --scorer-id context_relevancy_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf96327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables\n",
      "Loading API data from api_data.json...\n",
      "Loaded 20 item mappings\n",
      "Reading CSV from demo_results/agent.query_routing_dataset/agent_evaluation_results.csv...\n",
      "Read 20 rows from CSV\n",
      "Created 20 results for upload\n",
      "\n",
      "Uploading 20 results in 1 batches...\n",
      "‚úó Batch 1/1 failed: 201\n",
      "  Response: {\"success\":true,\"created\":20,\"failed\":0,\"results\":[{\"result_id\":\"bcc832a3-fda1-4129-8988-5ba5a30ed2f0\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_1\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent completely fails to adhere to its role as it provided no response and made no tool calls. There is no evidence of an attempt to answer the question about AI breakthroughs. The agent's lack of any output indicates a total disregard for the task and role instructions.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"7f5cdc48-40bb-4944-ae1d-c4e9d3ace92d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_10\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent completely fails to adhere to its role. It provides no response or tool calls, indicating a complete inability to fulfill its assigned task of providing AI news. It acts inappropriately by failing to respond, showing no understanding or attempt to interact with any available tools.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"a862d4fb-240a-4682-b8f1-2f68eb386142\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_11\",\"scorer_id\":\"role_adherence_scorer\",\"score\":9,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role, providing a concise response about the benefits of using Noveum Trace. The absence of tool calls indicates no deviation from the provided context. The response is consistent, focused, and free of any role contradictions or inappropriate behaviors, demonstrating a strong understanding of its assigned task.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"e8604ecb-b171-45b0-aab3-1fa128c734e4\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_12\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response, and therefore failed to adhere to the role or address the task. It did not provide any information or utilize any tools. The lack of response demonstrates complete failure in understanding and executing the assigned instructions.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"b0ef13bb-bf66-47b9-9458-b5d52d1488fb\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_13\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The agent's response is relevant to its role and the tool calls are appropriate for this role and its task. The agent doesn't contradict its assigned task. No deviations or inconsistencies are observed.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"10dcd5c4-9fb7-4670-98a6-b858caacd938\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_14\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent completely fails to fulfill its role. The agent provides no response and makes no tool calls, indicating a complete disregard for the assigned task. There's no evidence of role adherence, task completion, or relevant information retrieval. The agent is inactive, rendering the evaluation impossible.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"fb9c6145-3e19-493a-808e-884484daf019\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_15\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The agent correctly identified that there were no tools calls, as it was a prompt and not a request for a specific action. The response is consistent with the expectations of the assigned role.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"0a8d4083-d2fe-4083-b161-e8fddd8f231f\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_16\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response or tool calls, therefore failing to adhere to any aspect of its role and task. It did not attempt to answer the question or make any progress towards the objective. The lack of any action completely contradicts the expectation for a helpful response.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"5dc8fa70-5bab-4697-81ea-745e24680c3d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_17\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The agent has not provided a response nor made any tool calls, which is the expected behavior given the prompt which instructed it to evaluate an agent's response. No deviations or contradictions were observed, maintaining complete consistency.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"7c645c45-f5a4-41a3-ab8f-51168c02856d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_18\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response, and made no tool calls, meaning the agent completely failed to fulfill its role or task. It did not try to answer the question about pricing plans or attempt any data analysis or retrieval. This constitutes a complete failure to adhere to the role.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"ca5a3ea3-7023-4a11-b12e-07bf43d91e4d\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_19\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response, meaning the agent failed at every aspect of its role. It did not provide a response, tool calls, or do anything to accomplish its assigned task. The agent completely ignored all instructions and failed to operate as requested. Therefore, the adherence score is very low.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"497d5631-bb51-415d-84b8-ea1d0669768c\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_2\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The response is consistent with expectations for the assigned role. The absence of any tool calls is acceptable as there is no requirement to make a tool call in this scenario, therefore the agent has no need to deviate from its role.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"2510458b-3a84-4f67-b3c6-8d55dfb2ba92\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_20\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task, maintaining consistency throughout. The absence of any tool calls implies that the agent may have responded directly with the answer to the question. This aligns well with the prompt, suggesting an exact response is expected given the lack of tool usage. No deviations from the role or inappropriate behaviors are observed.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"37bb1928-0b4e-4eff-9c9b-99c374df758a\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_3\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The absence of tool calls indicates that the agent knows to respond without them. The agent does not stray from the assigned task and provides an expected answer while acting appropriately as an agent.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"56b5f6b9-aa35-4c1e-9380-4f6e42d37ef6\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_4\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The absence of tool calls indicates no actions were taken, which aligns with the prompt requesting an evaluation without any tool usage. The response, while missing, doesn't deviate from the intended role of reporting current crypto market status. The consistency is flawless.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"00ffa56b-dee2-4798-adac-c9b67c04409b\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_5\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent provided no response and made no tool calls. This is a complete failure to adhere to the role and task. The agent should have provided some information, even if it had to use a tool to gather it. The lack of any output demonstrates a fundamental misunderstanding of the prompt's requirements.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"19e7022b-a731-4bb7-ba91-ea1f15acea19\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_6\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent completely fails to adhere to its role. It's supposed to summarize tech news but hasn't provided any information or made any tool calls. Its response is blank, and thus it cannot fulfill its assigned task. There are significant role contradictions and inappropriate behaviors due to this complete lack of output.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"1855df2f-4341-4e34-b02b-70b4f0844690\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_7\",\"scorer_id\":\"role_adherence_scorer\",\"score\":1,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent completely fails to adhere to its assigned role or perform the task. No tool calls were made, indicating a complete lack of engagement with the prompt. There is no information provided about the current trends in observability tools, directly contradicting the instructions. The agent fails at all aspects of the evaluation.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"13771286-0139-4c43-9287-c3290f402da1\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_8\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The response is consistent with the role of machine learning expert. The agent appropriately answers the prompt, delivering a relevant overview. No tool calls were made, suggesting that the agent could answer the query without external assistance, which aligns with perfect role adherence.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"},{\"result_id\":\"a66d4346-5a43-4b06-a269-216bcc40f03e\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_9\",\"scorer_id\":\"role_adherence_scorer\",\"score\":10,\"passed\":1,\"metadata\":\"{\\\"details\\\":\\\"The agent perfectly adheres to its role and task. The agent correctly executes its role and the tool calls are appropriate for retrieving information about the weather, as intended. The response is consistent with the role and task requirements, showing no contradictions or inappropriate behaviors. The agent demonstrates flawless adherence.\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:01:48.477000000\",\"updated_at\":\"2025-10-22 18:01:48.477000000\",\"scorer_name\":\"Role Adherence Scorer\"}]}\n",
      "\n",
      "Upload complete!\n"
     ]
    }
   ],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col role_adherence --reasoning-col role_adherence_reasoning --api-data api_data.json --scorer-id role_adherence_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08f948b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables\n",
      "Loading API data from api_data.json...\n",
      "Loaded 20 item mappings\n",
      "Reading CSV from demo_results/agent.query_routing_dataset/agent_evaluation_results.csv...\n",
      "Read 20 rows from CSV\n",
      "Created 20 results for upload\n",
      "\n",
      "Uploading 20 results in 1 batches...\n",
      "‚úó Batch 1/1 failed: 201\n",
      "  Response: {\"success\":true,\"created\":20,\"failed\":0,\"results\":[{\"result_id\":\"35b42464-7989-4caa-90cb-5636319d4fd1\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_1\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"28380f39-f4e4-41a3-a5c7-01241174fb78\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_10\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"f1ea8545-c1ab-4791-958b-04d3c75cf92a\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_11\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"db8c7724-19ca-46c6-8c6b-796f229279e4\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_12\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"86929a3d-38c7-4bcf-8c40-820f3d9e69ef\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_13\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"068aaa68-b454-47db-854d-c09b87d33ec9\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_14\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"b80aac89-5007-412c-a372-d7a80703ec0f\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_15\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"07585067-3e96-4491-8f4b-a4fa89b80493\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_16\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"172395b1-bd1d-43dd-9359-51854355376b\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_17\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"a54ae11d-5232-4434-b704-1a5f8b327ee7\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_18\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"61847a0c-de20-4e36-abd0-2067bb210207\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_19\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"70f241a7-05cc-47df-8bc3-2eb3b428d064\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_2\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"1b5c2018-e801-4ac1-98e9-8dab56fa19ed\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_20\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"65aa0719-a555-4fae-8203-d3f06bcd0f5e\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_3\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"5e710451-f3d1-4d35-8ed2-8c6b54a46ccb\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_4\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"1db2a945-e30a-43ee-b591-c98dbe004f47\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_5\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"297fadf1-51fa-43e7-91cc-58b783550d3b\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_6\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"f00da0b9-f3df-4055-9507-0b4b9ae31501\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_7\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"3f9733b7-23b3-4396-84a6-5f87146cb0a2\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_8\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"},{\"result_id\":\"c6629883-f239-4b64-ba54-2fe517d25551\",\"organization_slug\":\"magic-api\",\"dataset_slug\":\"customersupportagentdemo-new\",\"item_id\":\"item_9\",\"scorer_id\":\"parameter_correctness_scorer\",\"score\":0,\"passed\":0,\"metadata\":\"{\\\"details\\\":\\\"Error: Missing required fields: ['tool_calls'], out of all required fields: ['tool_calls', 'parameters_passed', 'tool_call_results']\\\"}\",\"error\":\"\",\"execution_time_ms\":0,\"created_at\":\"2025-10-22 18:03:01.353000000\",\"updated_at\":\"2025-10-22 18:03:01.353000000\",\"scorer_name\":\"Parameter Correctness Scorer\"}]}\n",
      "\n",
      "Upload complete!\n"
     ]
    }
   ],
   "source": [
    "!python upload_scores.py demo_results/agent.query_routing_dataset/agent_evaluation_results.csv --item-key-col task_id --score-col parameter_correctness --reasoning-col parameter_correctness_reasoning --api-data api_data.json --scorer-id parameter_correctness_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83466df7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
