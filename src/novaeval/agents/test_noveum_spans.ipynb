{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Noveum Spans Dataset Testing\n",
        "\n",
        "This notebook tests the `noveum_spans_dataset.py` functionality with Noveum trace JSON files.\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Configuration\n",
        "Set your JSON file path here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set your JSON file path here\n",
        "JSON_FILE_PATH = \"/mnt/drive2/trace_details.json\"  # Update this path\n",
        "\n",
        "# Output paths\n",
        "OUTPUT_CSV = \"/mnt/drive2/noveum_spans_output.csv\"\n",
        "CHUNK_SIZE = 2  # For streaming test\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Import and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Add the parent directory to the path to import noveum_spans_dataset\n",
        "sys.path.append(os.path.dirname(os.getcwd()))\n",
        "\n",
        "from noveum_spans_dataset import noveum_spans_preprocessing, create_dataset, stream_dataset\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 3. Check JSON File Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ JSON file found: /mnt/drive2/trace_details.json\n",
            "\n",
            "Trace ID: 2d842385-2baa-40f3-8e12-9a7da4240d17\n",
            "Number of spans: 8\n",
            "Trace name: test_research_workflow_openai_gpt-3.5-turbo\n",
            "\n",
            "First span:\n",
            "  - Span ID: f2d9563d-6a0b-4ff6-b46f-330c1cdf9b07\n",
            "  - Name: agent:research_coordinator:research_coordinator\n",
            "  - Status: ok\n",
            "  - Duration: 1801.633 ms\n",
            "  - Function name: research_coordinator\n",
            "  - Input fields: ['agent.input.research_topic']\n"
          ]
        }
      ],
      "source": [
        "# Check if file exists and preview its structure\n",
        "if os.path.exists(JSON_FILE_PATH):\n",
        "    print(f\"✓ JSON file found: {JSON_FILE_PATH}\")\n",
        "    \n",
        "    # Load and preview the JSON structure\n",
        "    with open(JSON_FILE_PATH, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"\\nTrace ID: {data.get('trace_id')}\")\n",
        "    print(f\"Number of spans: {len(data.get('spans', []))}\")\n",
        "    print(f\"Trace name: {data.get('name')}\")\n",
        "    \n",
        "    # Preview first span\n",
        "    if data.get('spans'):\n",
        "        first_span = data['spans'][0]\n",
        "        print(f\"\\nFirst span:\")\n",
        "        print(f\"  - Span ID: {first_span.get('span_id')}\")\n",
        "        print(f\"  - Name: {first_span.get('name')}\")\n",
        "        print(f\"  - Status: {first_span.get('status')}\")\n",
        "        print(f\"  - Duration: {first_span.get('duration_ms')} ms\")\n",
        "        \n",
        "        # Check attributes\n",
        "        attributes = first_span.get('attributes', {})\n",
        "        print(f\"  - Function name: {attributes.get('function.name')}\")\n",
        "        \n",
        "        # Check for input fields\n",
        "        input_fields = [k for k in attributes.keys() if k.startswith('agent.input.') or k.startswith('tool.input.')]\n",
        "        print(f\"  - Input fields: {input_fields}\")\n",
        "        \n",
        "else:\n",
        "    print(f\"❌ JSON file not found: {JSON_FILE_PATH}\")\n",
        "    print(\"Please update the JSON_FILE_PATH variable above.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 4. Test Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing noveum_spans_preprocessing...\n",
            "Processing /mnt/drive2/trace_details.json\n",
            "Processed 8 spans and saved to /mnt/drive2/noveum_spans_output.csv\n",
            "✓ Preprocessing completed successfully!\n",
            "\n",
            "Output CSV created with 8 rows\n",
            "Columns: ['turn_id', 'agent_name', 'agent_task', 'agent_response', 'metadata', 'trace_id', 'span_name', 'status', 'start_time', 'end_time', 'attributes']\n",
            "\n",
            "First few rows:\n",
            "                                turn_id            agent_name  \\\n",
            "0  f2d9563d-6a0b-4ff6-b46f-330c1cdf9b07  research_coordinator   \n",
            "1  d33dba4a-dc67-46ae-9836-ac49ed938c6f          search_agent   \n",
            "2  f1e4204b-9cbb-4322-9ba0-cfada1607da7       web_search_tool   \n",
            "3  8387dbbd-9923-4299-aef9-62a60b0e4c70  academic_search_tool   \n",
            "4  7826fa8a-3534-4206-a336-d15fe41ae35a        analysis_agent   \n",
            "\n",
            "                                          agent_task status  \n",
            "0              artificial intelligence in healthcare     ok  \n",
            "1                                                NaN     ok  \n",
            "2              artificial intelligence in healthcare     ok  \n",
            "3              artificial intelligence in healthcare     ok  \n",
            "4  [{'title': 'Understanding artificial intellige...     ok  \n"
          ]
        }
      ],
      "source": [
        "# Test the preprocessing function\n",
        "print(\"Testing noveum_spans_preprocessing...\")\n",
        "\n",
        "try:\n",
        "    noveum_spans_preprocessing(\n",
        "        json_files=[JSON_FILE_PATH],\n",
        "        output_csv=OUTPUT_CSV\n",
        "    )\n",
        "    print(\"✓ Preprocessing completed successfully!\")\n",
        "    \n",
        "    # Check the output CSV\n",
        "    if os.path.exists(OUTPUT_CSV):\n",
        "        df = pd.read_csv(OUTPUT_CSV)\n",
        "        print(f\"\\nOutput CSV created with {len(df)} rows\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "        \n",
        "        # Show first few rows\n",
        "        print(\"\\nFirst few rows:\")\n",
        "        print(df[['turn_id', 'agent_name', 'agent_task', 'status']].head())\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during preprocessing: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 5. Test Dataset Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing create_dataset...\n",
            "✓ Dataset created successfully!\n",
            "\n",
            "Dataset info:\n",
            "Number of records: 8\n",
            "\n",
            "First record:\n",
            "  - Turn ID: f2d9563d-6a0b-4ff6-b46f-330c1cdf9b07\n",
            "  - Agent name: research_coordinator\n",
            "  - Agent role: coordinator\n",
            "  - Task: artificial intelligence in healthcare\n",
            "  - Response: {'topic': 'artificial intelligence in healthcare', 'search_results': [{'title': 'Understanding artif...\n",
            "  - Metadata keys: ['trace_id', 'duration_ms', 'parent_span_id', 'status_message', 'agent_type', 'span_name', 'status', 'start_time', 'end_time']\n"
          ]
        }
      ],
      "source": [
        "# Test creating a dataset from the CSV\n",
        "print(\"Testing create_dataset...\")\n",
        "\n",
        "try:\n",
        "    dataset = create_dataset(OUTPUT_CSV)\n",
        "    print(\"✓ Dataset created successfully!\")\n",
        "    \n",
        "    # Check dataset properties\n",
        "    print(f\"\\nDataset info:\")\n",
        "    print(f\"Number of records: {len(dataset.data)}\")\n",
        "    \n",
        "    if dataset.data:\n",
        "        first_record = dataset.data[0]\n",
        "        print(f\"\\nFirst record:\")\n",
        "        print(f\"  - Turn ID: {first_record.turn_id}\")\n",
        "        print(f\"  - Agent name: {first_record.agent_name}\")\n",
        "        print(f\"  - Agent role: {first_record.agent_role}\")\n",
        "        print(f\"  - Task: {first_record.agent_task[:100]}...\") if len(first_record.agent_task) > 100 else print(f\"  - Task: {first_record.agent_task}\")\n",
        "        print(f\"  - Response: {first_record.agent_response[:100]}...\") if len(first_record.agent_response) > 100 else print(f\"  - Response: {first_record.agent_response}\")\n",
        "        \n",
        "        # Check metadata\n",
        "        if first_record.metadata:\n",
        "            metadata = json.loads(first_record.metadata)\n",
        "            print(f\"  - Metadata keys: {list(metadata.keys())}\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating dataset: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 6. Test Streaming Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing stream_dataset with chunk_size=2...\n",
            "\n",
            "Chunk 1: 2 records\n",
            "  Record 1:\n",
            "    - Turn ID: f2d9563d-6a0b-4ff6-b46f-330c1cdf9b07\n",
            "    - Agent: research_coordinator\n",
            "    - Role: coordinator\n",
            "    - Task: artificial intelligence in healthcare\n",
            "  Record 2:\n",
            "    - Turn ID: d33dba4a-dc67-46ae-9836-ac49ed938c6f\n",
            "    - Agent: search_agent\n",
            "    - Role: researcher\n",
            "    - Task: nan\n",
            "\n",
            "Chunk 2: 2 records\n",
            "\n",
            "Chunk 3: 2 records\n",
            "\n",
            "Chunk 4: 2 records\n",
            "\n",
            "✓ Streaming completed!\n",
            "Total chunks: 4\n",
            "Total records: 8\n"
          ]
        }
      ],
      "source": [
        "# Test streaming the dataset with chunk size 2\n",
        "print(f\"Testing stream_dataset with chunk_size={CHUNK_SIZE}...\")\n",
        "\n",
        "try:\n",
        "    chunk_count = 0\n",
        "    total_records = 0\n",
        "    \n",
        "    for chunk in stream_dataset(OUTPUT_CSV, chunk_size=CHUNK_SIZE):\n",
        "        chunk_count += 1\n",
        "        chunk_size_actual = len(chunk)\n",
        "        total_records += chunk_size_actual\n",
        "        \n",
        "        print(f\"\\nChunk {chunk_count}: {chunk_size_actual} records\")\n",
        "        \n",
        "        # Show details for first chunk\n",
        "        if chunk_count == 1:\n",
        "            for i, record in enumerate(chunk):\n",
        "                print(f\"  Record {i+1}:\")\n",
        "                print(f\"    - Turn ID: {record.turn_id}\")\n",
        "                print(f\"    - Agent: {record.agent_name}\")\n",
        "                print(f\"    - Role: {record.agent_role}\")\n",
        "                task_preview = record.agent_task[:50] + \"...\" if len(record.agent_task) > 50 else record.agent_task\n",
        "                print(f\"    - Task: {task_preview}\")\n",
        "        \n",
        "        # Limit output for large datasets\n",
        "        if chunk_count >= 5:\n",
        "            print(f\"\\n... (showing first 5 chunks only)\")\n",
        "            # Continue counting without printing\n",
        "            remaining_chunks = list(stream_dataset(OUTPUT_CSV, chunk_size=CHUNK_SIZE))[5:]\n",
        "            for remaining_chunk in remaining_chunks:\n",
        "                chunk_count += 1\n",
        "                total_records += len(remaining_chunk)\n",
        "            break\n",
        "    \n",
        "    print(f\"\\n✓ Streaming completed!\")\n",
        "    print(f\"Total chunks: {chunk_count}\")\n",
        "    print(f\"Total records: {total_records}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error during streaming: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 7. Validation and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data Analysis:\n",
            "\n",
            "Unique agent names: 8\n",
            "Agent name distribution:\n",
            "agent_name\n",
            "research_coordinator    1\n",
            "search_agent            1\n",
            "web_search_tool         1\n",
            "academic_search_tool    1\n",
            "analysis_agent          1\n",
            "llm_analysis_call       1\n",
            "summary_agent           1\n",
            "llm_summary_call        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Status distribution:\n",
            "status\n",
            "ok    8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Empty agent_task fields: 1\n",
            "Empty agent_response fields: 0\n",
            "\n",
            "Sample of different span types:\n",
            "\n",
            "research_coordinator:\n",
            "  Span name: agent:research_coordinator:research_coordinator\n",
            "  Task: artificial intelligence in healthcare\n",
            "  Response length: 1000 chars\n",
            "\n",
            "search_agent:\n",
            "  Span name: agent:search_agent:search_agent\n",
            "  Task: nan\n",
            "  Response length: 1000 chars\n",
            "\n",
            "web_search_tool:\n",
            "  Span name: tool:web_search:web_search_tool\n",
            "  Task: artificial intelligence in healthcare\n",
            "  Response length: 632 chars\n",
            "\n",
            "academic_search_tool:\n",
            "  Span name: tool:academic_search:academic_search_tool\n",
            "  Task: artificial intelligence in healthcare\n",
            "  Response length: 414 chars\n",
            "\n",
            "analysis_agent:\n",
            "  Span name: agent:analysis_agent:analysis_agent\n",
            "  Task: [{'title': 'Understanding artificial intelligence in healthcare: A Comprehensive Guide', 'url': 'htt...\n",
            "  Response length: 746 chars\n"
          ]
        }
      ],
      "source": [
        "# Analyze the processed data\n",
        "print(\"Data Analysis:\")\n",
        "\n",
        "if os.path.exists(OUTPUT_CSV):\n",
        "    df = pd.read_csv(OUTPUT_CSV)\n",
        "    \n",
        "    print(f\"\\nUnique agent names: {df['agent_name'].nunique()}\")\n",
        "    print(\"Agent name distribution:\")\n",
        "    print(df['agent_name'].value_counts())\n",
        "    \n",
        "    print(f\"\\nStatus distribution:\")\n",
        "    print(df['status'].value_counts())\n",
        "    \n",
        "    # Check for empty fields\n",
        "    print(f\"\\nEmpty agent_task fields: {df['agent_task'].isna().sum() + (df['agent_task'] == '').sum()}\")\n",
        "    print(f\"Empty agent_response fields: {df['agent_response'].isna().sum() + (df['agent_response'] == '').sum()}\")\n",
        "    \n",
        "    # Show a sample of different span types\n",
        "    print(f\"\\nSample of different span types:\")\n",
        "    unique_names = df['agent_name'].unique()[:5]\n",
        "    for name in unique_names:\n",
        "        sample = df[df['agent_name'] == name].iloc[0]\n",
        "        print(f\"\\n{name}:\")\n",
        "        print(f\"  Span name: {sample['span_name']}\")\n",
        "        print(f\"  Task: {sample['agent_task'][:100]}...\") if len(str(sample['agent_task'])) > 100 else print(f\"  Task: {sample['agent_task']}\")\n",
        "        print(f\"  Response length: {len(str(sample['agent_response']))} chars\")\n",
        "        \n",
        "else:\n",
        "    print(\"❌ Output CSV not found\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 8. Cleanup (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing completed!\n"
          ]
        }
      ],
      "source": [
        "# Uncomment the line below to clean up the output CSV file\n",
        "# os.remove(OUTPUT_CSV)\n",
        "# print(f\"Cleaned up {OUTPUT_CSV}\")\n",
        "\n",
        "print(\"Testing completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
