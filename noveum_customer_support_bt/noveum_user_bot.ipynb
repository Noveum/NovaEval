{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780ff8d0",
   "metadata": {},
   "source": [
    "# Noveum AI Agent with RAG + Web Search\n",
    "\n",
    "An intelligent conversational agent that dynamically routes queries between **RAG (Retrieval-Augmented Generation)** for Noveum.ai-specific information and **Web Search** for external knowledge, providing comprehensive answers with full observability.\n",
    "\n",
    "## ðŸš€ What This Agent Does\n",
    "\n",
    "### Core Functionality\n",
    "- **Intelligent Query Routing**: Automatically determines whether to use RAG or Web Search based on query content\n",
    "- **Dual Knowledge Sources**: \n",
    "  - **RAG Mode**: Answers questions about Noveum.ai platform using scraped documentation\n",
    "  - **Web Search Mode**: Handles external queries using real-time web search\n",
    "- **Comprehensive Tracing**: Full observability with detailed metrics and performance tracking\n",
    "- **Modular Architecture**: Clean separation of concerns for easy maintenance and extension\n",
    "\n",
    "### Key Capabilities\n",
    "- ðŸ§  **Document Intelligence**: Scrapes and indexes Noveum.ai website content for semantic search\n",
    "- ðŸŒ **Real-time Web Search**: Uses DuckDuckGo for current events and external knowledge\n",
    "- ðŸŽ¯ **Smart Classification**: LLM-powered query routing with keyword fallback\n",
    "- ðŸ“Š **Performance Monitoring**: Detailed metrics on response quality, latency, and token usage\n",
    "- ðŸ”„ **Scalable Design**: Easy to extend with new data sources or routing logic\n",
    "\n",
    "## ðŸ“‹ Prerequisites & Requirements\n",
    "\n",
    "### Required Environment Variables\n",
    "```bash\n",
    "NOVEUM_API_KEY=your_noveum_api_key_here\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "```\n",
    "\n",
    "### Required Python Packages\n",
    "- `requests` - HTTP requests for web scraping\n",
    "- `beautifulsoup4` - HTML parsing\n",
    "- `trafilatura` - Advanced text extraction\n",
    "- `langchain` - LLM framework and vector operations\n",
    "- `langchain-openai` - OpenAI integration\n",
    "- `langchain-community` - Community tools (FAISS, DuckDuckGo)\n",
    "- `noveum-trace` - Observability and tracing\n",
    "- `python-dotenv` - Environment variable management\n",
    "\n",
    "### System Requirements\n",
    "- Python 3.8+\n",
    "- Internet connection for web scraping and API calls\n",
    "- ~500MB disk space for vector store and scraped data\n",
    "\n",
    "## ðŸ—ï¸ Architecture Overview\n",
    "\n",
    "### 1. **Website Scraper** (`NoveumWebsiteScraper`)\n",
    "- Recursively scrapes noveum.ai website and sub-pages\n",
    "- Extracts clean text content using trafilatura\n",
    "- Discovers internal links automatically\n",
    "- Saves scraped data to JSON for persistence\n",
    "\n",
    "### 2. **RAG System** (`NoveumRAGSystem`)\n",
    "- Loads scraped documents and creates vector embeddings\n",
    "- Uses FAISS for fast similarity search\n",
    "- Generates context-aware responses using OpenAI GPT-4o-mini\n",
    "- Tracks retrieval effectiveness and response quality\n",
    "\n",
    "### 3. **Web Search System** (`NoveumWebSearchSystem`)\n",
    "- Integrates DuckDuckGo search for external queries\n",
    "- Synthesizes information from multiple web sources\n",
    "- Handles real-time information and current events\n",
    "- Formats search results into coherent responses\n",
    "\n",
    "### 4. **Query Router** (`NoveumQueryRouter`)\n",
    "- **Keyword-based classification**: Matches queries against predefined keyword lists\n",
    "- **LLM-based classification**: Uses GPT-4o-mini for complex query analysis\n",
    "- **Confidence scoring**: Evaluates routing decision quality\n",
    "- **Fallback handling**: Defaults to Web Search for ambiguous queries\n",
    "\n",
    "### 5. **Main Agent** (`NoveumAIAgent`)\n",
    "- Orchestrates all components\n",
    "- Manages system initialization and data loading\n",
    "- Provides unified interface for query processing\n",
    "- Handles error recovery and response formatting\n",
    "\n",
    "## ðŸŽ¯ How to Use\n",
    "\n",
    "### Quick Start\n",
    "```python\n",
    "# 1. Initialize the system (first time only)\n",
    "noveum_agent.initialize_system(force_scrape=True)\n",
    "\n",
    "# 2. Ask questions\n",
    "response = noveum_agent.process_query(\"What is Noveum and what does it do?\")\n",
    "noveum_agent.display_response(response)\n",
    "\n",
    "# 3. Or use convenience function\n",
    "ask_question(\"How do I integrate Noveum Trace?\")\n",
    "```\n",
    "\n",
    "### Advanced Usage\n",
    "```python\n",
    "# Run full demo with 20 test queries\n",
    "demo_noveum_agent()\n",
    "\n",
    "# Process queries programmatically\n",
    "response = noveum_agent.process_query(\"What are the latest AI news?\")\n",
    "print(f\"Mode: {response['mode']}\")\n",
    "print(f\"Answer: {response['answer']}\")\n",
    "print(f\"Sources: {response['sources']}\")\n",
    "```\n",
    "\n",
    "### Query Types\n",
    "\n",
    "#### RAG Queries (Noveum-specific)\n",
    "- \"What is Noveum and what does it do?\"\n",
    "- \"How do I integrate Noveum Trace?\"\n",
    "- \"What are Noveum's pricing plans?\"\n",
    "- \"What features does Noveum Trace offer?\"\n",
    "- \"How do I set up observability with Noveum?\"\n",
    "\n",
    "#### Web Search Queries (External knowledge)\n",
    "- \"What are the latest AI news today?\"\n",
    "- \"What's the weather like today?\"\n",
    "- \"Tell me about recent developments in machine learning\"\n",
    "- \"What are the current trends in observability tools?\"\n",
    "- \"What happened in tech news this week?\"\n",
    "\n",
    "## ðŸ“Š Observability & Monitoring\n",
    "\n",
    "### Traced Operations\n",
    "- **System Initialization**: Website scraping and vector store creation\n",
    "- **Query Processing**: End-to-end query handling with performance metrics\n",
    "- **RAG Operations**: Document retrieval, context generation, and response creation\n",
    "- **Web Search Operations**: Search execution, result synthesis, and response generation\n",
    "- **Query Routing**: Classification decision making and confidence scoring\n",
    "\n",
    "### Key Metrics Tracked\n",
    "- **Performance**: Response latency, processing time, token usage\n",
    "- **Quality**: Response length, source diversity, context utilization\n",
    "- **Routing**: Classification confidence, keyword scores, decision rationale\n",
    "- **Model Usage**: Token consumption, cost estimation, efficiency scores\n",
    "- **Retrieval**: Document relevance, context quality, source effectiveness\n",
    "\n",
    "### Noveum Trace Integration\n",
    "- All operations are automatically traced with detailed spans\n",
    "- Comprehensive attribute tracking for debugging and optimization\n",
    "- Real-time monitoring through Noveum.ai dashboard\n",
    "- Export capabilities for further analysis\n",
    "\n",
    "## ðŸ”§ Configuration\n",
    "\n",
    "### Default Settings\n",
    "```python\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Customization Options\n",
    "- **Scraping**: Adjust `max_pages_to_scrape` for more/less content\n",
    "- **RAG**: Modify `chunk_size` and `chunk_overlap` for different text splitting\n",
    "- **Search**: Change `max_search_results` for more/fewer sources\n",
    "- **Routing**: Add keywords to `rag_keywords` or `web_keywords` lists\n",
    "\n",
    "## ðŸš¨ Error Handling\n",
    "\n",
    "### Common Issues\n",
    "- **API Key Missing**: Ensure `NOVEUM_API_KEY` and `OPENAI_API_KEY` are set\n",
    "- **Network Errors**: Check internet connection for scraping and API calls\n",
    "- **Vector Store Issues**: Delete `noveum_vectorstore` folder to regenerate\n",
    "- **Scraping Failures**: Set `force_scrape=True` to re-scrape website\n",
    "\n",
    "### Recovery Strategies\n",
    "- Automatic fallback to Web Search for RAG failures\n",
    "- Graceful error handling with informative messages\n",
    "- Retry mechanisms for transient network issues\n",
    "- Detailed error logging for debugging\n",
    "\n",
    "## ðŸ”„ Maintenance\n",
    "\n",
    "### Regular Tasks\n",
    "- **Update Scraped Content**: Run with `force_scrape=True` periodically\n",
    "- **Monitor Performance**: Check Noveum Trace dashboard for metrics\n",
    "- **Review Routing**: Analyze query classification accuracy\n",
    "- **Update Keywords**: Add new terms to routing keyword lists\n",
    "\n",
    "### Scaling Considerations\n",
    "- **Vector Store**: Can be shared across multiple agent instances\n",
    "- **Scraped Data**: JSON file can be versioned and distributed\n",
    "- **API Limits**: Monitor OpenAI token usage and costs\n",
    "- **Performance**: Consider caching for frequently asked questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "88c54bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=48009) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 4)) (4.12.3)\n",
      "Requirement already satisfied: python-dotenv==1.0.1 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: langchain==0.3.26 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.3.26)\n",
      "Requirement already satisfied: langchain-community==0.3.18 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (0.3.18)\n",
      "Requirement already satisfied: langchain-core==0.3.66 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 10)) (0.3.66)\n",
      "Requirement already satisfied: langchain-openai==0.3.25 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (0.3.25)\n",
      "Requirement already satisfied: trafilatura>=1.6.4 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (2.0.0)\n",
      "Requirement already satisfied: lxml>=5.3.0 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 15)) (5.4.0)\n",
      "Requirement already satisfied: faiss-cpu==1.12.0 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 18)) (1.12.0)\n",
      "Requirement already satisfied: duckduckgo-search>=6.1.12 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 22)) (8.1.1)\n",
      "Requirement already satisfied: pandas>=2.2.3 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 25)) (2.3.3)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 26)) (4.67.1)\n",
      "Requirement already satisfied: noveum_trace>=0.3.5 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 29)) (0.3.8)\n",
      "Requirement already satisfied: jupyter==1.0.0 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.0.0)\n",
      "Requirement already satisfied: ipykernel==6.29.4 in ./.venv/lib/python3.12/site-packages (from -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (6.29.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests==2.32.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 3)) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4==4.12.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 4)) (2.8)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (2.11.10)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (3.13.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (0.4.2)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (2.3.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core==0.3.66->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 10)) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core==0.3.66->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 10)) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core==0.3.66->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 10)) (4.15.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./.venv/lib/python3.12/site-packages (from langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.12/site-packages (from langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (0.12.0)\n",
      "Requirement already satisfied: notebook in ./.venv/lib/python3.12/site-packages (from jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (7.4.7)\n",
      "Requirement already satisfied: qtconsole in ./.venv/lib/python3.12/site-packages (from jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (5.7.0)\n",
      "Requirement already satisfied: jupyter-console in ./.venv/lib/python3.12/site-packages (from jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in ./.venv/lib/python3.12/site-packages (from jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (7.16.6)\n",
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.12/site-packages (from jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (8.1.7)\n",
      "Requirement already satisfied: appnope in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (1.8.17)\n",
      "Requirement already satisfied: ipython>=7.23.1 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (9.6.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (1.6.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv/lib/python3.12/site-packages (from ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (5.14.3)\n",
      "Requirement already satisfied: courlan>=1.3.2 in ./.venv/lib/python3.12/site-packages (from trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=1.9.2 in ./.venv/lib/python3.12/site-packages (from trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (1.9.3)\n",
      "Requirement already satisfied: justext>=3.0.1 in ./.venv/lib/python3.12/site-packages (from trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (3.0.2)\n",
      "Requirement already satisfied: click>=8.1.8 in ./.venv/lib/python3.12/site-packages (from duckduckgo-search>=6.1.12->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 22)) (8.3.0)\n",
      "Requirement already satisfied: primp>=0.15.0 in ./.venv/lib/python3.12/site-packages (from duckduckgo-search>=6.1.12->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 22)) (0.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 25)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 25)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 25)) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (1.22.0)\n",
      "Requirement already satisfied: babel>=2.16.0 in ./.venv/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in ./.venv/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (0.13.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in ./.venv/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (1.2.2)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.6.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.66->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (4.4.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (0.11.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.3->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 25)) (1.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.25->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 11)) (2025.9.18)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv/lib/python3.12/site-packages (from ipywidgets->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv/lib/python3.12/site-packages (from ipywidgets->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (3.0.15)\n",
      "Requirement already satisfied: bleach!=5.0.0 in ./.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (3.1.6)\n",
      "Requirement already satisfied: jupyterlab-pygments in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (3.0.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.10.2)\n",
      "Requirement already satisfied: nbformat>=5.7 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in ./.venv/lib/python3.12/site-packages (from nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.5.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in ./.venv/lib/python3.12/site-packages (from notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.17.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in ./.venv/lib/python3.12/site-packages (from notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.9 in ./.venv/lib/python3.12/site-packages (from notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (4.4.9)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in ./.venv/lib/python3.12/site-packages (from notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.2.4)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in ./.venv/lib/python3.12/site-packages (from qtconsole->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.4.3)\n",
      "Requirement already satisfied: webencodings in ./.venv/lib/python3.12/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from bleach[css]!=5.0.0->nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.4.0)\n",
      "Requirement already satisfied: tzlocal>=0.2 in ./.venv/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (5.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain==0.3.26->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 8)) (0.16.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.8.5)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (25.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.5.3)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.23.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in ./.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.9.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in ./.venv/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.0.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in ./.venv/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.3.0)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in ./.venv/lib/python3.12/site-packages (from jupyterlab<4.5,>=4.4.9->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (80.9.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in ./.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.12.1)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in ./.venv/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (4.25.1)\n",
      "Requirement already satisfied: lxml_html_clean in ./.venv/lib/python3.12/site-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura>=1.6.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 14)) (0.4.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv/lib/python3.12/site-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.21.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.2.14)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.18->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 9)) (1.1.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel==6.29.4->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 33)) (0.2.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in ./.venv/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.27.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in ./.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (4.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in ./.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in ./.venv/lib/python3.12/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (0.1.1)\n",
      "Requirement already satisfied: fqdn in ./.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in ./.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (20.11.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in ./.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.1.0)\n",
      "Requirement already satisfied: uri-template in ./.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in ./.venv/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (24.11.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in ./.venv/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.23)\n",
      "Requirement already satisfied: lark>=1.2.2 in ./.venv/lib/python3.12/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in ./.venv/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./.venv/lib/python3.12/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->-r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt (line 32)) (2.9.0.20251008)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r /Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/noveum_agent_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e7a810bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup & Imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "\n",
    "# LangChain ecosystem\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Noveum Trace integration\n",
    "import noveum_trace\n",
    "from noveum_trace.context_managers import trace_operation, trace_agent\n",
    "\n",
    "# Load environment variables\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    print(\"python-dotenv not installed. Environment variables will be read from system only.\")\n",
    "\n",
    "print(\"âœ… All imports loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef38e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NOVEUM_API_KEY\"] = \"NOVEUM_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "c0dc8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Noveum Trace initialized and configuration loaded!\n",
      "ðŸ”§ Configuration: {'noveum_base_url': 'https://noveum.ai', 'max_pages_to_scrape': 50, 'chunk_size': 1000, 'chunk_overlap': 200, 'max_search_results': 5, 'rag_threshold': 0.7, 'noveum_docs_file': 'noveum_docs.json', 'vector_store_path': 'noveum_vectorstore'}\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Noveum Trace Integration & Configuration\n",
    "# Initialize the Noveum Trace SDK\n",
    "noveum_trace.init(\n",
    "    project=\"noveum-ai-agent-rag-websearch\",\n",
    "    api_key=os.getenv(\"NOVEUM_API_KEY\"),\n",
    "    environment=\"development\",\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"noveum_base_url\": \"https://noveum.ai\",\n",
    "    \"max_pages_to_scrape\": 50,\n",
    "    \"chunk_size\": 1000,\n",
    "    \"chunk_overlap\": 200,\n",
    "    \"max_search_results\": 5,\n",
    "    \"rag_threshold\": 0.7,  # Similarity threshold for RAG retrieval\n",
    "    \"noveum_docs_file\": \"noveum_docs.json\",\n",
    "    \"vector_store_path\": \"noveum_vectorstore\"\n",
    "}\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Initialize web search tool\n",
    "web_search = DuckDuckGoSearchRun()\n",
    "\n",
    "print(\"âœ… Noveum Trace initialized and configuration loaded!\")\n",
    "print(f\"ðŸ”§ Configuration: {CONFIG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c765c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Website scraper initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Website Scraper - Extract content from noveum.ai and sub-URLs\n",
    "class NoveumWebsiteScraper:\n",
    "    def __init__(self, base_url: str, max_pages: int = 50):\n",
    "        self.base_url = base_url\n",
    "        self.max_pages = max_pages\n",
    "        self.scraped_urls = set()\n",
    "        self.scraped_content = []\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "    \n",
    "    def is_valid_url(self, url: str) -> bool:\n",
    "        \"\"\"Check if URL is valid and belongs to noveum.ai domain\"\"\"\n",
    "        try:\n",
    "            parsed = urlparse(url)\n",
    "            return (\n",
    "                parsed.netloc in ['noveum.ai', 'www.noveum.ai'] and\n",
    "                not any(ext in url.lower() for ext in ['.pdf', '.jpg', '.png', '.gif', '.css', '.js', '.xml', '.txt']) and\n",
    "                '#' not in url\n",
    "            )\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def extract_text_content(self, html_content: str, url: str) -> str:\n",
    "        \"\"\"Extract clean text content from HTML\"\"\"\n",
    "        try:\n",
    "            # Use trafilatura for better text extraction\n",
    "            extracted = trafilatura.extract(html_content)\n",
    "            if extracted:\n",
    "                return extracted.strip()\n",
    "            \n",
    "            # Fallback to BeautifulSoup\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            \n",
    "            # Remove script and style elements\n",
    "            for script in soup([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Get text and clean up\n",
    "            text = soup.get_text()\n",
    "            lines = (line.strip() for line in text.splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "            \n",
    "            return text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting text from {url}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def find_internal_links(self, html_content: str, current_url: str) -> List[str]:\n",
    "        \"\"\"Find all internal links from the current page\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            links = []\n",
    "            \n",
    "            for link in soup.find_all('a', href=True):\n",
    "                href = link['href']\n",
    "                full_url = urljoin(current_url, href)\n",
    "                \n",
    "                if self.is_valid_url(full_url) and full_url not in self.scraped_urls:\n",
    "                    links.append(full_url)\n",
    "            \n",
    "            return links\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding links in {current_url}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def scrape_page(self, url: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Scrape a single page and return content\"\"\"\n",
    "        try:\n",
    "            print(f\"ðŸ” Scraping: {url}\")\n",
    "            response = self.session.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Extract text content\n",
    "            text_content = self.extract_text_content(response.text, url)\n",
    "            \n",
    "            if not text_content or len(text_content) < 100:  # Skip pages with too little content\n",
    "                print(f\"âš ï¸  Skipping {url} - insufficient content\")\n",
    "                return None\n",
    "            \n",
    "            # Find internal links\n",
    "            internal_links = self.find_internal_links(response.text, url)\n",
    "            \n",
    "            page_data = {\n",
    "                \"url\": url,\n",
    "                \"title\": self.extract_title(response.text),\n",
    "                \"content\": text_content,\n",
    "                \"content_length\": len(text_content),\n",
    "                \"internal_links\": internal_links,\n",
    "                \"scraped_at\": time.time()\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… Scraped {url} - {len(text_content)} chars, {len(internal_links)} internal links\")\n",
    "            return page_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error scraping {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def extract_title(self, html_content: str) -> str:\n",
    "        \"\"\"Extract page title\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            title_tag = soup.find('title')\n",
    "            return title_tag.get_text().strip() if title_tag else \"Untitled\"\n",
    "        except:\n",
    "            return \"Untitled\"\n",
    "    \n",
    "    def scrape_website(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Main scraping function - scrape noveum.ai recursively\"\"\"\n",
    "        print(f\"ðŸš€ Starting to scrape {self.base_url}\")\n",
    "        \n",
    "        urls_to_scrape = [self.base_url]\n",
    "        self.scraped_urls.add(self.base_url)\n",
    "        \n",
    "        with trace_operation(\"noveum_website_scraping\") as scrape_span:\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.base_url\": self.base_url,\n",
    "                \"scraper.max_pages\": self.max_pages,\n",
    "                \"input_query\": f\"Scrape website: {self.base_url}\",\n",
    "                \"output_response\": f\"Scraping completed: {len(self.scraped_content)} pages scraped, {sum(page['content_length'] for page in self.scraped_content)} total characters extracted\"\n",
    "            })\n",
    "            \n",
    "            while urls_to_scrape and len(self.scraped_content) < self.max_pages:\n",
    "                current_url = urls_to_scrape.pop(0)\n",
    "                \n",
    "                # Scrape the current page\n",
    "                page_data = self.scrape_page(current_url)\n",
    "                \n",
    "                if page_data:\n",
    "                    self.scraped_content.append(page_data)\n",
    "                    \n",
    "                    # Add new internal links to the queue\n",
    "                    for link in page_data[\"internal_links\"]:\n",
    "                        if link not in self.scraped_urls and len(urls_to_scrape) < 100:  # Prevent infinite loops\n",
    "                            urls_to_scrape.append(link)\n",
    "                            self.scraped_urls.add(link)\n",
    "                    \n",
    "                    # Add page data to span\n",
    "                    scrape_span.add_event(\"page_scraped\", {\n",
    "                        \"input_query\": f\"Scrape page: {current_url}\",\n",
    "                        \"output_response\": f\"Page scraped successfully: {page_data['content_length']} characters, {len(page_data['internal_links'])} internal links found\",\n",
    "                        \"url\": current_url,\n",
    "                        \"content_length\": page_data[\"content_length\"],\n",
    "                        \"internal_links_found\": len(page_data[\"internal_links\"])\n",
    "                    })\n",
    "                \n",
    "                # Small delay to be respectful\n",
    "                time.sleep(0.5)\n",
    "            \n",
    "            # Final metrics\n",
    "            scrape_span.set_attributes({\n",
    "                \"scraper.pages_scraped\": len(self.scraped_content),\n",
    "                \"scraper.total_urls_found\": len(self.scraped_urls),\n",
    "                \"scraper.total_content_length\": sum(page[\"content_length\"] for page in self.scraped_content)\n",
    "            })\n",
    "        \n",
    "        print(f\"âœ… Scraping complete! Scraped {len(self.scraped_content)} pages\")\n",
    "        return self.scraped_content\n",
    "    \n",
    "    def save_to_json(self, filename: str) -> None:\n",
    "        \"\"\"Save scraped content to JSON file\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.scraped_content, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"ðŸ’¾ Saved scraped content to {filename}\")\n",
    "\n",
    "# Initialize scraper\n",
    "scraper = NoveumWebsiteScraper(CONFIG[\"noveum_base_url\"], CONFIG[\"max_pages_to_scrape\"])\n",
    "print(\"âœ… Website scraper initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0d0e2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: RAG System - Vector search and retrieval over scraped content\n",
    "class NoveumRAGSystem:\n",
    "    def __init__(self, embeddings, llm, config):\n",
    "        self.embeddings = embeddings\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        self.vectorstore = None\n",
    "        self.documents = []\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=config[\"chunk_size\"],\n",
    "            chunk_overlap=config[\"chunk_overlap\"]\n",
    "        )\n",
    "    \n",
    "    def load_documents_from_json(self, json_file: str) -> List[Document]:\n",
    "        \"\"\"Load documents from scraped JSON file\"\"\"\n",
    "        try:\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                scraped_data = json.load(f)\n",
    "            \n",
    "            documents = []\n",
    "            for page in scraped_data:\n",
    "                # Create document from page content\n",
    "                doc = Document(\n",
    "                    page_content=page[\"content\"],\n",
    "                    metadata={\n",
    "                        \"url\": page[\"url\"],\n",
    "                        \"title\": page[\"title\"],\n",
    "                        \"content_length\": page[\"content_length\"],\n",
    "                        \"scraped_at\": page[\"scraped_at\"]\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "            \n",
    "            print(f\"âœ… Loaded {len(documents)} documents from {json_file}\")\n",
    "            return documents\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ File {json_file} not found. Please run the scraper first.\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def create_vectorstore(self, documents: List[Document]) -> None:\n",
    "        \"\"\"Create FAISS vector store from documents\"\"\"\n",
    "        if not documents:\n",
    "            print(\"âŒ No documents to create vector store\")\n",
    "            return\n",
    "        \n",
    "        print(\"ðŸ”„ Creating vector store...\")\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        split_docs = self.text_splitter.split_documents(documents)\n",
    "        print(f\"ðŸ“„ Split into {len(split_docs)} chunks\")\n",
    "        \n",
    "        # Create vector store\n",
    "        self.vectorstore = FAISS.from_documents(split_docs, self.embeddings)\n",
    "        \n",
    "        # Save vector store\n",
    "        self.vectorstore.save_local(self.config[\"vector_store_path\"])\n",
    "        print(f\"ðŸ’¾ Vector store saved to {self.config['vector_store_path']}\")\n",
    "    \n",
    "    def load_vectorstore(self) -> bool:\n",
    "        \"\"\"Load existing vector store from disk\"\"\"\n",
    "        try:\n",
    "            self.vectorstore = FAISS.load_local(\n",
    "                self.config[\"vector_store_path\"], \n",
    "                self.embeddings,\n",
    "                allow_dangerous_deserialization=True\n",
    "            )\n",
    "            print(f\"âœ… Loaded existing vector store from {self.config['vector_store_path']}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error loading vector store: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def search_relevant_docs(self, query: str, k: int = 5) -> List[Document]:\n",
    "        \"\"\"Search for relevant documents using similarity search\"\"\"\n",
    "        if not self.vectorstore:\n",
    "            print(\"âŒ Vector store not initialized\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Perform similarity search\n",
    "            docs = self.vectorstore.similarity_search(query, k=k)\n",
    "            \n",
    "            # Filter by similarity threshold if needed\n",
    "            # Note: FAISS doesn't return scores by default, but we can add that if needed\n",
    "            \n",
    "            print(f\"ðŸ” Found {len(docs)} relevant documents for query: '{query}'\")\n",
    "            return docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error searching documents: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def retrieve_context(self, query: str, max_docs: int = 5) -> str:\n",
    "        \"\"\"Retrieve and format context for the query\"\"\"\n",
    "        relevant_docs = self.search_relevant_docs(query, max_docs)\n",
    "        \n",
    "        if not relevant_docs:\n",
    "            return \"No relevant information found in Noveum documentation.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, doc in enumerate(relevant_docs, 1):\n",
    "            context_parts.append(f\"Source {i} ({doc.metadata.get('url', 'Unknown URL')}):\\n{doc.page_content[:500]}...\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_rag_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using RAG\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"rag_agent\",\n",
    "            operation=\"llm-rag\",\n",
    "            capabilities=[\"document_retrieval\", \"context_generation\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_rag_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as rag_span:\n",
    "            \n",
    "            # Retrieve relevant context\n",
    "            context = self.retrieve_context(query, CONFIG[\"max_search_results\"])\n",
    "            \n",
    "            # Create prompt for RAG\n",
    "            rag_prompt = f\"\"\"You are a helpful assistant for Noveum.ai. Answer the user's question based on the provided context from Noveum's documentation.\n",
    "\n",
    "Context from Noveum documentation:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based primarily on the provided context\n",
    "2. If the context doesn't contain enough information, say so clearly\n",
    "3. Be specific and cite sources when possible\n",
    "4. Keep responses concise but informative\n",
    "5. If the question is not related to Noveum, politely redirect to ask about Noveum\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "            \n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(rag_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                if response.content:\n",
    "                    answer = response.content\n",
    "                else:\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(rag_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track retrieval, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"rag_evaluation_metrics\",\n",
    "                capabilities=[\"retrieval_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as rag_node:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer)\n",
    "                sources_count = len(context.split(\"Source\")) - 1 if \"Source\" in context else 0\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                rag_node.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"rag_evaluation_query\",\n",
    "                    \n",
    "                    # Retrieval metrics\n",
    "                    \"retrieval.context_retrieved\": f\"Context: {context[:300]}{'...' if len(context) > 300 else ''}\",\n",
    "                    \"retrieval.context_length\": context_length,\n",
    "                    \"retrieval.sources_count\": sources_count,\n",
    "                    \"retrieval.context_quality\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"retrieval.effectiveness\": sources_count / 5.0,  # Normalized to max expected sources\n",
    "                    \"retrieval.context_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": rag_prompt,\n",
    "                    \"prompt.prompt_length\": len(rag_prompt),\n",
    "                    \"prompt.context_injection\": f\"Context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"rag_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 100 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 200 and sources_count > 2 else \"medium\" if answer_length > 100 else \"low\",\n",
    "                    \"response.source_citation\": sources_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.retrieval_effectiveness\": sources_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 150 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": sources_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 500 else \"medium\" if context_length > 200 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 200 and sources_count > 2 and context_length > 500 else \"medium\" if answer_length > 100 and sources_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # RAG-specific metrics\n",
    "                    \"rag.retrieval_strategy\": \"semantic_similarity\",\n",
    "                    \"rag.vector_search_results\": sources_count,\n",
    "                    \"rag.context_synthesis\": \"multi_source\" if sources_count > 1 else \"single_source\",\n",
    "                    \"rag.document_coverage\": sources_count / 5.0,  # Normalized coverage\n",
    "                    \"rag.information_density\": answer_length / context_length if context_length > 0 else 0\n",
    "                })\n",
    "\n",
    "            # Set main RAG span attributes (simplified)\n",
    "            rag_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"rag_query\",\n",
    "                \"output_response\": f\"RAG Answer: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                \"rag.context_length\": context_length,\n",
    "                \"rag.sources_count\": sources_count,\n",
    "                \"rag.answer_length\": answer_length,\n",
    "                \"rag.mode\": \"retrieval_augmented_generation\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"RAG\",\n",
    "                \"sources\": [doc.metadata.get('url', 'Unknown') for doc in self.search_relevant_docs(query, CONFIG[\"max_search_results\"])],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize RAG system\n",
    "rag_system = NoveumRAGSystem(embeddings, llm, CONFIG)\n",
    "print(\"âœ… RAG system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "09823cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Web search system initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Web Search Integration - DuckDuckGo search for external queries\n",
    "class NoveumWebSearchSystem:\n",
    "    def __init__(self, web_search_tool, llm, config):\n",
    "        self.web_search = web_search_tool\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "    \n",
    "    def search_web(self, query: str, max_results: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Perform web search and return formatted results\"\"\"\n",
    "        try:\n",
    "            # Perform web search\n",
    "            search_results = self.web_search.run(query)\n",
    "            \n",
    "            # Parse results (DuckDuckGo returns a string, need to parse it)\n",
    "            results = []\n",
    "            if isinstance(search_results, str):\n",
    "                # Split by lines and parse each result\n",
    "                lines = search_results.split('\\n')\n",
    "                for i, line in enumerate(lines[:max_results]):\n",
    "                    if line.strip():\n",
    "                        results.append({\n",
    "                            \"title\": f\"Search Result {i+1}\",\n",
    "                            \"snippet\": line.strip(),\n",
    "                            \"url\": f\"https://duckduckgo.com/?q={query.replace(' ', '+')}\"\n",
    "                        })\n",
    "            else:\n",
    "                # If it's already a list/dict format\n",
    "                results = search_results[:max_results]\n",
    "            \n",
    "            print(f\"ðŸ” Found {len(results)} web search results for: '{query}'\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error performing web search: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def format_search_context(self, search_results: List[Dict[str, Any]]) -> str:\n",
    "        \"\"\"Format search results into context string\"\"\"\n",
    "        if not search_results:\n",
    "            return \"No search results found.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        for i, result in enumerate(search_results, 1):\n",
    "            title = result.get('title', f'Result {i}')\n",
    "            snippet = result.get('snippet', 'No description available')\n",
    "            url = result.get('url', 'No URL available')\n",
    "            \n",
    "            context_parts.append(f\"Source {i} - {title}:\\n{snippet}\\nURL: {url}\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_web_response(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate response using web search\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"web_search_agent\",\n",
    "            operation=\"web_search_generation\",\n",
    "            capabilities=[\"web_search\", \"content_synthesis\", \"response_generation\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_web_search_agent\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as web_span:\n",
    "            \n",
    "            # Perform web search\n",
    "            search_results = self.search_web(query, self.config[\"max_search_results\"])\n",
    "            \n",
    "            # Format context\n",
    "            context = self.format_search_context(search_results)\n",
    "            \n",
    "            # Create prompt for web search response\n",
    "            web_prompt = f\"\"\"You are a helpful assistant. Answer the user's question based on the provided web search results.\n",
    "\n",
    "Web Search Results:\n",
    "{context}\n",
    "\n",
    "User Question: {query}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based on the provided web search results\n",
    "2. Synthesize information from multiple sources when relevant\n",
    "3. Be informative and accurate\n",
    "4. If the results don't contain enough information, say so clearly\n",
    "5. Keep responses concise but comprehensive\n",
    "6. Cite sources when possible\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "            # Extract model parameters and metadata\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span - Track model-specific information\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                # Generate response\n",
    "                response = self.llm.invoke(web_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "\n",
    "                # Handle response content extraction\n",
    "                if hasattr(response, 'content'):\n",
    "                    # When response is a proper SDK object\n",
    "                    answer = response.content\n",
    "                elif isinstance(response, dict):\n",
    "                    # When response is returned as a plain dict\n",
    "                    answer = response.get('content', '')\n",
    "                else:\n",
    "                    # Fallback to string\n",
    "                    answer = str(response)\n",
    "\n",
    "                # Extract token usage metadata - Enhanced extraction\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                # Try multiple ways to extract token usage\n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                elif hasattr(response, 'token_usage'):\n",
    "                    token_usage = response.token_usage\n",
    "                    prompt_tokens = getattr(token_usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(token_usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(token_usage, \"total_tokens\", 0)\n",
    "                \n",
    "                # If still no tokens found, try to estimate from content length\n",
    "                if total_tokens == 0:\n",
    "                    # Rough estimation: ~4 characters per token for English text\n",
    "                    estimated_prompt_tokens = len(web_prompt) // 4\n",
    "                    estimated_completion_tokens = len(answer) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 2.0 else \"medium\" if model_latency < 5.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(answer) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(answer),\n",
    "                    \"model.response_quality\": \"high\" if len(answer) > 200 else \"medium\" if len(answer) > 100 else \"low\",\n",
    "                    \"model.output_response\": f\"Model Response: {answer[:200]}{'...' if len(answer) > 200 else ''}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Other Details Span - Track web search, response quality, and evaluation metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"web_search_evaluation_metrics\",\n",
    "                capabilities=[\"web_search_analysis\", \"response_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Calculate additional evaluation metrics\n",
    "                search_results_count = len(search_results)\n",
    "                context_length = len(context)\n",
    "                answer_length = len(answer or \"\")\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"web_search_evaluation_query\",\n",
    "                    \n",
    "                    # Web search metrics\n",
    "                    \"web_search.results_count\": search_results_count,\n",
    "                    \"web_search.context_length\": context_length,\n",
    "                    \"web_search.context_synthesized\": f\"Context from {search_results_count} web sources\",\n",
    "                    \"web_search.search_effectiveness\": search_results_count / 5.0,  # Normalized to max expected results\n",
    "                    \"web_search.context_quality\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"web_search.source_diversity\": search_results_count,\n",
    "                    \"web_search.information_synthesis\": \"high\" if search_results_count > 3 and answer_length > 200 else \"medium\" if search_results_count > 1 else \"low\",\n",
    "                    \"web_search.external_knowledge_utilization\": context_length / 1000.0,  # Normalized context usage\n",
    "                    \n",
    "                    # Prompt engineering metrics\n",
    "                    \"prompt.complete_prompt\": web_prompt,\n",
    "                    \"prompt.prompt_length\": len(web_prompt),\n",
    "                    \"prompt.context_injection\": f\"Web context injected: {context[:200]}{'...' if len(context) > 200 else ''}\",\n",
    "                    \"prompt.instruction_following\": \"web_search_optimized\",\n",
    "                    \n",
    "                    # Response quality metrics\n",
    "                    \"response.answer_length\": answer_length,\n",
    "                    \"response.answer_completeness\": \"complete\" if answer_length > 150 else \"brief\",\n",
    "                    \"response.response_quality\": \"high\" if answer_length > 300 and search_results_count > 3 else \"medium\" if answer_length > 150 else \"low\",\n",
    "                    \"response.source_citation\": search_results_count,\n",
    "                    \"response.context_utilization\": answer_length / context_length if context_length > 0 else 0,\n",
    "                    \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.search_effectiveness\": search_results_count / 5.0,\n",
    "                    \"evaluation.response_completeness\": \"complete\" if answer_length > 200 else \"partial\",\n",
    "                    \"evaluation.source_diversity\": search_results_count,\n",
    "                    \"evaluation.context_relevance\": \"high\" if context_length > 800 else \"medium\" if context_length > 400 else \"low\",\n",
    "                    \"evaluation.overall_quality\": \"high\" if answer_length > 300 and search_results_count > 3 and context_length > 800 else \"medium\" if answer_length > 150 and search_results_count > 1 else \"low\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Web search specific metrics\n",
    "                    \"web_search.search_strategy\": \"duckduckgo_api\",\n",
    "                    \"web_search.real_time_data\": True,\n",
    "                    \"web_search.external_sources\": search_results_count,\n",
    "                    \"web_search.information_freshness\": \"current\",\n",
    "                    \"web_search.knowledge_synthesis\": \"multi_source\" if search_results_count > 1 else \"single_source\"\n",
    "                })\n",
    "\n",
    "            # Set main Web Search span attributes (simplified)\n",
    "            web_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"web_search_query\",\n",
    "                \"output_response\": f\"Web Search Answer: {answer[:200]}{'...' if len(answer or '') > 200 else ''}\" if answer else \"No answer generated\",\n",
    "                \"web_search.results_count\": search_results_count,\n",
    "                \"web_search.context_length\": context_length,\n",
    "                \"web_search.response_length\": answer_length,\n",
    "                \"web_search.mode\": \"external_web_search\"\n",
    "            })\n",
    "\n",
    "            return {\n",
    "                \"answer\": answer,\n",
    "                \"context\": context,\n",
    "                \"mode\": \"Web Search\",\n",
    "                \"sources\": [result.get('url', 'Unknown') for result in search_results],\n",
    "                \"model_info\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"tokens_used\": total_tokens,\n",
    "                    \"prompt_tokens\": prompt_tokens,\n",
    "                    \"completion_tokens\": completion_tokens,\n",
    "                    \"latency\": model_latency\n",
    "                }\n",
    "            }\n",
    "\n",
    "# Initialize web search system\n",
    "web_search_system = NoveumWebSearchSystem(web_search, llm, CONFIG)\n",
    "print(\"âœ… Web search system initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3d47287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query router initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Query Router - Intelligent decision making between RAG and Web Search\n",
    "class NoveumQueryRouter:\n",
    "    def __init__(self, llm, config):\n",
    "        self.llm = llm\n",
    "        self.config = config\n",
    "        \n",
    "        # Keywords that suggest RAG should be used\n",
    "        self.rag_keywords = [\n",
    "            \"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\",\n",
    "            \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\",\n",
    "            \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\",\n",
    "            \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"\n",
    "        ]\n",
    "        \n",
    "        # Keywords that suggest Web Search should be used\n",
    "        self.web_keywords = [\n",
    "            \"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\",\n",
    "            \"today\", \"yesterday\", \"this week\", \"this month\", \"current\",\n",
    "            \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\",\n",
    "            \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\",\n",
    "            \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"\n",
    "        ]\n",
    "    \n",
    "    def classify_query(self, query: str) -> str:\n",
    "        \"\"\"Classify query to determine whether to use RAG or Web Search\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # Check for RAG keywords\n",
    "        rag_score = sum(1 for keyword in self.rag_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for Web Search keywords\n",
    "        web_score = sum(1 for keyword in self.web_keywords if keyword in query_lower)\n",
    "        \n",
    "        # Check for explicit mentions of Noveum\n",
    "        if \"noveum\" in query_lower:\n",
    "            return \"RAG\"\n",
    "        \n",
    "        # If both scores are 0, use LLM-based classification\n",
    "        if rag_score == 0 and web_score == 0:\n",
    "            return self._llm_classify_query(query)\n",
    "        \n",
    "        # Return the mode with higher score\n",
    "        return \"RAG\" if rag_score >= web_score else \"Web Search\"\n",
    "    \n",
    "    def _llm_classify_query(self, query: str) -> str:\n",
    "        \"\"\"Use LLM to classify query when keyword matching is inconclusive\"\"\"\n",
    "        try:\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "\n",
    "            # Extract model parameters for tracking\n",
    "            model_name = getattr(self.llm, 'model_name', 'unknown')\n",
    "            model_temperature = getattr(self.llm, 'temperature', 0.0)\n",
    "            model_max_tokens = getattr(self.llm, 'max_tokens', None)\n",
    "            model_top_p = getattr(self.llm, 'top_p', None)\n",
    "            model_frequency_penalty = getattr(self.llm, 'frequency_penalty', None)\n",
    "            model_presence_penalty = getattr(self.llm, 'presence_penalty', None)\n",
    "\n",
    "            # Model Details Span for classification\n",
    "            with trace_agent(\n",
    "                agent_type=\"model_details\",\n",
    "                operation=\"llm_model_execution\",\n",
    "                capabilities=[\"model_invocation\", \"parameter_tracking\", \"latency_measurement\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_model_details\",\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as model_span:\n",
    "                \n",
    "                # Record start time for latency measurement\n",
    "                model_start_time = time.time()\n",
    "                \n",
    "                response = self.llm.invoke(classification_prompt)\n",
    "                \n",
    "                # Record end time and calculate latency\n",
    "                model_end_time = time.time()\n",
    "                model_latency = model_end_time - model_start_time\n",
    "            \n",
    "                if hasattr(response, 'content'):\n",
    "                    result = response.content.strip().upper()\n",
    "                else:\n",
    "                    result = str(response).strip().upper()\n",
    "\n",
    "                # Extract token usage for classification\n",
    "                prompt_tokens = 0\n",
    "                completion_tokens = 0\n",
    "                total_tokens = 0\n",
    "                \n",
    "                if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "                    usage = response.usage_metadata\n",
    "                    prompt_tokens = getattr(usage, \"input_tokens\", 0) or getattr(usage, \"prompt_tokens\", 0)\n",
    "                    completion_tokens = getattr(usage, \"output_tokens\", 0) or getattr(usage, \"completion_tokens\", 0)\n",
    "                    total_tokens = getattr(usage, \"total_tokens\", 0)\n",
    "                elif hasattr(response, 'response_metadata') and response.response_metadata:\n",
    "                    metadata = response.response_metadata\n",
    "                    if 'token_usage' in metadata:\n",
    "                        token_usage = metadata['token_usage']\n",
    "                        prompt_tokens = token_usage.get('prompt_tokens', 0)\n",
    "                        completion_tokens = token_usage.get('completion_tokens', 0)\n",
    "                        total_tokens = token_usage.get('total_tokens', 0)\n",
    "                \n",
    "                # If still no tokens found, estimate\n",
    "                if total_tokens == 0:\n",
    "                    estimated_prompt_tokens = len(classification_prompt) // 4\n",
    "                    estimated_completion_tokens = len(result) // 4\n",
    "                    prompt_tokens = estimated_prompt_tokens\n",
    "                    completion_tokens = estimated_completion_tokens\n",
    "                    total_tokens = prompt_tokens + completion_tokens\n",
    "\n",
    "                # Set model details span attributes\n",
    "                model_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Model execution for classification: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"classification_model_query\",\n",
    "                    \n",
    "                    # Model parameters and configuration\n",
    "                    \"model.name\": model_name,\n",
    "                    \"model.temperature\": model_temperature,\n",
    "                    \"model.max_tokens\": model_max_tokens,\n",
    "                    \"model.top_p\": model_top_p,\n",
    "                    \"model.frequency_penalty\": model_frequency_penalty,\n",
    "                    \"model.presence_penalty\": model_presence_penalty,\n",
    "                    \"model.provider\": \"openai\",\n",
    "                    \"model.type\": \"chat_completion\",\n",
    "                    \"model.version\": \"gpt-4o-mini\",\n",
    "                    \n",
    "                    # Latency and performance metrics\n",
    "                    \"model.latency_seconds\": model_latency,\n",
    "                    \"model.latency_ms\": model_latency * 1000,\n",
    "                    \"model.start_time\": model_start_time,\n",
    "                    \"model.end_time\": model_end_time,\n",
    "                    \"model.performance_tier\": \"fast\" if model_latency < 1.0 else \"medium\" if model_latency < 3.0 else \"slow\",\n",
    "                    \n",
    "                    # Token usage and cost metrics\n",
    "                    \"model.prompt_tokens\": prompt_tokens,\n",
    "                    \"model.completion_tokens\": completion_tokens,\n",
    "                    \"model.total_tokens\": total_tokens,\n",
    "                    \"model.tokens_per_second\": total_tokens / model_latency if model_latency > 0 else 0,\n",
    "                    \"model.estimated_cost\": total_tokens * 0.00003,  # Rough cost estimate\n",
    "                    \"model.efficiency_score\": len(result) / total_tokens if total_tokens > 0 else 0,\n",
    "                    \n",
    "                    # Response characteristics\n",
    "                    \"model.response_length\": len(result),\n",
    "                    \"model.response_quality\": \"high\" if len(result) > 10 else \"medium\" if len(result) > 5 else \"low\",\n",
    "                    \"model.output_response\": f\"Classification Result: {result}\",\n",
    "                    \n",
    "                    # Model configuration details\n",
    "                    \"model.config\": {\n",
    "                        \"name\": model_name,\n",
    "                        \"temperature\": model_temperature,\n",
    "                        \"max_tokens\": model_max_tokens,\n",
    "                        \"top_p\": model_top_p,\n",
    "                        \"frequency_penalty\": model_frequency_penalty,\n",
    "                        \"presence_penalty\": model_presence_penalty,\n",
    "                        \"provider\": \"openai\",\n",
    "                        \"type\": \"chat_completion\"\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            # Log classification details for debugging\n",
    "            print(f\"ðŸ” LLM Classification - Model: {model_name}, Tokens: {total_tokens}, Result: {result}\")\n",
    "            \n",
    "            if \"RAG\" in result:\n",
    "                return \"RAG\"\n",
    "            elif \"WEB\" in result or \"SEARCH\" in result:\n",
    "                return \"Web Search\"\n",
    "            else:\n",
    "                # Default to Web Search if unclear\n",
    "                return \"Web Search\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error in LLM classification: {e}\")\n",
    "            # Default to Web Search on error\n",
    "            return \"Web Search\"\n",
    "    \n",
    "    def route_query(self, query: str) -> Tuple[str, Dict[str, Any]]:\n",
    "        \"\"\"Route query to appropriate system and return response\"\"\"\n",
    "        with trace_agent(\n",
    "            agent_type=\"query_router\",\n",
    "            operation=\"query_routing\",\n",
    "            capabilities=[\"query_classification\", \"routing_decision\"],\n",
    "            attributes={\n",
    "                \"agent.id\": \"noveum_query_router\",\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query)\n",
    "            }\n",
    "        ) as router_span:\n",
    "            \n",
    "            # Define classification prompt for tracing\n",
    "            classification_prompt = f\"\"\"Classify the following user query to determine the best response method:\n",
    "\n",
    "Query: \"{query}\"\n",
    "\n",
    "Choose between:\n",
    "- RAG: Use when the query is about Noveum.ai platform, products, features, documentation, or internal information\n",
    "- Web Search: Use when the query is about recent events, news, general knowledge, or external topics\n",
    "\n",
    "Respond with only \"RAG\" or \"Web Search\".\"\"\"\n",
    "            \n",
    "            # Classify the query\n",
    "            mode = self.classify_query(query)\n",
    "            \n",
    "            # Calculate routing evaluation metrics\n",
    "            query_lower = query.lower()\n",
    "            rag_keywords = [\"noveum\", \"platform\", \"product\", \"feature\", \"api\", \"documentation\", \"trace\", \"observability\", \"monitoring\", \"agent\", \"system\", \"tool\", \"integration\", \"setup\", \"configuration\", \"usage\", \"guide\", \"tutorial\", \"pricing\", \"plan\", \"subscription\", \"account\", \"dashboard\", \"metrics\"]\n",
    "            web_keywords = [\"recent\", \"latest\", \"news\", \"update\", \"announcement\", \"release\", \"today\", \"yesterday\", \"this week\", \"this month\", \"current\", \"trending\", \"popular\", \"viral\", \"breaking\", \"live\", \"real-time\", \"weather\", \"stock\", \"price\", \"market\", \"cryptocurrency\", \"bitcoin\", \"election\", \"politics\", \"sports\", \"entertainment\", \"celebrity\"]\n",
    "            \n",
    "            rag_score = sum(1 for keyword in rag_keywords if keyword in query_lower)\n",
    "            web_score = sum(1 for keyword in web_keywords if keyword in query_lower)\n",
    "            confidence_score = abs(rag_score - web_score) / max(rag_score + web_score, 1)\n",
    "            \n",
    "            # Other Details Span - Track routing analysis and decision metrics\n",
    "            with trace_agent(\n",
    "                agent_type=\"other_details\",\n",
    "                operation=\"routing_evaluation_metrics\",\n",
    "                capabilities=[\"routing_analysis\", \"decision_evaluation\", \"quality_assessment\"],\n",
    "                attributes={\n",
    "                    \"agent.id\": \"noveum_other_details\",\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query)\n",
    "                }\n",
    "            ) as other_span:\n",
    "                \n",
    "                # Set other details span attributes\n",
    "                other_span.set_attributes({\n",
    "                    # Input metrics\n",
    "                    \"input_query\": f\"Routing evaluation for query: {query[:100]}{'...' if len(query) > 100 else ''}\",\n",
    "                    \"query_length\": len(query),\n",
    "                    \"query_type\": \"routing_evaluation_query\",\n",
    "                    \n",
    "                    # Classification metrics\n",
    "                    \"classification.mode\": mode,\n",
    "                    \"classification.rag_keyword_score\": rag_score,\n",
    "                    \"classification.web_keyword_score\": web_score,\n",
    "                    \"classification.confidence_score\": confidence_score,\n",
    "                    \"classification.confidence_level\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"classification.method\": \"llm_based\" if rag_score == 0 and web_score == 0 else \"keyword_based\",\n",
    "                    \n",
    "                    # Query analysis metrics\n",
    "                    \"query.complexity\": \"complex\" if len(query) > 50 else \"medium\" if len(query) > 20 else \"simple\",\n",
    "                    \"query.intent\": \"noveum_specific\" if \"noveum\" in query_lower else \"general_knowledge\" if web_score > rag_score else \"documentation\",\n",
    "                    \"query.keyword_density\": (rag_score + web_score) / len(query.split()),\n",
    "                    \"query.domain_affinity\": \"noveum\" if rag_score > web_score else \"general\" if web_score > rag_score else \"neutral\",\n",
    "                    \n",
    "                    # Routing decision metrics\n",
    "                    \"routing.decision\": f\"Routed to {mode} based on analysis\",\n",
    "                    \"routing.rationale\": f\"RAG score: {rag_score}, Web score: {web_score}, Confidence: {confidence_score:.2f}\",\n",
    "                    \"routing.expected_performance\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"routing.alternative_mode\": \"Web Search\" if mode == \"RAG\" else \"RAG\",\n",
    "                    \"routing.decision_confidence\": confidence_score,\n",
    "                    \n",
    "                    # Evaluation metrics\n",
    "                    \"evaluation.routing_accuracy\": \"high\" if confidence_score > 0.5 else \"medium\" if confidence_score > 0.2 else \"low\",\n",
    "                    \"evaluation.keyword_coverage\": (rag_score + web_score) / len(rag_keywords + web_keywords),\n",
    "                    \"evaluation.query_understanding\": \"clear\" if confidence_score > 0.5 else \"ambiguous\" if confidence_score > 0.2 else \"unclear\",\n",
    "                    \"evaluation.ready_for_production\": True,\n",
    "                    \n",
    "                    # Router-specific metrics\n",
    "                    \"router.classification_strategy\": \"hybrid_keyword_llm\",\n",
    "                    \"router.keyword_matching\": \"used\" if rag_score > 0 or web_score > 0 else \"bypassed\",\n",
    "                    \"router.llm_fallback\": \"used\" if rag_score == 0 and web_score == 0 else \"not_needed\",\n",
    "                    \"router.decision_time\": \"instant\" if rag_score > 0 or web_score > 0 else \"llm_required\",\n",
    "                    \"output_response\": f\"Routing Decision: {mode} (Confidence: {confidence_score:.2f})\"\n",
    "                })\n",
    "\n",
    "            # Set main router span attributes (simplified)\n",
    "            router_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query_length\": len(query),\n",
    "                \"query_type\": \"routing_query\",\n",
    "                \"output_response\": f\"Routed to {mode} for query processing\",\n",
    "                \"router.classification\": mode,\n",
    "                \"router.confidence_score\": confidence_score,\n",
    "                \"router.rag_keyword_score\": rag_score,\n",
    "                \"router.web_keyword_score\": web_score,\n",
    "                \"router.mode\": \"intelligent_routing\"\n",
    "            })\n",
    "            \n",
    "            # Route to appropriate system\n",
    "            if mode == \"RAG\":\n",
    "                print(f\"ðŸ§  Routing to RAG system for: '{query}'\")\n",
    "                response = rag_system.generate_rag_response(query)\n",
    "            else:\n",
    "                print(f\"ðŸŒ Routing to Web Search for: '{query}'\")\n",
    "                response = web_search_system.generate_web_response(query)\n",
    "            \n",
    "            return mode, response\n",
    "\n",
    "# Initialize query router\n",
    "query_router = NoveumQueryRouter(llm, CONFIG)\n",
    "print(\"âœ… Query router initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a865a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Noveum AI Agent initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Main Executor - Orchestrates the complete agent workflow\n",
    "class NoveumAIAgent:\n",
    "    def __init__(self, scraper, rag_system, web_search_system, query_router, config):\n",
    "        self.scraper = scraper\n",
    "        self.rag_system = rag_system\n",
    "        self.web_search_system = web_search_system\n",
    "        self.query_router = query_router\n",
    "        self.config = config\n",
    "        self.is_initialized = False\n",
    "    \n",
    "    def initialize_system(self, force_scrape: bool = False) -> bool:\n",
    "        \"\"\"Initialize the system by setting up RAG with scraped data\"\"\"\n",
    "        print(\"ðŸš€ Initializing Noveum AI Agent...\")\n",
    "        \n",
    "        with trace_operation(\"system_initialization\") as init_span:\n",
    "            init_span.set_attributes({\n",
    "                \"system.force_scrape\": force_scrape,\n",
    "                \"system.config\": self.config,\n",
    "                \"input_query\": f\"Initialize system with force_scrape={force_scrape}\",\n",
    "                \"output_response\": \"System initialization: RAG system loaded, vector store ready, agent operational\"\n",
    "            })\n",
    "            \n",
    "            # Check if we need to scrape or if data already exists\n",
    "            if force_scrape or not os.path.exists(self.config[\"noveum_docs_file\"]):\n",
    "                print(\"ðŸ“¥ Scraping Noveum website...\")\n",
    "                \n",
    "                # Scrape the website\n",
    "                scraped_data = self.scraper.scrape_website()\n",
    "                \n",
    "                if not scraped_data:\n",
    "                    print(\"âŒ Failed to scrape website data\")\n",
    "                    return False\n",
    "                \n",
    "                # Save scraped data\n",
    "                self.scraper.save_to_json(self.config[\"noveum_docs_file\"])\n",
    "                \n",
    "                init_span.add_event(\"website_scraped\", {\n",
    "                    \"input_query\": f\"Scrape website: {self.config['noveum_base_url']}\",\n",
    "                    \"output_response\": f\"Website scraping completed: {len(scraped_data)} pages scraped, {sum(page['content_length'] for page in scraped_data)} total characters extracted for RAG system\",\n",
    "                    \"pages_scraped\": len(scraped_data),\n",
    "                    \"total_content_length\": sum(page[\"content_length\"] for page in scraped_data)\n",
    "                })\n",
    "            else:\n",
    "                print(\"ðŸ“ Using existing scraped data...\")\n",
    "            \n",
    "            # Load documents and create/load vector store\n",
    "            documents = self.rag_system.load_documents_from_json(self.config[\"noveum_docs_file\"])\n",
    "            \n",
    "            if not documents:\n",
    "                print(\"âŒ Failed to load documents\")\n",
    "                return False\n",
    "            \n",
    "            # Try to load existing vector store, create if doesn't exist\n",
    "            if not self.rag_system.load_vectorstore():\n",
    "                print(\"ðŸ”„ Creating new vector store...\")\n",
    "                self.rag_system.create_vectorstore(documents)\n",
    "            \n",
    "            self.is_initialized = True\n",
    "            print(\"âœ… Noveum AI Agent initialized successfully!\")\n",
    "            \n",
    "            init_span.set_attributes({\n",
    "                \"system.initialized\": True,\n",
    "                \"system.documents_loaded\": len(documents),\n",
    "                \"system.vectorstore_ready\": self.rag_system.vectorstore is not None\n",
    "            })\n",
    "            \n",
    "            return True\n",
    "    \n",
    "    def process_query(self, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a user query and return response\"\"\"\n",
    "        if not self.is_initialized:\n",
    "            print(\"âŒ System not initialized. Please run initialize_system() first.\")\n",
    "            return {\n",
    "                \"answer\": \"System not initialized. Please run initialize_system() first.\",\n",
    "                \"mode\": \"Error\",\n",
    "                \"sources\": [],\n",
    "                \"error\": \"System not initialized\"\n",
    "            }\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ Processing query: '{query}'\")\n",
    "        \n",
    "        with trace_operation(\"tool-orchestator\") as process_span:\n",
    "            process_span.set_attributes({\n",
    "                \"input_query\": query,\n",
    "                \"query.length\": len(query)\n",
    "            })\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Route query and get response\n",
    "                mode, response = self.query_router.route_query(query)\n",
    "                \n",
    "                # Add processing metrics\n",
    "                end_time = time.time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                response.update({\n",
    "                    \"processing_time\": processing_time,\n",
    "                    \"timestamp\": time.time()\n",
    "                })\n",
    "                \n",
    "                # Add metrics to span\n",
    "                process_span.set_attributes({\n",
    "                    \"processing.mode\": mode,\n",
    "                    \"processing.time_seconds\": processing_time,\n",
    "                    \"processing.response_length\": len(response.get(\"answer\", \"\")),\n",
    "                    \"processing.sources_count\": len(response.get(\"sources\", [])),\n",
    "                    \"output_response\": f\"Final Answer: {response.get('answer', '')[:200]}{'...' if len(response.get('answer', '')) > 200 else ''}\",\n",
    "                    \"final_answer_mode\": mode,\n",
    "                    \"query_processed.input_query\": query,\n",
    "                    \"query_processed.output_response\": f\"Successfully processed query using {mode}, generated {len(response.get('answer', ''))} character response\",\n",
    "                    \"query_processed.mode\": mode,\n",
    "                    \"query_processed.processing_time\": processing_time,\n",
    "                    \"query_processed.response_length\": len(response.get(\"answer\", \"\"))\n",
    "                })\n",
    "                \n",
    "                print(f\"âœ… Query processed in {processing_time:.2f}s using {mode}\")\n",
    "                return response\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error processing query: {str(e)}\"\n",
    "                print(f\"âŒ {error_msg}\")\n",
    "                \n",
    "                process_span.add_event(\"query_processing_error\", {\n",
    "                    \"error\": str(e),\n",
    "                    \"input_query\": query,\n",
    "                    \"output_response\": f\"I encountered an error while processing your query: {str(e)}\"\n",
    "                })\n",
    "                \n",
    "                return {\n",
    "                    \"answer\": f\"I encountered an error while processing your query: {str(e)}\",\n",
    "                    \"mode\": \"Error\",\n",
    "                    \"sources\": [],\n",
    "                    \"error\": str(e),\n",
    "                    \"processing_time\": time.time() - start_time\n",
    "                }\n",
    "    \n",
    "    def display_response(self, response: Dict[str, Any]) -> None:\n",
    "        \"\"\"Display the response in a formatted way\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"ðŸ¤– NOVEUM AI AGENT RESPONSE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ðŸ“Š Mode: {response.get('mode', 'Unknown')}\")\n",
    "        print(f\"â±ï¸  Processing Time: {response.get('processing_time', 0):.2f}s\")\n",
    "        print(f\"ðŸ“… Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(response.get('timestamp', time.time())))}\")\n",
    "        \n",
    "        if response.get('sources'):\n",
    "            print(f\"ðŸ“š Sources ({len(response['sources'])}):\")\n",
    "            for i, source in enumerate(response['sources'][:3], 1):  # Show first 3 sources\n",
    "                print(f\"   {i}. {source}\")\n",
    "            if len(response['sources']) > 3:\n",
    "                print(f\"   ... and {len(response['sources']) - 3} more\")\n",
    "        \n",
    "        print(\"\\nðŸ’¬ Answer:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(response.get('answer', 'No answer provided'))\n",
    "        print(\"=\"*80)\n",
    "\n",
    "# Initialize the main agent\n",
    "noveum_agent = NoveumAIAgent(scraper, rag_system, web_search_system, query_router, CONFIG)\n",
    "print(\"âœ… Noveum AI Agent initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4b30e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Demo functions ready!\n",
      "\n",
      "ðŸš€ To get started:\n",
      "1. Run: demo_noveum_agent()  # For a full demo\n",
      "2. Run: ask_question('Your question here')  # For a single question\n",
      "3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Usage Examples and Demo\n",
    "def demo_noveum_agent():\n",
    "    \"\"\"Demo function showing how to use the Noveum AI Agent\"\"\"\n",
    "    \n",
    "    print(\"ðŸŽ¬ NOVEUM AI AGENT DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Step 1: Initialize the system\n",
    "    print(\"\\n1ï¸âƒ£ Initializing the system...\")\n",
    "    success = noveum_agent.initialize_system(force_scrape=False)  # Set to True to force re-scraping\n",
    "    \n",
    "    if not success:\n",
    "        print(\"âŒ Failed to initialize system\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Demo queries - 20 comprehensive test questions\n",
    "    demo_queries = [\n",
    "        # RAG Queries (Noveum-specific)\n",
    "        \"What is Noveum and what does it do?\",  # Basic product info\n",
    "        \"How do I integrate Noveum Trace in my application?\",  # Technical integration\n",
    "        \"What are Noveum's pricing plans?\",  # Pricing information\n",
    "        \"What features does Noveum Trace offer?\",  # Feature overview\n",
    "        \"How do I set up observability with Noveum?\",  # Setup guidance\n",
    "        \"What APIs are available in Noveum platform?\",  # API documentation\n",
    "        \"How does Noveum handle agent tracing?\",  # Technical details\n",
    "        \"What monitoring capabilities does Noveum provide?\",  # Capabilities\n",
    "        \"How do I configure Noveum for my system?\",  # Configuration\n",
    "        \"What are the benefits of using Noveum Trace?\",  # Value proposition\n",
    "        \n",
    "        # Web Search Queries (External/Recent information)\n",
    "        \"What are the latest AI news today?\",  # Recent news\n",
    "        \"What's the weather like today?\",  # Current weather\n",
    "        \"Tell me about recent developments in machine learning\",  # Recent developments\n",
    "        \"What are the current trends in observability tools?\",  # Industry trends\n",
    "        \"What happened in tech news this week?\",  # Weekly tech news\n",
    "        \"What are the latest updates in Python programming?\",  # Recent updates\n",
    "        \"What's the current status of cryptocurrency markets?\",  # Market information\n",
    "        \"What are the newest features in cloud computing?\",  # Recent features\n",
    "        \"What's happening in the software development world today?\",  # Current events\n",
    "        \"What are the latest breakthroughs in artificial intelligence?\"  # Recent breakthroughs\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n2ï¸âƒ£ Running {len(demo_queries)} demo queries...\")\n",
    "    \n",
    "    for i, query in enumerate(demo_queries, 1):\n",
    "        print(f\"\\n--- Demo Query {i} ---\")\n",
    "        response = noveum_agent.process_query(query)\n",
    "        noveum_agent.display_response(response)\n",
    "        \n",
    "        # Small delay between queries\n",
    "        time.sleep(1)\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ Demo completed! Check Noveum Trace dashboard for detailed observability data.\")\n",
    "    print(\"ðŸ’¡ You can now use noveum_agent.process_query('your question') for your own queries!\")\n",
    "\n",
    "# Interactive query function\n",
    "def ask_question(question: str):\n",
    "    \"\"\"Convenience function to ask a single question\"\"\"\n",
    "    if not noveum_agent.is_initialized:\n",
    "        print(\"âš ï¸  System not initialized. Initializing now...\")\n",
    "        if not noveum_agent.initialize_system():\n",
    "            print(\"âŒ Failed to initialize system\")\n",
    "            return\n",
    "    \n",
    "    response = noveum_agent.process_query(question)\n",
    "    noveum_agent.display_response(response)\n",
    "    return response\n",
    "\n",
    "print(\"âœ… Demo functions ready!\")\n",
    "print(\"\\nðŸš€ To get started:\")\n",
    "print(\"1. Run: demo_noveum_agent()  # For a full demo\")\n",
    "print(\"2. Run: ask_question('Your question here')  # For a single question\")\n",
    "print(\"3. Or use: noveum_agent.process_query('Your question')  # For programmatic access\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "99c27d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¬ NOVEUM AI AGENT DEMO\n",
      "==================================================\n",
      "\n",
      "1ï¸âƒ£ Initializing the system...\n",
      "ðŸš€ Initializing Noveum AI Agent...\n",
      "ðŸ“ Using existing scraped data...\n",
      "âœ… Loaded 38 documents from noveum_docs.json\n",
      "âœ… Loaded existing vector store from noveum_vectorstore\n",
      "âœ… Noveum AI Agent initialized successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:54:54 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_system_initialization (ID: aff5d7ed-2681-4ee6-9e17-c5f5fdd9d361) - 1 spans\n",
      "2025-10-09 13:54:54 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_system_initialization (ID: aff5d7ed-2681-4ee6-9e17-c5f5fdd9d361) - 1 spans\n",
      "2025-10-09 13:54:54 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace aff5d7ed-2681-4ee6-9e17-c5f5fdd9d361\n",
      "2025-10-09 13:54:54 - noveum_trace.transport.http_transport - INFO - âœ… Trace aff5d7ed-2681-4ee6-9e17-c5f5fdd9d361 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2ï¸âƒ£ Running 20 demo queries...\n",
      "\n",
      "--- Demo Query 1 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What is Noveum and what does it do?'\n",
      "ðŸ§  Routing to RAG system for: 'What is Noveum and what does it do?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What is Noveum and what does it do?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:54:57 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: f5c40ecf-36c0-45ba-9cc9-dc0329b0324b) - 6 spans\n",
      "2025-10-09 13:54:57 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: f5c40ecf-36c0-45ba-9cc9-dc0329b0324b) - 6 spans\n",
      "2025-10-09 13:54:57 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace f5c40ecf-36c0-45ba-9cc9-dc0329b0324b\n",
      "2025-10-09 13:54:57 - noveum_trace.transport.http_transport - INFO - âœ… Trace f5c40ecf-36c0-45ba-9cc9-dc0329b0324b successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What is Noveum and what does it do?'\n",
      "âœ… Query processed in 3.50s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 3.50s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:54:57\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/en/docs/getting-started/overview\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "Noveum.ai is a comprehensive tracing and observability platform specifically designed for AI applications, including those powered by large language models (LLMs), retrieval-augmented generation (RAG) systems, and AI agents. It provides essential insights that help developers understand, debug, and optimize their AI-driven systems. The platform addresses the complexities of building production AI applications by offering complete visibility into workflows involving LLM calls, vector searches, data retrieval, and agent reasoning, thereby making debugging and optimization more manageable (Sources 1 and 2).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 2 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'How do I integrate Noveum Trace in my application?'\n",
      "ðŸ§  Routing to RAG system for: 'How do I integrate Noveum Trace in my application?'\n",
      "ðŸ” Found 5 relevant documents for query: 'How do I integrate Noveum Trace in my application?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:06 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: b7945c49-f584-4c70-972d-536a805d8a31) - 6 spans\n",
      "2025-10-09 13:55:06 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: b7945c49-f584-4c70-972d-536a805d8a31) - 6 spans\n",
      "2025-10-09 13:55:06 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace b7945c49-f584-4c70-972d-536a805d8a31\n",
      "2025-10-09 13:55:06 - noveum_trace.transport.http_transport - INFO - âœ… Trace b7945c49-f584-4c70-972d-536a805d8a31 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'How do I integrate Noveum Trace in my application?'\n",
      "âœ… Query processed in 8.40s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 8.40s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:06\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/sdk-integration\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "To integrate Noveum Trace into your application, you can use either the Python SDK (`noveum-trace`) or the TypeScript SDK (`@noveum/trace`). Hereâ€™s a quick start guide based on the provided documentation:\n",
      "\n",
      "1. **Create Your Account & Get API Key**:\n",
      "   - Sign up at [noveum.ai](https://noveum.ai).\n",
      "   - Create a project in your dashboard.\n",
      "   - Generate an API key.\n",
      "\n",
      "2. **Integrate the SDK**:\n",
      "   - For **Python**: Use the `noveum-trace` SDK, which offers decorator-based tracing for LLM calls, agents, and RAG pipelines, along with automatic instrumentation for popular AI frameworks.\n",
      "   - For **TypeScript**: Use the `@noveum/trace` SDK, designed for frameworks like Next.js, Express.js, and Hono, ensuring full type safety and universal compatibility across Node.js, Edge Runtime, and browsers.\n",
      "\n",
      "3. **Capture Metrics**: The SDKs automatically capture essential metrics and traces with minimal code changes, including performance metrics, cost tracking, request/response data, and context flow.\n",
      "\n",
      "For detailed integration steps, refer to the SDK Integration Guide in the documentation ([Source 3](https://noveum.ai/docs/getting-started/sdk-integration)).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 3 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are Noveum's pricing plans?'\n",
      "ðŸ§  Routing to RAG system for: 'What are Noveum's pricing plans?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What are Noveum's pricing plans?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:11 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: fc64e6cc-6739-4256-ac4a-7b80c3028233) - 6 spans\n",
      "2025-10-09 13:55:11 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: fc64e6cc-6739-4256-ac4a-7b80c3028233) - 6 spans\n",
      "2025-10-09 13:55:11 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace fc64e6cc-6739-4256-ac4a-7b80c3028233\n",
      "2025-10-09 13:55:11 - noveum_trace.transport.http_transport - INFO - âœ… Trace fc64e6cc-6739-4256-ac4a-7b80c3028233 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What are Noveum's pricing plans?'\n",
      "âœ… Query processed in 3.51s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 3.51s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:11\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/docs/getting-started/overview\n",
      "   2. https://noveum.ai/en/docs/getting-started/overview\n",
      "   3. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not include specific information about Noveum's pricing plans. However, it mentions that all users will have access to the Observability suite for free, and early users will receive free evaluation jobs and premium support for the first year (Source 1 and Source 2). For detailed pricing plans, you may need to check the Noveum.ai website or contact their support directly.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 4 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What features does Noveum Trace offer?'\n",
      "ðŸ§  Routing to RAG system for: 'What features does Noveum Trace offer?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What features does Noveum Trace offer?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:19 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 16143f74-2831-4753-b33d-ce4b645093c5) - 6 spans\n",
      "2025-10-09 13:55:19 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 16143f74-2831-4753-b33d-ce4b645093c5) - 6 spans\n",
      "2025-10-09 13:55:19 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 16143f74-2831-4753-b33d-ce4b645093c5\n",
      "2025-10-09 13:55:19 - noveum_trace.transport.http_transport - INFO - âœ… Trace 16143f74-2831-4753-b33d-ce4b645093c5 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What features does Noveum Trace offer?'\n",
      "âœ… Query processed in 7.14s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 7.14s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:19\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/en/docs/getting-started/sdk-integration\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "Noveum Trace offers several key features through its Python SDK (`noveum-trace`) and TypeScript SDK (`@noveum/trace`):\n",
      "\n",
      "1. **Decorator-based Tracing**: It provides a simple way to trace LLM calls, agents, and RAG pipelines using decorators.\n",
      "2. **Automatic Instrumentation**: The SDK automatically instruments popular AI frameworks, making integration easier.\n",
      "3. **Context Propagation**: It supports context propagation across asynchronous operations, ensuring that trace information is maintained throughout.\n",
      "4. **TypeScript-first Design**: The TypeScript SDK is designed with full type safety and is compatible with various frameworks like Next.js, Express.js, and Hono.\n",
      "5. **Universal Compatibility**: The TypeScript SDK works across Node.js, Edge Runtime, and browsers.\n",
      "\n",
      "Additionally, the Noveum Platform includes a real-time dashboard for analyzing traces and performance, allowing for features like bulk export of traces, comparative analysis, live updates, and performance monitoring (Sources 1, 2, 3, 4, 5).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 5 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'How do I set up observability with Noveum?'\n",
      "ðŸ§  Routing to RAG system for: 'How do I set up observability with Noveum?'\n",
      "ðŸ” Found 5 relevant documents for query: 'How do I set up observability with Noveum?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:28 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 7da9814d-a2e8-4c4e-b750-68b26bd5fd22) - 6 spans\n",
      "2025-10-09 13:55:28 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 7da9814d-a2e8-4c4e-b750-68b26bd5fd22) - 6 spans\n",
      "2025-10-09 13:55:28 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 7da9814d-a2e8-4c4e-b750-68b26bd5fd22\n",
      "2025-10-09 13:55:28 - noveum_trace.transport.http_transport - INFO - âœ… Trace 7da9814d-a2e8-4c4e-b750-68b26bd5fd22 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'How do I set up observability with Noveum?'\n",
      "âœ… Query processed in 8.31s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 8.31s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:28\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/en/docs/getting-started/tracing-concepts\n",
      "   3. https://noveum.ai/docs/getting-started/tracing-concepts\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "To set up observability with Noveum, follow these steps:\n",
      "\n",
      "1. **Sign Up**: Go to [noveum.ai](https://noveum.ai) and create an account.\n",
      "2. **Create a Project**: Once signed in, create a new project to obtain your API key.\n",
      "3. **Install the SDK**: Choose your preferred programming language and install the corresponding SDK.\n",
      "4. **Add Tracing**: Integrate tracing into your AI workflows using the SDK.\n",
      "5. **Explore Insights**: Use the Noveum.ai dashboard to analyze the collected data and gain insights into your AI applications.\n",
      "\n",
      "For more detailed guidance, you can explore framework-specific integrations and advanced instrumentation techniques in the Noveum documentation ([Source 2](https://noveum.ai/en/docs/getting-started/tracing-concepts)). Remember, effective observability focuses on collecting the right data to help you understand, debug, and optimize your applications ([Source 2](https://noveum.ai/en/docs/getting-started/tracing-concepts)).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 6 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What APIs are available in Noveum platform?'\n",
      "ðŸ§  Routing to RAG system for: 'What APIs are available in Noveum platform?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What APIs are available in Noveum platform?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:32 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 5e043630-6493-42b5-beb8-79faa19bfa37) - 6 spans\n",
      "2025-10-09 13:55:32 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 5e043630-6493-42b5-beb8-79faa19bfa37) - 6 spans\n",
      "2025-10-09 13:55:32 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 5e043630-6493-42b5-beb8-79faa19bfa37\n",
      "2025-10-09 13:55:32 - noveum_trace.transport.http_transport - INFO - âœ… Trace 5e043630-6493-42b5-beb8-79faa19bfa37 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What APIs are available in Noveum platform?'\n",
      "âœ… Query processed in 2.78s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 2.78s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:32\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not specify the APIs available in the Noveum platform. For detailed information about the APIs, I recommend checking the official Noveum documentation or the SDK Integration Guide. If you have any other questions about Noveum, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 7 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'How does Noveum handle agent tracing?'\n",
      "ðŸ§  Routing to RAG system for: 'How does Noveum handle agent tracing?'\n",
      "ðŸ” Found 5 relevant documents for query: 'How does Noveum handle agent tracing?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:37 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 04bebf38-a343-4563-80db-0154bef8d927) - 6 spans\n",
      "2025-10-09 13:55:37 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 04bebf38-a343-4563-80db-0154bef8d927) - 6 spans\n",
      "2025-10-09 13:55:37 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 04bebf38-a343-4563-80db-0154bef8d927\n",
      "2025-10-09 13:55:37 - noveum_trace.transport.http_transport - INFO - âœ… Trace 04bebf38-a343-4563-80db-0154bef8d927 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'How does Noveum handle agent tracing?'\n",
      "âœ… Query processed in 3.62s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 3.62s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:37\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/blog/noveum-ai-your-one-stop-ai-evaluation-platform\n",
      "   2. https://noveum.ai/docs/advanced/multi-agent-tracing\n",
      "   3. https://noveum.ai/en/docs/advanced/multi-agent-tracing\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "Noveum.ai handles agent tracing through its specialized Multi-Agent Tracing capabilities, which are designed to observe complex workflows and inter-agent communications within multi-agent systems. These systems often involve multiple agents that coordinate, communicate, and collaborate to achieve shared goals, presenting unique observability challenges.\n",
      "\n",
      "Noveum.ai provides comprehensive tracing to help users understand and optimize these intricate workflows, ensuring complete visibility into agent interactions and processes. This functionality is crucial for debugging, performance optimization, and gaining insights into user interactions with AI applications (Source 2 and Source 3).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 8 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What monitoring capabilities does Noveum provide?'\n",
      "ðŸ§  Routing to RAG system for: 'What monitoring capabilities does Noveum provide?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What monitoring capabilities does Noveum provide?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:42 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: dc511122-c0b6-415c-9a49-c7b45132dd87) - 6 spans\n",
      "2025-10-09 13:55:42 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: dc511122-c0b6-415c-9a49-c7b45132dd87) - 6 spans\n",
      "2025-10-09 13:55:42 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace dc511122-c0b6-415c-9a49-c7b45132dd87\n",
      "2025-10-09 13:55:42 - noveum_trace.transport.http_transport - INFO - âœ… Trace dc511122-c0b6-415c-9a49-c7b45132dd87 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What monitoring capabilities does Noveum provide?'\n",
      "âœ… Query processed in 4.50s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 4.50s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:42\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en\n",
      "   2. https://noveum.ai/\n",
      "   3. https://noveum.ai\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "Noveum provides comprehensive monitoring capabilities for AI applications, including the ability to monitor, trace, and optimize AI agents across various frameworks such as LangChain, CrewAI, AutoGen, and custom implementations. Key features include:\n",
      "\n",
      "1. **Unified Dashboard**: A single dashboard that consolidates monitoring for all AI agents, allowing users to see everything in one place.\n",
      "2. **Lightweight SDKs**: These SDKs capture every trace and span within the AI agent ecosystem, from simple LLM calls to complex multi-agent interactions.\n",
      "3. **Insights for Optimization**: Noveum offers insights that help users understand, debug, and improve their AI systems, ensuring that no critical information is missed.\n",
      "\n",
      "Overall, Noveum serves as a control plane for AI agents, enabling effective monitoring and evaluation (Sources 1, 2, 4).\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 9 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'How do I configure Noveum for my system?'\n",
      "ðŸ§  Routing to RAG system for: 'How do I configure Noveum for my system?'\n",
      "ðŸ” Found 5 relevant documents for query: 'How do I configure Noveum for my system?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:47 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 255fd49c-84b4-4b18-887e-6308a412d535) - 6 spans\n",
      "2025-10-09 13:55:47 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 255fd49c-84b4-4b18-887e-6308a412d535) - 6 spans\n",
      "2025-10-09 13:55:47 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 255fd49c-84b4-4b18-887e-6308a412d535\n",
      "2025-10-09 13:55:47 - noveum_trace.transport.http_transport - INFO - âœ… Trace 255fd49c-84b4-4b18-887e-6308a412d535 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'How do I configure Noveum for my system?'\n",
      "âœ… Query processed in 3.27s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 3.27s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:47\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/docs\n",
      "   2. https://noveum.ai/docs\n",
      "   3. https://noveum.ai/docs/getting-started/overview\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "To configure Noveum for your system, you can refer to the SDK Integration Guide available in the Noveum documentation. This guide will help you trace your AI applications with minimal code changes. The SDKs provided for Python and TypeScript are designed to facilitate this integration.\n",
      "\n",
      "Unfortunately, the specific steps for configuration are not detailed in the provided context. For more comprehensive instructions, you may want to explore the full documentation on the Noveum website or reach out to their support channels for assistance. \n",
      "\n",
      "If you have any other questions related to Noveum, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 10 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the benefits of using Noveum Trace?'\n",
      "ðŸ§  Routing to RAG system for: 'What are the benefits of using Noveum Trace?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What are the benefits of using Noveum Trace?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:55:55 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 2218f641-604c-491a-9710-b51a9941b982) - 6 spans\n",
      "2025-10-09 13:55:55 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 2218f641-604c-491a-9710-b51a9941b982) - 6 spans\n",
      "2025-10-09 13:55:55 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 2218f641-604c-491a-9710-b51a9941b982\n",
      "2025-10-09 13:55:55 - noveum_trace.transport.http_transport - INFO - âœ… Trace 2218f641-604c-491a-9710-b51a9941b982 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What are the benefits of using Noveum Trace?'\n",
      "âœ… Query processed in 7.77s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 7.77s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:55:55\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/docs/platform/dashboard\n",
      "   2. https://noveum.ai/en/docs\n",
      "   3. https://noveum.ai/docs\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "Using Noveum Trace offers several benefits, including:\n",
      "\n",
      "1. **Real-Time Monitoring**: The Noveum platform provides a real-time dashboard for analyzing traces and performance, with live updates as new traces arrive. This includes connection monitoring and performance indicators for system health (Source 1).\n",
      "\n",
      "2. **Advanced Analysis Tools**: Users can perform bulk exports to download multiple traces simultaneously and conduct comparative analysis to evaluate performance across different traces (Source 1).\n",
      "\n",
      "3. **Cost Analysis and Optimization**: Noveum Trace includes features for cost analysis and provides optimization recommendations, helping users manage expenses related to AI operations (Source 4).\n",
      "\n",
      "4. **Collaboration Features**: The platform supports team collaboration by allowing shared insights and alerts, enhancing communication and teamwork (Source 4).\n",
      "\n",
      "5. **Comprehensive Tracing Capabilities**: With SDKs for both Python and TypeScript, Noveum Trace offers decorator-based tracing for LLM calls, automatic instrumentation for popular AI frameworks, and context propagation across async operations (Source 2, Source 3).\n",
      "\n",
      "6. **Detailed Metrics**: It provides insights into model calls, token usage, prompt engineering effectiveness, and response quality metrics, which are crucial for optimizing AI applications (Source 4, Source 5).\n",
      "\n",
      "These features collectively enhance the ability to monitor, analyze, and optimize AI applications effectively.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 11 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the latest AI news today?'\n",
      "ðŸŒ Routing to Web Search for: 'What are the latest AI news today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What are the latest AI news today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:01 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 83c7dcce-3d89-4da1-8b3f-d419885d4cbc) - 6 spans\n",
      "2025-10-09 13:56:01 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 83c7dcce-3d89-4da1-8b3f-d419885d4cbc) - 6 spans\n",
      "2025-10-09 13:56:01 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 83c7dcce-3d89-4da1-8b3f-d419885d4cbc\n",
      "2025-10-09 13:56:01 - noveum_trace.transport.http_transport - INFO - âœ… Trace 83c7dcce-3d89-4da1-8b3f-d419885d4cbc successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 4.53s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 4.53s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:01\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+AI+news+today?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The latest news in artificial intelligence includes several key updates:\n",
      "\n",
      "1. **AI Spending Concerns**: Jeff Bezos has expressed concerns that the current level of investment in AI resembles an \"industrial bubble,\" where both promising and less viable ideas are receiving funding. This could potentially lead to significant financial losses in the future (Source 1).\n",
      "\n",
      "2. **Technological Advancements**: There have been recent developments in AI technologies, including new language and video models from companies like OpenAI and Anthropic. These advancements are part of ongoing efforts to enhance AI capabilities and applications (Source 1).\n",
      "\n",
      "3. **Industry Insights**: Various platforms are providing live updates and expert insights on AI trends, including machine learning and deep learning. This includes coverage of regulatory and ethical considerations surrounding AI technology (Source 1).\n",
      "\n",
      "For more detailed updates, you can explore dedicated AI news platforms or follow major tech news outlets.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 12 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What's the weather like today?'\n",
      "ðŸŒ Routing to Web Search for: 'What's the weather like today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What's the weather like today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:07 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 230aad27-f3dd-4968-a45a-3c2f07ac28ed) - 6 spans\n",
      "2025-10-09 13:56:07 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 230aad27-f3dd-4968-a45a-3c2f07ac28ed) - 6 spans\n",
      "2025-10-09 13:56:07 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 230aad27-f3dd-4968-a45a-3c2f07ac28ed\n",
      "2025-10-09 13:56:07 - noveum_trace.transport.http_transport - INFO - âœ… Trace 230aad27-f3dd-4968-a45a-3c2f07ac28ed successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 5.47s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 5.47s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:07\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+the+weather+like+today?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information about today's weather in any particular location. They mention weather forecasts for various places, including France and Singapore, but do not provide current weather details. For accurate and up-to-date weather information, I recommend checking a reliable weather website or app for your specific location.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 13 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'Tell me about recent developments in machine learning'\n",
      "ðŸŒ Routing to Web Search for: 'Tell me about recent developments in machine learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'Tell me about recent developments in machine learning'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:15 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: a81ca3a8-80aa-4c39-876e-8d40ea7a0aef) - 6 spans\n",
      "2025-10-09 13:56:15 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: a81ca3a8-80aa-4c39-876e-8d40ea7a0aef) - 6 spans\n",
      "2025-10-09 13:56:15 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace a81ca3a8-80aa-4c39-876e-8d40ea7a0aef\n",
      "2025-10-09 13:56:15 - noveum_trace.transport.http_transport - INFO - âœ… Trace a81ca3a8-80aa-4c39-876e-8d40ea7a0aef successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 6.63s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 6.63s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:15\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=Tell+me+about+recent+developments+in+machine+learning\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information about recent developments in machine learning. Therefore, I cannot provide a detailed answer based on those results.\n",
      "\n",
      "However, I can summarize some general trends and advancements in machine learning as of late 2023:\n",
      "\n",
      "1. **Generative AI**: There has been significant progress in generative models, particularly with tools like ChatGPT and DALL-E, which can create text and images, respectively. These models are being integrated into various applications, enhancing creativity and productivity.\n",
      "\n",
      "2. **Transformer Models**: The transformer architecture continues to dominate, with improvements in efficiency and scalability. New variants and optimizations are being developed to reduce computational costs while maintaining performance.\n",
      "\n",
      "3. **Ethics and Fairness**: There is an increasing focus on the ethical implications of machine learning, including bias mitigation and transparency in AI systems. Researchers are working on frameworks to ensure that AI technologies are fair and accountable.\n",
      "\n",
      "4. **Federated Learning**: This approach allows models to be trained across decentralized devices while keeping data localized, enhancing privacy and security. It is gaining traction in industries like healthcare and finance.\n",
      "\n",
      "5. **Automated Machine Learning (AutoML)**: Tools that automate the process of applying machine learning to real-world problems are becoming more sophisticated, making it easier for non-experts to leverage AI.\n",
      "\n",
      "For the latest and most specific developments, I recommend checking dedicated AI and machine learning news sources or academic journals.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 14 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the current trends in observability tools?'\n",
      "ðŸ§  Routing to RAG system for: 'What are the current trends in observability tools?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What are the current trends in observability tools?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:22 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 52aacb67-c361-4445-9b72-c157f79f47d6) - 6 spans\n",
      "2025-10-09 13:56:22 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 52aacb67-c361-4445-9b72-c157f79f47d6) - 6 spans\n",
      "2025-10-09 13:56:22 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 52aacb67-c361-4445-9b72-c157f79f47d6\n",
      "2025-10-09 13:56:22 - noveum_trace.transport.http_transport - INFO - âœ… Trace 52aacb67-c361-4445-9b72-c157f79f47d6 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What are the current trends in observability tools?'\n",
      "âœ… Query processed in 5.66s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 5.66s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:22\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/blog/from-logs-to-intelligent-choices-inside-noveum-ais-evaluation-process\n",
      "   2. https://noveum.ai/docs/getting-started/tracing-concepts\n",
      "   3. https://noveum.ai/en/docs/getting-started/tracing-concepts\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not explicitly outline current trends in observability tools. However, it highlights some key aspects of observability that are particularly relevant to AI applications. \n",
      "\n",
      "1. **Comprehensive Tracing**: There is a trend towards implementing detailed tracing across various stages of AI systems, such as retrieval, context preparation, and generation, to ensure accurate and relevant outputs (Source 5).\n",
      "\n",
      "2. **Focus on Relevant Data**: Good observability is emphasized as not merely collecting all possible data, but rather gathering the right data that aids in understanding, debugging, and optimizing AI applications (Source 2 and Source 3).\n",
      "\n",
      "3. **AI-Specific Monitoring**: Traditional monitoring tools are noted to fall short for AI applications, as they do not address specific challenges such as understanding the reasons behind irrelevant results or high costs associated with LLM calls (Source 4).\n",
      "\n",
      "For more detailed insights or specific trends, you may want to explore further resources or ask about Noveum's offerings in observability tools.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 15 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What happened in tech news this week?'\n",
      "ðŸŒ Routing to Web Search for: 'What happened in tech news this week?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What happened in tech news this week?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:26 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 5d2517e1-220a-429d-9d59-f701bda25eed) - 6 spans\n",
      "2025-10-09 13:56:26 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 5d2517e1-220a-429d-9d59-f701bda25eed) - 6 spans\n",
      "2025-10-09 13:56:26 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 5d2517e1-220a-429d-9d59-f701bda25eed\n",
      "2025-10-09 13:56:26 - noveum_trace.transport.http_transport - INFO - âœ… Trace 5d2517e1-220a-429d-9d59-f701bda25eed successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 3.77s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 3.77s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:26\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+happened+in+tech+news+this+week?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The web search results do not provide specific information about recent events in tech news for this week. They primarily discuss the grammatical usage of the phrase \"what happened\" and its variations. \n",
      "\n",
      "To find out what happened in tech news this week, I recommend checking reliable tech news websites or platforms that aggregate current events in technology, such as TechCrunch, The Verge, or Wired. If you have a specific topic or company in mind, I can help you look for more targeted information.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Demo Query 16 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the latest updates in Python programming?'\n",
      "ðŸŒ Routing to Web Search for: 'What are the latest updates in Python programming?'\n",
      "ðŸ” Found 1 web search results for: 'What are the latest updates in Python programming?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:31 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 9a1983f4-09da-4b53-80e6-38de6878e0e7) - 6 spans\n",
      "2025-10-09 13:56:31 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 9a1983f4-09da-4b53-80e6-38de6878e0e7) - 6 spans\n",
      "2025-10-09 13:56:31 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 9a1983f4-09da-4b53-80e6-38de6878e0e7\n",
      "2025-10-09 13:56:31 - noveum_trace.transport.http_transport - INFO - âœ… Trace 9a1983f4-09da-4b53-80e6-38de6878e0e7 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 3.24s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 3.24s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:31\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+updates+in+Python+programming?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The web search results do not provide specific information about the latest updates in Python programming. They focus primarily on news related to China, including geopolitics, economy, and lifestyle, without mentioning programming or technology updates.\n",
      "\n",
      "For the latest updates in Python programming, I recommend checking the official Python website (python.org) or popular programming news platforms like Real Python, Python Weekly, or the Python subreddit. These sources typically provide information on new releases, features, and enhancements in the Python programming language.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 17 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What's the current status of cryptocurrency markets?'\n",
      "ðŸŒ Routing to Web Search for: 'What's the current status of cryptocurrency markets?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What's the current status of cryptocurrency markets?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:34 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 43cdf081-4f01-49cd-b566-dbd1619e6cd2) - 6 spans\n",
      "2025-10-09 13:56:34 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 43cdf081-4f01-49cd-b566-dbd1619e6cd2) - 6 spans\n",
      "2025-10-09 13:56:34 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 43cdf081-4f01-49cd-b566-dbd1619e6cd2\n",
      "2025-10-09 13:56:34 - noveum_trace.transport.http_transport - INFO - âœ… Trace 43cdf081-4f01-49cd-b566-dbd1619e6cd2 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 2.67s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 2.67s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:34\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+the+current+status+of+cryptocurrency+markets?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The web search results did not provide any specific information regarding the current status of cryptocurrency markets. Therefore, I cannot provide an accurate update on market conditions, trends, or specific cryptocurrency prices at this time. For the latest information, I recommend checking reliable financial news websites or cryptocurrency market tracking platforms.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 18 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the newest features in cloud computing?'\n",
      "ðŸ§  Routing to RAG system for: 'What are the newest features in cloud computing?'\n",
      "ðŸ” Found 5 relevant documents for query: 'What are the newest features in cloud computing?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:40 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: f1f37bd7-0851-4659-b493-b80d3800d920) - 6 spans\n",
      "2025-10-09 13:56:40 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: f1f37bd7-0851-4659-b493-b80d3800d920) - 6 spans\n",
      "2025-10-09 13:56:40 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace f1f37bd7-0851-4659-b493-b80d3800d920\n",
      "2025-10-09 13:56:40 - noveum_trace.transport.http_transport - INFO - âœ… Trace f1f37bd7-0851-4659-b493-b80d3800d920 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 5 relevant documents for query: 'What are the newest features in cloud computing?'\n",
      "âœ… Query processed in 4.93s using RAG\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: RAG\n",
      "â±ï¸  Processing Time: 4.93s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:40\n",
      "ðŸ“š Sources (5):\n",
      "   1. https://noveum.ai/en/changelog\n",
      "   2. https://noveum.ai/en/changelog\n",
      "   3. https://noveum.ai/docs/platform/dashboard\n",
      "   ... and 2 more\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided context does not specifically mention any new features in cloud computing as a general topic. However, it does highlight several recent enhancements and features related to the Noveum.ai platform, which may involve cloud computing aspects. These include:\n",
      "\n",
      "1. **Enhanced Dashboard Analytics**: Real-time request tracking, latency monitoring, and cost analysis (Source 1).\n",
      "2. **Improved Logs Interface**: Better search functionality and enhanced debugging capabilities (Source 1).\n",
      "3. **Team Management**: Advanced member management with role-based access control (Source 1).\n",
      "4. **Security Improvements**: Enhanced API key management and secure credential storage (Source 1).\n",
      "5. **NovaEval Framework**: A comprehensive AI model evaluation framework with over 20 built-in scorers (Source 4).\n",
      "\n",
      "If you have specific questions about Noveum.ai or its features, feel free to ask!\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 19 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What's happening in the software development world today?'\n",
      "ðŸŒ Routing to Web Search for: 'What's happening in the software development world today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What's happening in the software development world today?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:45 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: 0ffffba1-8a37-443c-8866-d53ffbfa7718) - 6 spans\n",
      "2025-10-09 13:56:45 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: 0ffffba1-8a37-443c-8866-d53ffbfa7718) - 6 spans\n",
      "2025-10-09 13:56:45 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace 0ffffba1-8a37-443c-8866-d53ffbfa7718\n",
      "2025-10-09 13:56:45 - noveum_trace.transport.http_transport - INFO - âœ… Trace 0ffffba1-8a37-443c-8866-d53ffbfa7718 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 3.53s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 3.53s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:45\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What's+happening+in+the+software+development+world+today?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The web search did not yield any specific results regarding current events in the software development world. Therefore, I cannot provide detailed information on what's happening today in that field.\n",
      "\n",
      "However, generally speaking, trends in software development often include advancements in artificial intelligence, the rise of low-code/no-code platforms, increased focus on cybersecurity, and the adoption of agile methodologies. Additionally, many organizations are exploring cloud-native development and DevOps practices to enhance collaboration and efficiency.\n",
      "\n",
      "For the latest updates, I recommend checking reputable tech news websites, developer forums, or platforms like GitHub and Stack Overflow, which often highlight current trends and discussions in the software development community.\n",
      "================================================================================\n",
      "\n",
      "--- Demo Query 20 ---\n",
      "\n",
      "ðŸŽ¯ Processing query: 'What are the latest breakthroughs in artificial intelligence?'\n",
      "ðŸŒ Routing to Web Search for: 'What are the latest breakthroughs in artificial intelligence?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mramanindia/Documents/Work/Noveum_Agent_trace_Report/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:63: RuntimeWarning: This package (`duckduckgo_search`) has been renamed to `ddgs`! Use `pip install ddgs` instead.\n",
      "  with DDGS() as ddgs:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 1 web search results for: 'What are the latest breakthroughs in artificial intelligence?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-09 13:56:48 - noveum_trace.transport.http_transport - INFO - ðŸ“¤ EXPORTING TRACE: auto_trace_tool-orchestator (ID: eda4fe22-9a2b-4b73-856b-f4f3309bf719) - 6 spans\n",
      "2025-10-09 13:56:48 - noveum_trace.transport.batch_processor - INFO - ðŸ“¥ ADDING TRACE TO QUEUE: auto_trace_tool-orchestator (ID: eda4fe22-9a2b-4b73-856b-f4f3309bf719) - 6 spans\n",
      "2025-10-09 13:56:48 - noveum_trace.transport.batch_processor - INFO - âœ… Successfully queued trace eda4fe22-9a2b-4b73-856b-f4f3309bf719\n",
      "2025-10-09 13:56:48 - noveum_trace.transport.http_transport - INFO - âœ… Trace eda4fe22-9a2b-4b73-856b-f4f3309bf719 successfully queued for export\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query processed in 2.30s using Web Search\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– NOVEUM AI AGENT RESPONSE\n",
      "================================================================================\n",
      "ðŸ“Š Mode: Web Search\n",
      "â±ï¸  Processing Time: 2.30s\n",
      "ðŸ“… Timestamp: 2025-10-09 13:56:48\n",
      "ðŸ“š Sources (1):\n",
      "   1. https://duckduckgo.com/?q=What+are+the+latest+breakthroughs+in+artificial+intelligence?\n",
      "\n",
      "ðŸ’¬ Answer:\n",
      "----------------------------------------\n",
      "The provided web search results do not contain specific information about the latest breakthroughs in artificial intelligence. To find the most recent advancements in AI, I recommend checking reputable technology news websites, academic journals, or AI research organizations that frequently publish updates on the field. If you have access to specific sources or articles, I can help summarize or analyze that information.\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ‰ Demo completed! Check Noveum Trace dashboard for detailed observability data.\n",
      "ðŸ’¡ You can now use noveum_agent.process_query('your question') for your own queries!\n"
     ]
    }
   ],
   "source": [
    "demo_noveum_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd53eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c087c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7feb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06289a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
