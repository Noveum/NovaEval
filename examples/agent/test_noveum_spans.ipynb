{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Noveum Spans Dataset Testing\n",
    "\n",
    "This notebook tests the `noveum_spans_dataset.py` functionality with Noveum trace JSON files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your JSON file path here\n",
    "# Configuration - can be overridden with environment variables for portability\n",
    "JSON_FILE_PATH = os.getenv(\"NOVEUM_JSON_PATH\", \"/mnt/drive2/trace_details.json\")\n",
    "OUTPUT_CSV = os.getenv(\"NOVEUM_OUTPUT_CSV\", \"/mnt/drive2/noveum_spans_output.csv\")\n",
    "CHUNK_SIZE = int(os.getenv(\"NOVEUM_CHUNK_SIZE\", \"2\"))  # Set to 2 for testing purposes to verify streaming behavior\n",
    "\n",
    "# Alternative: Use relative paths if the files are in the current directory\n",
    "# JSON_FILE_PATH = os.getenv(\"NOVEUM_JSON_PATH\", \"./trace_details.json\")\n",
    "# OUTPUT_CSV = os.getenv(\"NOVEUM_OUTPUT_CSV\", \"./noveum_spans_output.csv\")\n",
    "\n",
    "# Output paths\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Import and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Add the parent directory to the path to import noveum_spans_dataset\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from novaeval.datasets.noveum_spans_dataset import (\n",
    "    create_dataset,\n",
    "    noveum_spans_preprocessing,\n",
    "    stream_dataset,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Check JSON File Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists and preview its structure\n",
    "if os.path.exists(JSON_FILE_PATH):\n",
    "    print(f\"✓ JSON file found: {JSON_FILE_PATH}\")\n",
    "\n",
    "    # Load and preview the JSON structure\n",
    "    with open(JSON_FILE_PATH) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(f\"\\nTrace ID: {data.get('trace_id')}\")\n",
    "    print(f\"Number of spans: {len(data.get('spans', []))}\")\n",
    "    print(f\"Trace name: {data.get('name')}\")\n",
    "\n",
    "    # Preview first span\n",
    "    if data.get(\"spans\"):\n",
    "        first_span = data[\"spans\"][0]\n",
    "        print(\"\\nFirst span:\")\n",
    "        print(f\"  - Span ID: {first_span.get('span_id')}\")\n",
    "        print(f\"  - Name: {first_span.get('name')}\")\n",
    "        print(f\"  - Status: {first_span.get('status')}\")\n",
    "        print(f\"  - Duration: {first_span.get('duration_ms')} ms\")\n",
    "\n",
    "        # Check attributes\n",
    "        attributes = first_span.get(\"attributes\", {})\n",
    "        print(f\"  - Function name: {attributes.get('function.name')}\")\n",
    "\n",
    "        # Check for input fields\n",
    "        input_fields = [k for k in attributes if k.startswith(\"agent.input.\") or k.startswith(\"tool.input.\")]\n",
    "        print(f\"  - Input fields: {input_fields}\")\n",
    "\n",
    "else:\n",
    "    print(f\"❌ JSON file not found: {JSON_FILE_PATH}\")\n",
    "    print(\"Please update the JSON_FILE_PATH variable above.\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. Test Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the preprocessing function\n",
    "print(\"Testing noveum_spans_preprocessing...\")\n",
    "\n",
    "try:\n",
    "    noveum_spans_preprocessing(\n",
    "        json_files=[JSON_FILE_PATH],\n",
    "        output_csv=OUTPUT_CSV\n",
    "    )\n",
    "    print(\"✓ Preprocessing completed successfully!\")\n",
    "\n",
    "    # Check the output CSV\n",
    "    if os.path.exists(OUTPUT_CSV):\n",
    "        df = pd.read_csv(OUTPUT_CSV)\n",
    "        print(f\"\\nOutput CSV created with {len(df)} rows\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "        # Show first few rows\n",
    "        print(\"\\nFirst few rows:\")\n",
    "        print(df[[\"turn_id\", \"agent_name\", \"agent_task\", \"status\"]].head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during preprocessing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. Test Dataset Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test creating a dataset from the CSV\n",
    "print(\"Testing create_dataset...\")\n",
    "\n",
    "try:\n",
    "    dataset = create_dataset(OUTPUT_CSV)\n",
    "    print(\"✓ Dataset created successfully!\")\n",
    "\n",
    "    # Check dataset properties\n",
    "    print(\"\\nDataset info:\")\n",
    "    print(f\"Number of records: {len(dataset.data)}\")\n",
    "\n",
    "    if dataset.data:\n",
    "        first_record = dataset.data[0]\n",
    "        print(\"\\nFirst record:\")\n",
    "        print(f\"  - Turn ID: {first_record.turn_id}\")\n",
    "        print(f\"  - Agent name: {first_record.agent_name}\")\n",
    "        print(f\"  - Agent role: {first_record.agent_role}\")\n",
    "        if len(first_record.agent_task) > 100:\n",
    "            print(f\"  - Task: {first_record.agent_task[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  - Task: {first_record.agent_task}\")\n",
    "        if len(first_record.agent_response) > 100:\n",
    "            print(f\"  - Response: {first_record.agent_response[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  - Response: {first_record.agent_response}\")\n",
    "\n",
    "        # Check metadata\n",
    "        if first_record.metadata:\n",
    "            metadata = json.loads(first_record.metadata)\n",
    "            print(f\"  - Metadata keys: {list(metadata.keys())}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating dataset: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. Test Streaming Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming the dataset with chunk size 2\n",
    "print(f\"Testing stream_dataset with chunk_size={CHUNK_SIZE}...\")\n",
    "\n",
    "try:\n",
    "    chunk_count = 0\n",
    "    total_records = 0\n",
    "\n",
    "    for chunk in stream_dataset(OUTPUT_CSV, chunk_size=CHUNK_SIZE):\n",
    "        chunk_count += 1\n",
    "        chunk_size_actual = len(chunk)\n",
    "        total_records += chunk_size_actual\n",
    "\n",
    "        print(f\"\\nChunk {chunk_count}: {chunk_size_actual} records\")\n",
    "\n",
    "        # Show details for first chunk\n",
    "        if chunk_count == 1:\n",
    "            for i, record in enumerate(chunk):\n",
    "                print(f\"  Record {i+1}:\")\n",
    "                print(f\"    - Turn ID: {record.turn_id}\")\n",
    "                print(f\"    - Agent: {record.agent_name}\")\n",
    "                print(f\"    - Role: {record.agent_role}\")\n",
    "                task_preview = record.agent_task[:50] + \"...\" if len(record.agent_task) > 50 else record.agent_task\n",
    "                print(f\"    - Task: {task_preview}\")\n",
    "\n",
    "        # Limit output for large datasets\n",
    "        if chunk_count >= 5:\n",
    "            print(\"\\n... (showing first 5 chunks only)\")\n",
    "            # Continue counting without printing\n",
    "            # Continue counting remaining chunks without printing to preserve streaming behavior\n",
    "            # Skip the first 5 chunks and process the rest\n",
    "            skip_count = 0\n",
    "            for remaining_chunk in stream_dataset(OUTPUT_CSV, chunk_size=CHUNK_SIZE):\n",
    "                if skip_count < 5:\n",
    "                    skip_count += 1\n",
    "                    continue\n",
    "                chunk_count += 1\n",
    "                total_records += len(remaining_chunk)\n",
    "            break\n",
    "\n",
    "    print(\"\\n✓ Streaming completed!\")\n",
    "    print(f\"Total chunks: {chunk_count}\")\n",
    "    print(f\"Total records: {total_records}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during streaming: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. Validation and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the processed data\n",
    "print(\"Data Analysis:\")\n",
    "\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    df = pd.read_csv(OUTPUT_CSV)\n",
    "\n",
    "    print(f\"\\nUnique agent names: {df['agent_name'].nunique()}\")\n",
    "    print(\"Agent name distribution:\")\n",
    "    print(df[\"agent_name\"].value_counts())\n",
    "\n",
    "    print(\"\\nStatus distribution:\")\n",
    "    print(df[\"status\"].value_counts())\n",
    "\n",
    "    # Check for empty fields\n",
    "    print(f\"\\nEmpty agent_task fields: {df['agent_task'].isna().sum() + (df['agent_task'] == '').sum()}\")\n",
    "    print(f\"Empty agent_response fields: {df['agent_response'].isna().sum() + (df['agent_response'] == '').sum()}\")\n",
    "\n",
    "    # Show a sample of different span types\n",
    "    print(\"\\nSample of different span types:\")\n",
    "    unique_names = df[\"agent_name\"].unique()[:5]\n",
    "    for name in unique_names:\n",
    "        sample = df[df[\"agent_name\"] == name].iloc[0]\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Span name: {sample['span_name']}\")\n",
    "        if len(str(sample[\"agent_task\"])) > 100:\n",
    "            print(f\"  Task: {sample['agent_task'][:100]}...\")\n",
    "        else:\n",
    "            print(f\"  Task: {sample['agent_task']}\")\n",
    "        print(f\"  Response length: {len(str(sample['agent_response']))} chars\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Output CSV not found\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. Cleanup (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to clean up the output CSV file\n",
    "# os.remove(OUTPUT_CSV)\n",
    "# print(f\"Cleaned up {OUTPUT_CSV}\")\n",
    "\n",
    "print(\"Testing completed!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
